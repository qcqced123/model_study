{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:27:20.116893Z",
     "start_time": "2024-05-03T03:27:11.471974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import eda\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matp\n",
    "import matplotlib.gridspec as gridspec\n",
    "import re, gc, pickle, json\n",
    "import configuration as configuration\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from typing import List, Tuple, Dict, Callable, Any\n",
    "from preprocessing import jsonl_to_json, load_all_types_dataset, stratified_kfold, check_null, null2str, sequence_length\n",
    "%matplotlib inline"
   ],
   "id": "4b30f8788596e520",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T03:28:07.416244Z",
     "start_time": "2024-05-03T03:28:07.411637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" LCS Test \"\"\"\n",
    "\n",
    "\n",
    "gen_ngram = ['i', 'am', 'a', 'girl']\n",
    "ref_ngram = ['i', 'am', 'a', 'girl']\n",
    "\n",
    "def cal_longest_common_sequence() -> int:\n",
    "    \"\"\" calculating length of longest common sequence between generated text and reference text \"\"\"\n",
    "    result = 0\n",
    "    rows, cols = len(gen_ngram) + 1, len(ref_ngram)+1\n",
    "\n",
    "    dp = [[0]*cols for _ in range(rows)]\n",
    "    for y in range(1, rows):\n",
    "        for x in range(1, cols):\n",
    "            if gen_ngram[y-1] == ref_ngram[x-1]:\n",
    "                dp[y][x] = dp[y-1][x-1] + 1\n",
    "                result = max(result, dp[y][x])\n",
    "                continue\n",
    "            \n",
    "            dp[y][x] = max(dp[y-1][x], dp[y][x-1])\n",
    "            \n",
    "    return result\n",
    "\n",
    "cal_longest_common_sequence()"
   ],
   "id": "99a5494770d76d09",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b252a11238853e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T13:04:16.749474Z",
     "start_time": "2024-04-26T13:04:11.922009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data_folder/commerce/amazon/meta_grocery_gourmet_food_asin_db.csv')\n",
    "df"
   ],
   "id": "d212b554a3f6f584",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T13:05:12.603257Z",
     "start_time": "2024-04-26T13:05:12.580396Z"
    }
   },
   "cell_type": "code",
   "source": "df.sub_category.value_counts()",
   "id": "20355be4616484eb",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T08:25:24.519583Z",
     "start_time": "2024-04-17T08:24:34.811725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Merge Two different categories of dataset in amazon review data \"\"\"\n",
    "\n",
    "beauty_df, fashion_df = load_all_types_dataset('./data_folder/amazon_review/beauty.json'), load_all_types_dataset('./data_folder/amazon_review/fashion.json')\n",
    "beauty_df['domain'], fashion_df['domain'] = 'beauty', 'fashion'\n",
    "df = pd.concat([beauty_df, fashion_df], axis=0).reset_index(drop=True)\n",
    "df = stratified_kfold(df, 'rating', configuration.CFG)\n",
    "df.to_csv('train.csv', index=False, encoding='utf-8')"
   ],
   "id": "990e126b7ae8e762",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T04:47:38.002310Z",
     "start_time": "2024-04-19T04:47:26.539205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = load_all_types_dataset('./data_folder/commerce/amazon/train.csv')\n",
    "df"
   ],
   "id": "f1491f2103dfcd50",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:02:25.513575Z",
     "start_time": "2024-04-18T14:02:21.879504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Null Checker Function \"\"\"\n",
    "\n",
    "df = null2str(df)\n",
    "check_null(df)"
   ],
   "id": "fca0d88cecac7894",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:33:16.021417Z",
     "start_time": "2024-04-27T12:33:15.929018Z"
    }
   },
   "cell_type": "code",
   "source": "df['length'] = sequence_length(configuration.CFG, df['text'])",
   "id": "a660ea37f0102f72",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:07:18.789772Z",
     "start_time": "2024-04-16T11:07:17.060523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" configuration for preprocessing and eda \"\"\"\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    tokenizer_name = 'microsoft/deberta-v3-large'  # later, remove this line\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    max_len = 512\n",
    "    split_ratio = 0.2\n",
    "    n_folds = 5"
   ],
   "id": "c839ac099891d85",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:07:18.802565Z",
     "start_time": "2024-04-16T11:07:18.790935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Helper Function for preprocessing \"\"\"\n",
    "\n",
    "def group_texts(cfg: configuration.CFG, sequences: Dict) -> Dict:\n",
    "    \"\"\" Dealing Problem: some of data instances are longer than the maximum input length for the model,\n",
    "    This function is ONLY used to HF Dataset Object\n",
    "\n",
    "    1) Concatenate all texts\n",
    "    2) We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    3) customize this part to your needs\n",
    "    4) Split by chunks of max_len\n",
    "\n",
    "    \"\"\"\n",
    "    concatenated_sequences = {k: sum(sequences[k], []) for k in sequences.keys()}\n",
    "    total_length = len(concatenated_sequences[list(sequences.keys())[0]])\n",
    "    if total_length >= cfg.max_seq:\n",
    "        total_length = (total_length // cfg.max_seq) * cfg.max_seq\n",
    "    result = {\n",
    "        k: [t[i: i + cfg.max_seq] for i in range(0, total_length, cfg.max_seq)]\n",
    "        for k, t in concatenated_sequences.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def tokenizing(cfg: configuration.CFG, text: str, padding: bool or str = 'max_length') -> Any:\n",
    "    \"\"\" Preprocess text for LLM Input, for common batch system\n",
    "\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load tokenizer from Huggingface AutoTokenizer\n",
    "        text: text from dataframe or any other dataset, please pass str type\n",
    "        padding: padding options, default 'max_length', if you want use smart batching, init this param to False\n",
    "    \"\"\"\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=cfg.max_len,\n",
    "        padding=padding,\n",
    "        truncation=False,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=False,  # later, we will add ourselves\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v)\n",
    "    return inputs\n",
    "\n",
    "def adjust_sequences(sequences: List, max_len: int):\n",
    "    \"\"\" Similar to dynamic padding concept\n",
    "    Append slicing index from original, because original source code is implemented weired\n",
    "    So it generates some problem for applying very longer sequence\n",
    "    Add -1 value to slicing index, so we can get result what we want\n",
    "\n",
    "    Args:\n",
    "        sequences: list of each cell's token sequence in one unique notebook id, must pass tokenized sequence input_ids\n",
    "        => sequences = [[1,2,3,4,5,6], [1,2,3,4,5,6], ... , [1,2,3,4,5]]\n",
    "        max_len: max length of sequence into LLM Embedding Layer, default is 2048 for DeBERTa-V3-Large\n",
    "\n",
    "    Reference:\n",
    "         https://github.com/louis-she/ai4code/blob/master/ai4code/utils.py#L70\n",
    "    \"\"\"\n",
    "    length_of_seqs = [len(seq) for seq in sequences]\n",
    "    total_len = sum(length_of_seqs)\n",
    "    cut_off = total_len - max_len\n",
    "    if cut_off <= 0:\n",
    "        return sequences, length_of_seqs\n",
    "\n",
    "    for _ in range(cut_off):\n",
    "        max_index = length_of_seqs.index(max(length_of_seqs))\n",
    "        length_of_seqs[max_index] -= 1\n",
    "    sequences = [sequences[i][:l-1] for i, l in enumerate(length_of_seqs)]\n",
    "    return sequences, length_of_seqs\n",
    "\n",
    "def subsequent_tokenizing(cfg: configuration.CFG, text: str) -> Any:\n",
    "    \"\"\" Tokenize input sentence to longer sequence than common tokenizing\n",
    "    Append padding strategy NOT Apply same max length, similar concept to dynamic padding\n",
    "    Truncate longer sequence to match LLM max sequence\n",
    "\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load tokenizer from Huggingface AutoTokenizer\n",
    "        text: text from dataframe or any other dataset, please pass str type\n",
    "\n",
    "    Reference:\n",
    "        https://www.kaggle.com/competitions/AI4Code/discussion/343714\n",
    "        https://github.com/louis-she/ai4code/blob/master/tests/test_utils.py#L6\n",
    "    \"\"\"\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=False,  # No need to special token to subsequent text sequence\n",
    "    )\n",
    "    return inputs['input_ids']\n",
    "\n",
    "\n",
    "def find_index(x: np.ndarray, value: np.ndarray) -> int:\n",
    "    \"\"\" Method for find some tensor element's index\n",
    "\n",
    "    Args:\n",
    "        x: tensor object, which is contained whole tensor elements\n",
    "        value: element that you want to find index\n",
    "    \"\"\"\n",
    "    tensor_index = int(np.where(x == value)[0])\n",
    "    return tensor_index\n",
    "\n",
    "\n",
    "def subsequent_decode(cfg: configuration.CFG, token_list: List) -> Any:\n",
    "    \"\"\" Return decoded text from subsequent_tokenizing & adjust_sequences\n",
    "    For making prompt text\n",
    "\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load tokenizer from Huggingface AutoTokenizer\n",
    "        token_list: token list from subsequent_tokenizing & adjust_sequences\n",
    "    \"\"\"\n",
    "    output = cfg.tokenizer.decode(token_list)\n",
    "    return output\n",
    "\n",
    "\n",
    "def sequence_length(cfg: configuration.CFG, text_list: List) -> List:\n",
    "    \"\"\" Get sequence length of all text data for checking statistics value\n",
    "    \"\"\"\n",
    "    length_list = []\n",
    "    for text in tqdm(text_list):\n",
    "        tmp_text = tokenizing(cfg, text)['attention_mask']\n",
    "        length_list.append(torch.eq(tmp_text, 1).sum().item())  # not need to tensor, but need to scalar\n",
    "    return length_list\n",
    "\n",
    "def check_null(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\" check if input dataframe has null type object...etc\n",
    "    \"\"\"\n",
    "    return df.isnull().sum()\n",
    "\n",
    "def no_char(text):\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\^[a-zA-Z]\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]$\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def no_multi_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text, flags=re.I)\n",
    "\n",
    "\n",
    "def underscore_to_space(text: str):\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(source):\n",
    "    \"\"\" Remove all the special characters\n",
    "    \"\"\"\n",
    "    source = re.sub(r'\\W', ' ', str(source))\n",
    "    source = re.sub(r'^b\\s+', '', source)\n",
    "    source = source.lower()\n",
    "    return source\n",
    "\n",
    "\n",
    "def cleaning_words(text: str) -> str:\n",
    "    \"\"\" Apply all of cleaning process to text data\n",
    "    \"\"\"\n",
    "    tmp_text = underscore_to_space(text)\n",
    "    tmp_text = no_char(tmp_text)\n",
    "    tmp_text = preprocess_text(tmp_text)\n",
    "    tmp_text = no_multi_spaces(tmp_text)\n",
    "    return tmp_text\n",
    "\n",
    "\n",
    "def load_pkl(filepath: str) -> Any:\n",
    "    \"\"\" Load pickle file\n",
    "\n",
    "    Examples:\n",
    "        filepath = './dataset_class/data_folder/train.pkl'\n",
    "    \"\"\"\n",
    "    with open(f'{filepath}', 'rb') as file:\n",
    "        output = pickle.load(file)\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_json(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\" Load json file\n",
    "\n",
    "    Examples:\n",
    "        filepath = './dataset_class/data_folder/train.json'\n",
    "    \"\"\"\n",
    "    output = pd.read_json(filepath)\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_parquet(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\" Load parquet file\n",
    "\n",
    "    Examples:\n",
    "        filepath = './dataset_class/data_folder/train.parquet'\n",
    "    \"\"\"\n",
    "    output = pd.read_parquet(filepath)\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_csv(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\" Load csv file\n",
    "\n",
    "    Examples:\n",
    "        filepath = './dataset_class/data_folder/train.csv'\n",
    "    \"\"\"\n",
    "    output = pd.read_csv(filepath)\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_all_types_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\" Load all pickle files from folder\n",
    "\n",
    "    Args:\n",
    "        path: path in your local directory\n",
    "\n",
    "    Examples:\n",
    "        load_all_types_dataset('./data_folder/squad2/train.json')\n",
    "        load_all_types_dataset('./data_folder/yahoo_qa/test.csv')\n",
    "        load_all_types_dataset('./data_folder/yelp_review/train_0.parquet')\n",
    "\n",
    "    All of file types are supported: json, csv, parquet, pkl\n",
    "    And Then, they are converted to dict type in python\n",
    "    \"\"\"\n",
    "    output = None\n",
    "    file_types = path.split('.')[-1]\n",
    "    if file_types == 'pkl': output = load_pkl(path)\n",
    "    elif file_types == 'json': output = load_json(path)\n",
    "    elif file_types == 'parquet': output = load_parquet(path)\n",
    "    elif file_types == 'csv': output = load_csv(path)\n",
    "    \n",
    "    return output"
   ],
   "id": "994f126356df0d3",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:01:48.181078Z",
     "start_time": "2024-04-16T07:01:47.475708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Load Dataset \"\"\"\n",
    "\n",
    "DATA_PATH = './data_folder/'\n",
    "DATA_NAME = 'yelp_review'\n",
    "TYPE = 'train.parquet'\n",
    "\n",
    "df = load_all_types_dataset(f'{DATA_PATH}{DATA_NAME}/{TYPE}')\n",
    "df"
   ],
   "id": "6d800664caac2fc",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T07:02:39.659239Z",
     "start_time": "2024-04-16T07:01:52.923204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" cleaning text data in dataframe \"\"\"\n",
    "\n",
    "df['text'] = df['text'].apply(cleaning_words)\n",
    "df, df.text[1]"
   ],
   "id": "5c64fe6cf5afe3d4",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "\"\"\" Amazon Review Dataset \"\"\"\n",
    "\n",
    "\"\"\" Load Dataset \"\"\"\n",
    "\n",
    "DATA_PATH = './data_folder/'\n",
    "DATA_NAME = 'amazon_review'\n",
    "TYPE = 'beauty.json'\n",
    "\n",
    "df = load_all_types_dataset(f'{DATA_PATH}{DATA_NAME}/{TYPE}')\n",
    "df"
   ],
   "id": "d9ccf1d7bf0636d5",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\"\"\" calculate length of each text data, check statistics value of train text data \"\"\"\n",
    "\n",
    "lengths = sequence_length(CFG, df['text'])\n",
    "\n",
    "print('------------- Length Statistic Info -------------')\n",
    "print('Max Length of Sentence : {}'.format(np.max(lengths)))\n",
    "print('Min Length of Sentence : {}'.format(np.min(lengths)))\n",
    "print('Mean Length of Sentence : {:.2f}'.format(np.mean(lengths)))\n",
    "print('Std Length of Sentence : {:.2f}'.format(np.std(lengths)))\n",
    "print('Median Length of Sentence : {}'.format(np.median(lengths)))\n",
    "print('Q1 Length of Sentence : {}'.format(np.percentile(lengths, 25)))\n",
    "print('Q3 Length of Sentence : {}'.format(np.percentile(lengths, 75)))"
   ],
   "id": "b25a54a14669e0d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "\"\"\" Box plot of length of text data\"\"\"\n",
    "\n",
    "sns.set_style(style='dark')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.boxplot(lengths, labels=['count'], showmeans=True) "
   ],
   "id": "38a0d315e418379a",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "\"\"\" log scale hist plot \"\"\"\n",
    "\n",
    "sns.set_style(style='dark')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.hist(lengths, bins=30, alpha=0.5, color='blue', label='tokens')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Log-Histplot of Text length\", fontsize=20)\n",
    "plt.xlabel(\"length of tokens\", fontsize=16)\n",
    "plt.ylabel(\"number of texts\", fontsize=16)"
   ],
   "id": "1f4fa5248d67bd3c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\"\"\" word cloud plot \"\"\"\n",
    "\n",
    "cloud = WordCloud(width=800, height=600).generate(\" \".join(df['text']))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off') "
   ],
   "id": "f191a26dd11e6a72",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "\"\"\" plot for rating distribution \"\"\"\n",
    "\n",
    "rating_count = df['label'].value_counts()\n",
    "rating_count"
   ],
   "id": "b97d6d48a15d57ce",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "\"\"\" co-relation between length of review and rating \"\"\"\n",
    "\n",
    "labels = df.label.to_list()\n",
    "corr_df = pd.DataFrame()\n",
    "corr_df['label'], corr_df['length'] = labels, lengths\n",
    "measure_corr = corr_df.corr() \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(\n",
    "    measure_corr, \n",
    "    xticklabels=measure_corr.columns, \n",
    "    yticklabels=measure_corr.columns, \n",
    "    square=True,\n",
    "    annot=True, \n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\"\n",
    ")"
   ],
   "id": "b0e2895a2fc14251",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def jsonl_to_json(jsonl_file: str, json_file: str) -> None:\n",
    "    \"\"\" Convert jsonl file to json file\n",
    "    \n",
    "    Args:\n",
    "        jsonl_file: input jsonl file path\n",
    "        json_file: output json file path, which is converted from jsonl file\n",
    "        \n",
    "    Examples:\n",
    "        jsonl_to_json('./data_folder/amazon_review/beauty.jsonl', './data_folder/amazon_review/beauty.json')\n",
    "        \n",
    "    \"\"\"\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        jsonl_data = f.readlines()\n",
    "\n",
    "    json_data = [json.loads(line.strip()) for line in jsonl_data]\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "jsonl_to_json('./data_folder/amazon_review/beauty.jsonl', './data_folder/amazon_review/beauty.json')"
   ],
   "id": "7c73bb02633c8d37",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:07:28.553822Z",
     "start_time": "2024-04-16T11:07:23.011525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Load Amazon Review Dataset \"\"\"\n",
    "\n",
    "DATA_PATH = './data_folder/'\n",
    "DATA_NAME = 'amazon_review'\n",
    "TYPE = 'beauty.json'\n",
    "\n",
    "df = load_all_types_dataset(f'{DATA_PATH}{DATA_NAME}/{TYPE}')\n",
    "df"
   ],
   "id": "af7f3fcb6858e06c",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:19:37.671868Z",
     "start_time": "2024-04-16T12:16:32.967353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" calculate length of each text data, check statistics value of train text data \"\"\"\n",
    "\n",
    "lengths = sequence_length(CFG, df['text'])\n",
    "eda.print_length_stats_of_text(lengths)"
   ],
   "id": "603d2ba004231364",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:19:38.588668Z",
     "start_time": "2024-04-16T12:19:37.673332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" Box plot of length of text data \"\"\"\n",
    "\n",
    "eda.token_length_box_plot(lengths)"
   ],
   "id": "6cb001354ea099bb",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:19:39.632712Z",
     "start_time": "2024-04-16T12:19:38.591944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" log scale hist plot \"\"\"\n",
    "\n",
    "eda.log_scale_token_length_plot(lengths)"
   ],
   "id": "7b74ccc9ef14a95f",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Must use longer sequence for LLM model, because of the limitation of the maximum input length of the model\n",
    "such as llama, deberta, bigbird, longformer and so on"
   ],
   "id": "d7a3e777c7fc7232"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "cd9f30b2665e3152",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
