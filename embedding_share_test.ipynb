{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T13:58:09.555412703Z",
     "start_time": "2024-01-11T13:58:07.304402014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from configuration import CFG\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" Sharing Embedding method compare\n",
    "1) assignment method\n",
    "2) register_buffer method\n",
    "=> same result\n",
    "\"\"\"\n",
    "\n",
    "class SimpleModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModelA, self).__init__()\n",
    "        self.fc = nn.Linear(5, 10)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Linear(10, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SimpleModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModelB, self).__init__()\n",
    "        self.fc = nn.Linear(5, 10)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Linear(10, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "def _set_param(module, param_name, value):\n",
    "    \"\"\" set param for module\n",
    "    References:\n",
    "         https://github.com/microsoft/DeBERTa/blob/master/DeBERTa/apps/tasks/rtd_task.py#L132\n",
    "    \"\"\"\n",
    "    if hasattr(module, param_name):\n",
    "        delattr(module, param_name)\n",
    "    module.register_buffer(param_name, value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T14:17:46.965103092Z",
     "start_time": "2024-01-11T14:17:46.910342050Z"
    }
   },
   "id": "557ac5dc18775eed",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal tensor: tensor([[ 1.2118,  3.1685, -0.5414, -0.0677, -0.4438],\n",
      "        [ 1.0348, -0.3990,  0.2015,  1.0433, -1.1713],\n",
      "        [-2.3768,  1.2644, -0.6693,  0.2703, -0.6440],\n",
      "        [-2.0380,  0.9287, -0.2184, -0.8486, -1.4809],\n",
      "        [-0.8635, -1.8849,  0.7566,  0.5584, -0.3627]])\n",
      "modelA fc weight init: Parameter containing:\n",
      "tensor([[ 0.1308,  0.4245,  0.3810,  0.3773,  0.2410],\n",
      "        [-0.0236, -0.1569, -0.2598,  0.4251,  0.0310],\n",
      "        [ 0.1863,  0.2381, -0.2812, -0.0691, -0.2410],\n",
      "        [ 0.2252,  0.1283, -0.2561,  0.3531, -0.3959],\n",
      "        [ 0.3516,  0.3771,  0.1835, -0.0877,  0.0874],\n",
      "        [-0.2073,  0.4389, -0.2564, -0.2378, -0.1997],\n",
      "        [-0.2174, -0.2967,  0.3839, -0.0043,  0.3665],\n",
      "        [-0.0613,  0.2035,  0.2152,  0.0953, -0.2907],\n",
      "        [ 0.4015, -0.3282, -0.0389, -0.3063, -0.4215],\n",
      "        [ 0.0652,  0.4055,  0.3240,  0.3655,  0.2869]], requires_grad=True)\n",
      "modelB fc weight init: Parameter containing:\n",
      "tensor([[ 0.1308,  0.4245,  0.3810,  0.3773,  0.2410],\n",
      "        [-0.0236, -0.1569, -0.2598,  0.4251,  0.0310],\n",
      "        [ 0.1863,  0.2381, -0.2812, -0.0691, -0.2410],\n",
      "        [ 0.2252,  0.1283, -0.2561,  0.3531, -0.3959],\n",
      "        [ 0.3516,  0.3771,  0.1835, -0.0877,  0.0874],\n",
      "        [-0.2073,  0.4389, -0.2564, -0.2378, -0.1997],\n",
      "        [-0.2174, -0.2967,  0.3839, -0.0043,  0.3665],\n",
      "        [-0.0613,  0.2035,  0.2152,  0.0953, -0.2907],\n",
      "        [ 0.4015, -0.3282, -0.0389, -0.3063, -0.4215],\n",
      "        [ 0.0652,  0.4055,  0.3240,  0.3655,  0.2869]], requires_grad=True)\n",
      "loss: 21.214845657348633\n",
      "modelA fc weight 0: Parameter containing:\n",
      "tensor([[ 0.0308,  0.5245,  0.2810,  0.4773,  0.1410],\n",
      "        [-0.1236, -0.0569, -0.3598,  0.5251, -0.0690],\n",
      "        [ 0.2863,  0.1381, -0.1812, -0.1691, -0.1410],\n",
      "        [ 0.1252,  0.2283, -0.3561,  0.4531, -0.4959],\n",
      "        [ 0.4516,  0.2771,  0.2835, -0.1877,  0.1874],\n",
      "        [-0.1073,  0.3389, -0.1564, -0.3378, -0.0997],\n",
      "        [-0.1174, -0.3967,  0.4839, -0.1043,  0.4665],\n",
      "        [ 0.0387,  0.1035,  0.3152, -0.0047, -0.1907],\n",
      "        [ 0.3015, -0.2282, -0.1389, -0.2063, -0.5215],\n",
      "        [-0.0348,  0.5055,  0.2240,  0.4655,  0.1869]], requires_grad=True)\n",
      "modelB fc weight 0: Parameter containing:\n",
      "tensor([[ 0.0308,  0.5245,  0.2810,  0.4773,  0.1410],\n",
      "        [-0.1236, -0.0569, -0.3598,  0.5251, -0.0690],\n",
      "        [ 0.2863,  0.1381, -0.1812, -0.1691, -0.1410],\n",
      "        [ 0.1252,  0.2283, -0.3561,  0.4531, -0.4959],\n",
      "        [ 0.4516,  0.2771,  0.2835, -0.1877,  0.1874],\n",
      "        [-0.1073,  0.3389, -0.1564, -0.3378, -0.0997],\n",
      "        [-0.1174, -0.3967,  0.4839, -0.1043,  0.4665],\n",
      "        [ 0.0387,  0.1035,  0.3152, -0.0047, -0.1907],\n",
      "        [ 0.3015, -0.2282, -0.1389, -0.2063, -0.5215],\n",
      "        [-0.0348,  0.5055,  0.2240,  0.4655,  0.1869]], requires_grad=True)\n",
      "modelA ffn weight 0: Parameter containing:\n",
      "tensor([[-0.2058, -0.1080, -0.2651,  0.0611,  0.4157, -0.2133, -0.3741, -0.1199,\n",
      "         -0.1829,  0.1004],\n",
      "        [-0.0978,  0.2130,  0.3190, -0.3038,  0.1240,  0.1839,  0.3347, -0.3068,\n",
      "         -0.0155,  0.0688],\n",
      "        [-0.1062,  0.2377,  0.0908,  0.0364, -0.1958,  0.0189,  0.2977, -0.1960,\n",
      "          0.1805, -0.0745],\n",
      "        [-0.1325, -0.1773,  0.4119, -0.1708, -0.2883, -0.2755, -0.1613, -0.2068,\n",
      "          0.0618, -0.1949],\n",
      "        [ 0.0433, -0.0285,  0.0715,  0.3644,  0.0714,  0.1633, -0.2313, -0.0735,\n",
      "         -0.3619,  0.1450],\n",
      "        [ 0.1713, -0.0073, -0.0527, -0.2269,  0.1597,  0.0301,  0.0767,  0.1634,\n",
      "          0.2302, -0.0288],\n",
      "        [ 0.0264,  0.1708, -0.0563, -0.0878, -0.1729, -0.1093,  0.0734,  0.2106,\n",
      "         -0.2325, -0.0829],\n",
      "        [ 0.2395, -0.1664,  0.2769,  0.1115,  0.0734, -0.1867,  0.4141, -0.0766,\n",
      "         -0.0401,  0.2574],\n",
      "        [ 0.1258,  0.0473,  0.1018,  0.3624,  0.1989, -0.1183, -0.1370,  0.2538,\n",
      "         -0.0594, -0.0463],\n",
      "        [ 0.2301,  0.4062, -0.0775,  0.1339, -0.1596,  0.1856, -0.1734, -0.2647,\n",
      "          0.3971,  0.2901]], requires_grad=True)\n",
      "modelB ffn weight 0: Parameter containing:\n",
      "tensor([[ 0.0415,  0.3974, -0.1588, -0.3605, -0.0583,  0.2935, -0.1282,  0.0586,\n",
      "          0.1045, -0.2392],\n",
      "        [ 0.1225,  0.0423, -0.0490, -0.0759,  0.0336, -0.1833, -0.0870,  0.0546,\n",
      "          0.1790,  0.0585],\n",
      "        [-0.3774, -0.0687, -0.1611,  0.0653, -0.1647, -0.0411,  0.1509,  0.0510,\n",
      "         -0.3883,  0.1577],\n",
      "        [ 0.0605, -0.4100, -0.2805,  0.2636,  0.2056,  0.0752,  0.3444, -0.0300,\n",
      "         -0.3065, -0.1150],\n",
      "        [ 0.1369, -0.2127, -0.0025,  0.1460,  0.0575,  0.2692, -0.3394,  0.3532,\n",
      "         -0.1247, -0.0977],\n",
      "        [ 0.1535, -0.4058,  0.1474,  0.0636, -0.0977,  0.1441,  0.2178,  0.1342,\n",
      "         -0.2648, -0.2049],\n",
      "        [ 0.3864,  0.3802, -0.1550,  0.1686, -0.0207, -0.2068, -0.0025, -0.1606,\n",
      "          0.0041, -0.2328],\n",
      "        [-0.2004, -0.1778, -0.2280,  0.2739,  0.0161, -0.0546,  0.2702,  0.1202,\n",
      "         -0.2841,  0.2133],\n",
      "        [-0.0876, -0.0518,  0.0838, -0.1118, -0.1175, -0.0197, -0.2063,  0.2990,\n",
      "         -0.1479, -0.0593],\n",
      "        [-0.0096, -0.2945, -0.3077,  0.1963, -0.0912, -0.2969,  0.0950,  0.1650,\n",
      "         -0.2532, -0.1221]], requires_grad=True)\n",
      "loss: 12.411787033081055\n",
      "modelA fc weight 1: Parameter containing:\n",
      "tensor([[-0.0211,  0.5647,  0.2388,  0.5117,  0.0973],\n",
      "        [-0.1715,  0.0074, -0.4307,  0.5722, -0.1219],\n",
      "        [ 0.3178,  0.1665, -0.2114, -0.1410, -0.1534],\n",
      "        [ 0.0251,  0.2919, -0.3809,  0.5531, -0.5941],\n",
      "        [ 0.4881,  0.1992,  0.3686, -0.2391,  0.2435],\n",
      "        [-0.0868,  0.3137, -0.1195, -0.3378, -0.0839],\n",
      "        [-0.0301, -0.4920,  0.5835, -0.1892,  0.5547],\n",
      "        [-0.0099,  0.1243,  0.3337,  0.0492, -0.2359],\n",
      "        [ 0.3579, -0.2592, -0.1616, -0.2660, -0.4681],\n",
      "        [-0.0767,  0.5786,  0.1412,  0.5125,  0.1342]], requires_grad=True)\n",
      "modelB fc weight 1: Parameter containing:\n",
      "tensor([[-0.0211,  0.5647,  0.2388,  0.5117,  0.0973],\n",
      "        [-0.1715,  0.0074, -0.4307,  0.5722, -0.1219],\n",
      "        [ 0.3178,  0.1665, -0.2114, -0.1410, -0.1534],\n",
      "        [ 0.0251,  0.2919, -0.3809,  0.5531, -0.5941],\n",
      "        [ 0.4881,  0.1992,  0.3686, -0.2391,  0.2435],\n",
      "        [-0.0868,  0.3137, -0.1195, -0.3378, -0.0839],\n",
      "        [-0.0301, -0.4920,  0.5835, -0.1892,  0.5547],\n",
      "        [-0.0099,  0.1243,  0.3337,  0.0492, -0.2359],\n",
      "        [ 0.3579, -0.2592, -0.1616, -0.2660, -0.4681],\n",
      "        [-0.0767,  0.5786,  0.1412,  0.5125,  0.1342]], requires_grad=True)\n",
      "modelA ffn weight 1: Parameter containing:\n",
      "tensor([[-0.2595, -0.2067, -0.2647,  0.0802,  0.5131, -0.1505, -0.4007, -0.0747,\n",
      "         -0.2542,  0.0479],\n",
      "        [-0.0056,  0.1437,  0.3975, -0.3844,  0.1963,  0.0841,  0.4163, -0.3936,\n",
      "         -0.0217,  0.1601],\n",
      "        [-0.0133,  0.1687,  0.1696, -0.0445, -0.1236, -0.0806,  0.3797, -0.2834,\n",
      "          0.1769,  0.0174],\n",
      "        [-0.0649, -0.1133,  0.4823, -0.2401, -0.3481, -0.3427, -0.0924, -0.2748,\n",
      "          0.1286, -0.1272],\n",
      "        [-0.0449,  0.0423, -0.0059,  0.4432, -0.0015,  0.2630, -0.3109,  0.0101,\n",
      "         -0.3386,  0.0577],\n",
      "        [ 0.1797,  0.0825, -0.1091, -0.1804,  0.0779, -0.0170,  0.0359,  0.1786,\n",
      "          0.3142, -0.0244],\n",
      "        [-0.0022,  0.0754, -0.0114, -0.1179, -0.0872, -0.0545,  0.0955,  0.2184,\n",
      "         -0.3110, -0.1082],\n",
      "        [ 0.3394, -0.2286,  0.3602,  0.0244,  0.1428, -0.2771,  0.5032, -0.1728,\n",
      "         -0.0095,  0.3570],\n",
      "        [ 0.0357,  0.0819,  0.0063,  0.4617,  0.1409, -0.0421, -0.2371,  0.3506,\n",
      "         -0.1151, -0.1377],\n",
      "        [ 0.3082,  0.3326, -0.0024,  0.0584, -0.0856,  0.1006, -0.0977, -0.3414,\n",
      "          0.3345,  0.3680]], requires_grad=True)\n",
      "modelB ffn weight 1: Parameter containing:\n",
      "tensor([[ 0.1314,  0.4795, -0.0628, -0.2933, -0.1262,  0.3936, -0.2189,  0.0046,\n",
      "          0.1797, -0.1763],\n",
      "        [ 0.1564,  0.0994, -0.0898,  0.0099, -0.0513, -0.2025, -0.1179, -0.0423,\n",
      "          0.2519,  0.1491],\n",
      "        [-0.3359, -0.0082, -0.1957,  0.1492, -0.2479, -0.0507,  0.1119, -0.0436,\n",
      "         -0.3151,  0.2459],\n",
      "        [-0.0396, -0.5035, -0.3608,  0.2127,  0.2587, -0.0134,  0.4445, -0.0164,\n",
      "         -0.3833, -0.1523],\n",
      "        [ 0.2243, -0.1320,  0.0960,  0.2147, -0.0117,  0.3686, -0.4275,  0.2948,\n",
      "         -0.0496, -0.0323],\n",
      "        [ 0.1844, -0.3501,  0.1047,  0.1502, -0.1833,  0.1218,  0.1899,  0.0365,\n",
      "         -0.1921, -0.1135],\n",
      "        [ 0.4102,  0.3650, -0.0952,  0.0694,  0.0778, -0.1535, -0.0292, -0.0659,\n",
      "         -0.0648, -0.3326],\n",
      "        [-0.2418, -0.1885, -0.2908,  0.3733, -0.0838, -0.1137,  0.3134,  0.0334,\n",
      "         -0.2192,  0.3082],\n",
      "        [-0.0044,  0.0267,  0.1838, -0.0409, -0.1887,  0.0754, -0.2900,  0.2344,\n",
      "         -0.0731,  0.0095],\n",
      "        [-0.0982, -0.3759, -0.4051,  0.1282, -0.0226, -0.3968,  0.1844,  0.2214,\n",
      "         -0.3284, -0.1863]], requires_grad=True)\n",
      "loss: 7.415064811706543\n",
      "modelA fc weight 2: Parameter containing:\n",
      "tensor([[-0.0921,  0.5523,  0.2748,  0.5768,  0.0392],\n",
      "        [-0.2211, -0.0318, -0.3806,  0.6457, -0.1598],\n",
      "        [ 0.2559,  0.1305, -0.1560, -0.0748, -0.2180],\n",
      "        [ 0.0530,  0.2360, -0.3192,  0.6534, -0.5642],\n",
      "        [ 0.5259,  0.2481,  0.3139, -0.3114,  0.2648],\n",
      "        [-0.0545,  0.2472, -0.0528, -0.2790, -0.0421],\n",
      "        [-0.0324, -0.4362,  0.5222, -0.2756,  0.5456],\n",
      "        [ 0.0117,  0.0649,  0.3986,  0.1231, -0.2133],\n",
      "        [ 0.3356, -0.3211, -0.1039, -0.2493, -0.4795],\n",
      "        [-0.1478,  0.6542,  0.0686,  0.5532,  0.0595]], requires_grad=True)\n",
      "modelB fc weight 2: Parameter containing:\n",
      "tensor([[-0.0921,  0.5523,  0.2748,  0.5768,  0.0392],\n",
      "        [-0.2211, -0.0318, -0.3806,  0.6457, -0.1598],\n",
      "        [ 0.2559,  0.1305, -0.1560, -0.0748, -0.2180],\n",
      "        [ 0.0530,  0.2360, -0.3192,  0.6534, -0.5642],\n",
      "        [ 0.5259,  0.2481,  0.3139, -0.3114,  0.2648],\n",
      "        [-0.0545,  0.2472, -0.0528, -0.2790, -0.0421],\n",
      "        [-0.0324, -0.4362,  0.5222, -0.2756,  0.5456],\n",
      "        [ 0.0117,  0.0649,  0.3986,  0.1231, -0.2133],\n",
      "        [ 0.3356, -0.3211, -0.1039, -0.2493, -0.4795],\n",
      "        [-0.1478,  0.6542,  0.0686,  0.5532,  0.0595]], requires_grad=True)\n",
      "modelA ffn weight 2: Parameter containing:\n",
      "tensor([[-0.2771, -0.2349, -0.2664,  0.1301,  0.5730, -0.0866, -0.4598, -0.0258,\n",
      "         -0.3342,  0.0282],\n",
      "        [ 0.0726,  0.1812,  0.4515, -0.3426,  0.2152,  0.1373,  0.3673, -0.3675,\n",
      "         -0.0858,  0.2406],\n",
      "        [ 0.0605,  0.2158,  0.2200,  0.0052, -0.1213, -0.0238,  0.3253, -0.2443,\n",
      "          0.1130,  0.0930],\n",
      "        [-0.0296, -0.1025,  0.5385, -0.3188, -0.3731, -0.4058, -0.0116, -0.3374,\n",
      "          0.2005, -0.0897],\n",
      "        [-0.1231,  0.0081, -0.0596,  0.4033, -0.0242,  0.2092, -0.2630, -0.0140,\n",
      "         -0.2737, -0.0229],\n",
      "        [ 0.1206,  0.0483, -0.1452, -0.2313,  0.0571, -0.0891,  0.0921,  0.1288,\n",
      "          0.3874, -0.0833],\n",
      "        [ 0.0270,  0.0706,  0.0204, -0.0809, -0.0392,  0.0189,  0.0472,  0.2564,\n",
      "         -0.3964, -0.0817],\n",
      "        [ 0.4199, -0.1867,  0.4171,  0.0667,  0.1562, -0.2292,  0.4541, -0.1492,\n",
      "         -0.0707,  0.4401],\n",
      "        [-0.0566,  0.0408, -0.0626,  0.4372,  0.1248, -0.0527, -0.2018,  0.3643,\n",
      "         -0.0718, -0.2318],\n",
      "        [ 0.3822,  0.3725,  0.0479,  0.1044, -0.0705,  0.1591, -0.1498, -0.3067,\n",
      "          0.2687,  0.4438]], requires_grad=True)\n",
      "modelB ffn weight 2: Parameter containing:\n",
      "tensor([[ 0.1154,  0.5338, -0.0958, -0.3418, -0.2087,  0.3810, -0.1821, -0.0542,\n",
      "          0.2654, -0.2306],\n",
      "        [ 0.1269,  0.1368, -0.1590, -0.0286, -0.1428, -0.2548, -0.0718, -0.1292,\n",
      "          0.3340,  0.1034],\n",
      "        [-0.3206,  0.0371, -0.2406,  0.1690, -0.3253, -0.0714,  0.1113, -0.1199,\n",
      "         -0.2499,  0.2518],\n",
      "        [-0.0389, -0.5669, -0.3601,  0.2639,  0.3346, -0.0306,  0.4187,  0.0093,\n",
      "         -0.4700, -0.0952],\n",
      "        [ 0.2221, -0.0760,  0.0702,  0.1736, -0.0947,  0.3681, -0.4004,  0.2370,\n",
      "          0.0330, -0.0818],\n",
      "        [ 0.1411, -0.3180,  0.0328,  0.1019, -0.2718,  0.0609,  0.2442, -0.0558,\n",
      "         -0.1070, -0.1661],\n",
      "        [ 0.4414,  0.3550, -0.0413,  0.0533,  0.1700, -0.1062, -0.0704,  0.0100,\n",
      "         -0.1312, -0.3387],\n",
      "        [-0.2724, -0.1966, -0.3386,  0.4567, -0.1582, -0.1588,  0.3445, -0.0335,\n",
      "         -0.1715,  0.3887],\n",
      "        [-0.0075,  0.0812,  0.1519, -0.0804, -0.2726,  0.0696, -0.2623,  0.1722,\n",
      "          0.0089, -0.0386],\n",
      "        [-0.0947, -0.4321, -0.3800,  0.1706,  0.0602, -0.3962,  0.1563,  0.2782,\n",
      "         -0.4115, -0.1360]], requires_grad=True)\n",
      "loss: 5.142061233520508\n",
      "modelA fc weight 3: Parameter containing:\n",
      "tensor([[-0.1103,  0.4953,  0.3399,  0.6299,  0.0375],\n",
      "        [-0.2044, -0.0934, -0.3116,  0.7138, -0.1445],\n",
      "        [ 0.2383,  0.0687, -0.0894, -0.0194, -0.2230],\n",
      "        [ 0.0587,  0.2233, -0.3005,  0.7348, -0.5611],\n",
      "        [ 0.4826,  0.3089,  0.2457, -0.3838,  0.2274],\n",
      "        [ 0.0040,  0.1779,  0.0174, -0.2258,  0.0163],\n",
      "        [-0.0578, -0.3892,  0.4672, -0.3526,  0.5277],\n",
      "        [ 0.0272,  0.0348,  0.4373,  0.1879, -0.2042],\n",
      "        [ 0.3664, -0.3911, -0.0359, -0.2205, -0.4452],\n",
      "        [-0.2044,  0.6476,  0.0679,  0.5461,  0.0245]], requires_grad=True)\n",
      "modelB fc weight 3: Parameter containing:\n",
      "tensor([[-0.1103,  0.4953,  0.3399,  0.6299,  0.0375],\n",
      "        [-0.2044, -0.0934, -0.3116,  0.7138, -0.1445],\n",
      "        [ 0.2383,  0.0687, -0.0894, -0.0194, -0.2230],\n",
      "        [ 0.0587,  0.2233, -0.3005,  0.7348, -0.5611],\n",
      "        [ 0.4826,  0.3089,  0.2457, -0.3838,  0.2274],\n",
      "        [ 0.0040,  0.1779,  0.0174, -0.2258,  0.0163],\n",
      "        [-0.0578, -0.3892,  0.4672, -0.3526,  0.5277],\n",
      "        [ 0.0272,  0.0348,  0.4373,  0.1879, -0.2042],\n",
      "        [ 0.3664, -0.3911, -0.0359, -0.2205, -0.4452],\n",
      "        [-0.2044,  0.6476,  0.0679,  0.5461,  0.0245]], requires_grad=True)\n",
      "modelA ffn weight 3: Parameter containing:\n",
      "tensor([[-0.3168, -0.2774, -0.2746,  0.1402,  0.5533, -0.0411, -0.4714,  0.0048,\n",
      "         -0.3537, -0.0139],\n",
      "        [ 0.0964,  0.1962,  0.4864, -0.3284,  0.1785,  0.1704,  0.3482, -0.3603,\n",
      "         -0.1025,  0.2597],\n",
      "        [ 0.0946,  0.2436,  0.2520,  0.0325, -0.1637,  0.0160,  0.2947, -0.2223,\n",
      "          0.0841,  0.1236],\n",
      "        [ 0.0272, -0.0636,  0.5950, -0.3326, -0.3223, -0.4484, -0.0035, -0.3759,\n",
      "          0.2021, -0.0307],\n",
      "        [-0.1478, -0.0048, -0.0953,  0.3900,  0.0082,  0.1754, -0.2445, -0.0201,\n",
      "         -0.2559, -0.0431],\n",
      "        [ 0.1189,  0.0410, -0.1614, -0.2461,  0.1005, -0.1345,  0.1099,  0.1072,\n",
      "          0.4008, -0.0788],\n",
      "        [ 0.0367,  0.0603,  0.0441, -0.0595, -0.0227,  0.0755,  0.0178,  0.2831,\n",
      "         -0.4489, -0.0756],\n",
      "        [ 0.4458, -0.1683,  0.4535,  0.0812,  0.1152, -0.2002,  0.4350, -0.1440,\n",
      "         -0.0856,  0.4613],\n",
      "        [-0.1022,  0.0198, -0.1131,  0.4329,  0.1545, -0.0548, -0.1900,  0.3842,\n",
      "         -0.0636, -0.2746],\n",
      "        [ 0.3801,  0.3775,  0.0700,  0.1072, -0.1201,  0.1879, -0.1559, -0.3039,\n",
      "          0.2719,  0.4358]], requires_grad=True)\n",
      "modelB ffn weight 3: Parameter containing:\n",
      "tensor([[ 0.0690,  0.5082, -0.1458, -0.4049, -0.2058,  0.3427, -0.1227, -0.0468,\n",
      "          0.3450, -0.3024],\n",
      "        [ 0.0722,  0.1081, -0.2345, -0.0859, -0.1442, -0.3190, -0.0057, -0.1473,\n",
      "          0.4103,  0.0360],\n",
      "        [-0.3145,  0.0664, -0.2816,  0.1766, -0.3783, -0.0923,  0.1201, -0.1775,\n",
      "         -0.1953,  0.2402],\n",
      "        [-0.0079, -0.5530, -0.3422,  0.3268,  0.3358, -0.0248,  0.3699, -0.0065,\n",
      "         -0.5492, -0.0229],\n",
      "        [ 0.1931, -0.0795,  0.0305,  0.1201, -0.1105,  0.3457, -0.3526,  0.2242,\n",
      "          0.1068, -0.1477],\n",
      "        [ 0.0795, -0.3527, -0.0426,  0.0417, -0.2792, -0.0081,  0.3127, -0.0729,\n",
      "         -0.0287, -0.2350],\n",
      "        [ 0.4712,  0.3548,  0.0044,  0.0489,  0.2336, -0.0659, -0.1103,  0.0687,\n",
      "         -0.1870, -0.3291],\n",
      "        [-0.2891, -0.1866, -0.3751,  0.5428, -0.2378, -0.1931,  0.3574, -0.0940,\n",
      "         -0.1368,  0.4763],\n",
      "        [-0.0402,  0.0725,  0.1045, -0.1350, -0.2827,  0.0397, -0.2115,  0.1608,\n",
      "          0.0829, -0.1055],\n",
      "        [-0.0632, -0.4249, -0.3400,  0.2260,  0.0722, -0.3725,  0.1067,  0.2870,\n",
      "         -0.4863, -0.0687]], requires_grad=True)\n",
      "loss: 5.499859809875488\n",
      "modelA fc weight 4: Parameter containing:\n",
      "tensor([[-0.1072,  0.4287,  0.4121,  0.6662,  0.0536],\n",
      "        [-0.1942, -0.1336, -0.2607,  0.7719, -0.1419],\n",
      "        [ 0.2380, -0.0023, -0.0158,  0.0195, -0.2099],\n",
      "        [ 0.0621,  0.2107, -0.2845,  0.8060, -0.5566],\n",
      "        [ 0.4648,  0.3255,  0.2122, -0.4492,  0.2323],\n",
      "        [ 0.0524,  0.1223,  0.0751, -0.1811,  0.0613],\n",
      "        [-0.0653, -0.3640,  0.4319, -0.4206,  0.5298],\n",
      "        [ 0.0296,  0.0227,  0.4586,  0.2462, -0.2077],\n",
      "        [ 0.3778, -0.3964, -0.0155, -0.1909, -0.4461],\n",
      "        [-0.2138,  0.6040,  0.1067,  0.5102,  0.0375]], requires_grad=True)\n",
      "modelB fc weight 4: Parameter containing:\n",
      "tensor([[-0.1072,  0.4287,  0.4121,  0.6662,  0.0536],\n",
      "        [-0.1942, -0.1336, -0.2607,  0.7719, -0.1419],\n",
      "        [ 0.2380, -0.0023, -0.0158,  0.0195, -0.2099],\n",
      "        [ 0.0621,  0.2107, -0.2845,  0.8060, -0.5566],\n",
      "        [ 0.4648,  0.3255,  0.2122, -0.4492,  0.2323],\n",
      "        [ 0.0524,  0.1223,  0.0751, -0.1811,  0.0613],\n",
      "        [-0.0653, -0.3640,  0.4319, -0.4206,  0.5298],\n",
      "        [ 0.0296,  0.0227,  0.4586,  0.2462, -0.2077],\n",
      "        [ 0.3778, -0.3964, -0.0155, -0.1909, -0.4461],\n",
      "        [-0.2138,  0.6040,  0.1067,  0.5102,  0.0375]], requires_grad=True)\n",
      "modelA ffn weight 4: Parameter containing:\n",
      "tensor([[-3.6013e-01, -3.2275e-01, -2.7698e-01,  1.3550e-01,  5.1889e-01,\n",
      "         -1.8845e-03, -4.6777e-01,  2.6209e-02, -3.4771e-01, -6.1182e-02],\n",
      "        [ 9.0990e-02,  1.9336e-01,  5.2763e-01, -3.3611e-01,  1.2072e-01,\n",
      "          2.0105e-01,  3.5071e-01, -3.6862e-01, -7.9998e-02,  2.4453e-01],\n",
      "        [ 1.1019e-01,  2.5967e-01,  2.8733e-01,  4.5863e-02, -2.2000e-01,\n",
      "          5.0860e-02,  2.7766e-01, -2.1078e-01,  8.0308e-02,  1.3192e-01],\n",
      "        [ 9.6367e-02, -5.4399e-03,  6.2226e-01, -3.0635e-01, -2.5313e-01,\n",
      "         -4.8716e-01, -3.2907e-02, -3.9334e-01,  1.6026e-01,  4.1561e-02],\n",
      "        [-1.4313e-01, -5.3649e-04, -1.3618e-01,  3.9824e-01,  6.2847e-02,\n",
      "          1.4416e-01, -2.4721e-01, -1.1161e-02, -2.7759e-01, -2.8692e-02],\n",
      "        [ 1.4183e-01,  5.1866e-02, -1.8984e-01, -2.3705e-01,  1.6243e-01,\n",
      "         -1.7578e-01,  1.0477e-01,  1.0497e-01,  3.7503e-01, -4.6645e-02],\n",
      "        [ 5.9703e-02,  6.0849e-02,  5.9751e-02, -2.9304e-02,  1.2802e-02,\n",
      "          1.2192e-01, -1.8967e-02,  3.1178e-01, -5.1427e-01, -5.1827e-02],\n",
      "        [ 4.4312e-01, -1.6781e-01,  4.9628e-01,  7.4599e-02,  5.4715e-02,\n",
      "         -1.7306e-01,  4.3652e-01, -1.5326e-01, -6.3292e-02,  4.4898e-01],\n",
      "        [-1.2203e-01,  1.3154e-02, -1.6255e-01,  4.4344e-01,  2.0340e-01,\n",
      "         -5.8108e-02, -1.9366e-01,  4.0908e-01, -8.4595e-02, -2.8705e-01],\n",
      "        [ 3.4666e-01,  3.5619e-01,  1.1090e-01,  7.9817e-02, -1.8813e-01,\n",
      "          2.1729e-01, -1.3271e-01, -3.2583e-01,  3.1552e-01,  3.9427e-01]],\n",
      "       requires_grad=True)\n",
      "modelB ffn weight 4: Parameter containing:\n",
      "tensor([[ 0.0580,  0.5109, -0.1668, -0.4394, -0.2091,  0.3265, -0.0980, -0.0730,\n",
      "          0.3917, -0.3268],\n",
      "        [ 0.0647,  0.1154, -0.2690, -0.1066, -0.1535, -0.3523,  0.0129, -0.1948,\n",
      "          0.4474,  0.0290],\n",
      "        [-0.3054,  0.0943, -0.3135,  0.1872, -0.4240, -0.1083,  0.1224, -0.2296,\n",
      "         -0.1508,  0.2416],\n",
      "        [ 0.0035, -0.5556, -0.3356,  0.3698,  0.3402, -0.0262,  0.3423, -0.0009,\n",
      "         -0.6055,  0.0175],\n",
      "        [ 0.1883, -0.0651,  0.0121,  0.0885, -0.1282,  0.3378, -0.3311,  0.1916,\n",
      "          0.1577, -0.1750],\n",
      "        [ 0.0449, -0.3649, -0.0949,  0.0014, -0.2890, -0.0576,  0.3556, -0.1083,\n",
      "          0.0254, -0.2719],\n",
      "        [ 0.4929,  0.3505,  0.0417,  0.0397,  0.2888, -0.0327, -0.1395,  0.1215,\n",
      "         -0.2315, -0.3337],\n",
      "        [-0.3154, -0.1951, -0.4101,  0.5800, -0.2982, -0.2249,  0.3839, -0.1323,\n",
      "         -0.0936,  0.4840],\n",
      "        [-0.0419,  0.0870,  0.0863, -0.1624, -0.2970,  0.0301, -0.1939,  0.1242,\n",
      "          0.1296, -0.1246],\n",
      "        [-0.0587, -0.4382, -0.3230,  0.2575,  0.0873, -0.3650,  0.0859,  0.3189,\n",
      "         -0.5360, -0.0433]], requires_grad=True)\n",
      "loss: 4.849518775939941\n",
      "modelA fc weight 5: Parameter containing:\n",
      "tensor([[-0.1042,  0.3856,  0.4606,  0.6874,  0.0594],\n",
      "        [-0.1978, -0.1445, -0.2367,  0.8150, -0.1567],\n",
      "        [ 0.2425, -0.0561,  0.0405,  0.0443, -0.2017],\n",
      "        [ 0.0717,  0.1828, -0.2558,  0.8802, -0.5405],\n",
      "        [ 0.4607,  0.3207,  0.1997, -0.4989,  0.2539],\n",
      "        [ 0.0889,  0.0814,  0.1193, -0.1447,  0.0923],\n",
      "        [-0.0620, -0.3480,  0.4060, -0.4793,  0.5384],\n",
      "        [ 0.0287,  0.0098,  0.4791,  0.2999, -0.2095],\n",
      "        [ 0.3706, -0.3656, -0.0329, -0.1811, -0.4710],\n",
      "        [-0.2058,  0.5566,  0.1497,  0.4739,  0.0582]], requires_grad=True)\n",
      "modelB fc weight 5: Parameter containing:\n",
      "tensor([[-0.1042,  0.3856,  0.4606,  0.6874,  0.0594],\n",
      "        [-0.1978, -0.1445, -0.2367,  0.8150, -0.1567],\n",
      "        [ 0.2425, -0.0561,  0.0405,  0.0443, -0.2017],\n",
      "        [ 0.0717,  0.1828, -0.2558,  0.8802, -0.5405],\n",
      "        [ 0.4607,  0.3207,  0.1997, -0.4989,  0.2539],\n",
      "        [ 0.0889,  0.0814,  0.1193, -0.1447,  0.0923],\n",
      "        [-0.0620, -0.3480,  0.4060, -0.4793,  0.5384],\n",
      "        [ 0.0287,  0.0098,  0.4791,  0.2999, -0.2095],\n",
      "        [ 0.3706, -0.3656, -0.0329, -0.1811, -0.4710],\n",
      "        [-0.2058,  0.5566,  0.1497,  0.4739,  0.0582]], requires_grad=True)\n",
      "modelA ffn weight 5: Parameter containing:\n",
      "tensor([[-0.3968, -0.3564, -0.2836,  0.1322,  0.4838,  0.0305, -0.4646,  0.0458,\n",
      "         -0.3466, -0.1018],\n",
      "        [ 0.0855,  0.1867,  0.5697, -0.3433,  0.0766,  0.2301,  0.3528, -0.3777,\n",
      "         -0.0571,  0.2314],\n",
      "        [ 0.1233,  0.2716,  0.3220,  0.0572, -0.2648,  0.0820,  0.2630, -0.2017,\n",
      "          0.0789,  0.1391],\n",
      "        [ 0.1566,  0.0501,  0.6392, -0.2830, -0.1980, -0.5222, -0.0583, -0.4071,\n",
      "          0.1213,  0.1039],\n",
      "        [-0.1382,  0.0073, -0.1775,  0.4059,  0.1042,  0.1146, -0.2496, -0.0015,\n",
      "         -0.2999, -0.0162],\n",
      "        [ 0.1619,  0.0633, -0.2181, -0.2289,  0.2134, -0.2126,  0.1003,  0.1040,\n",
      "          0.3512, -0.0189],\n",
      "        [ 0.0815,  0.0708,  0.0641, -0.0019,  0.0287,  0.1571, -0.0506,  0.3397,\n",
      "         -0.5798, -0.0312],\n",
      "        [ 0.4401, -0.1710,  0.5393,  0.0684,  0.0077, -0.1475,  0.4378, -0.1629,\n",
      "         -0.0410,  0.4383],\n",
      "        [-0.1386,  0.0103, -0.2087,  0.4529,  0.2413, -0.0624, -0.1968,  0.4316,\n",
      "         -0.1054, -0.2977],\n",
      "        [ 0.3169,  0.3320,  0.1565,  0.0554, -0.2411,  0.2466, -0.1127, -0.3476,\n",
      "          0.3569,  0.3584]], requires_grad=True)\n",
      "modelB ffn weight 5: Parameter containing:\n",
      "tensor([[ 0.0649,  0.5269, -0.1759, -0.4572, -0.2155,  0.3219, -0.0951, -0.1194,\n",
      "          0.4076, -0.3253],\n",
      "        [ 0.0801,  0.1395, -0.2859, -0.1064, -0.1666, -0.3681,  0.0037, -0.2589,\n",
      "          0.4474,  0.0511],\n",
      "        [-0.2982,  0.1179, -0.3412,  0.1956, -0.4633, -0.1223,  0.1254, -0.2738,\n",
      "         -0.1120,  0.2409],\n",
      "        [ 0.0062, -0.5644, -0.3329,  0.4019,  0.3455, -0.0304,  0.3264,  0.0171,\n",
      "         -0.6440,  0.0414],\n",
      "        [ 0.1958, -0.0429,  0.0028,  0.0697, -0.1459,  0.3375, -0.3260,  0.1456,\n",
      "          0.1877, -0.1804],\n",
      "        [ 0.0090, -0.3813, -0.1428, -0.0374, -0.2962, -0.1032,  0.3988, -0.1249,\n",
      "          0.0799, -0.3119],\n",
      "        [ 0.5159,  0.3515,  0.0750,  0.0388,  0.3348, -0.0031, -0.1711,  0.1608,\n",
      "         -0.2760, -0.3200],\n",
      "        [-0.3531, -0.2210, -0.4441,  0.5763, -0.3419, -0.2559,  0.4277, -0.1413,\n",
      "         -0.0325,  0.4472],\n",
      "        [-0.0262,  0.1133,  0.0809, -0.1728, -0.3131,  0.0321, -0.1987,  0.0703,\n",
      "          0.1481, -0.1160],\n",
      "        [-0.0684, -0.4611, -0.3159,  0.2746,  0.1032, -0.3660,  0.0836,  0.3666,\n",
      "         -0.5619, -0.0420]], requires_grad=True)\n",
      "loss: 4.729999542236328\n",
      "modelA fc weight 6: Parameter containing:\n",
      "tensor([[-0.1153,  0.3879,  0.4624,  0.6819,  0.0428],\n",
      "        [-0.2094, -0.1315, -0.2384,  0.8191, -0.1751],\n",
      "        [ 0.2334, -0.0542,  0.0426,  0.0550, -0.2228],\n",
      "        [ 0.0891,  0.1364, -0.2096,  0.9620, -0.5135],\n",
      "        [ 0.4658,  0.2970,  0.2073, -0.5291,  0.2877],\n",
      "        [ 0.1163,  0.0538,  0.1505, -0.1225,  0.1163],\n",
      "        [-0.0619, -0.3298,  0.3806, -0.5174,  0.5331],\n",
      "        [ 0.0347, -0.0167,  0.5104,  0.3475, -0.1971],\n",
      "        [ 0.3520, -0.3127, -0.0768, -0.2097, -0.5082],\n",
      "        [-0.2051,  0.5311,  0.1725,  0.4914,  0.0546]], requires_grad=True)\n",
      "modelB fc weight 6: Parameter containing:\n",
      "tensor([[-0.1153,  0.3879,  0.4624,  0.6819,  0.0428],\n",
      "        [-0.2094, -0.1315, -0.2384,  0.8191, -0.1751],\n",
      "        [ 0.2334, -0.0542,  0.0426,  0.0550, -0.2228],\n",
      "        [ 0.0891,  0.1364, -0.2096,  0.9620, -0.5135],\n",
      "        [ 0.4658,  0.2970,  0.2073, -0.5291,  0.2877],\n",
      "        [ 0.1163,  0.0538,  0.1505, -0.1225,  0.1163],\n",
      "        [-0.0619, -0.3298,  0.3806, -0.5174,  0.5331],\n",
      "        [ 0.0347, -0.0167,  0.5104,  0.3475, -0.1971],\n",
      "        [ 0.3520, -0.3127, -0.0768, -0.2097, -0.5082],\n",
      "        [-0.2051,  0.5311,  0.1725,  0.4914,  0.0546]], requires_grad=True)\n",
      "modelA ffn weight 6: Parameter containing:\n",
      "tensor([[-4.4601e-01, -3.9375e-01, -2.5718e-01,  9.5904e-02,  4.2461e-01,\n",
      "          7.5230e-02, -4.2770e-01,  4.8205e-02, -3.0940e-01, -1.5890e-01],\n",
      "        [ 9.2162e-02,  1.8397e-01,  5.7924e-01, -3.3390e-01,  7.7437e-02,\n",
      "          2.3952e-01,  3.3968e-01, -3.7450e-01, -5.7302e-02,  2.3725e-01],\n",
      "        [ 1.4010e-01,  2.8332e-01,  3.3553e-01,  7.3965e-02, -2.7644e-01,\n",
      "          1.0274e-01,  2.4357e-01, -1.8894e-01,  6.7558e-02,  1.5406e-01],\n",
      "        [ 2.0449e-01,  9.6530e-02,  6.6531e-01, -2.7265e-01, -1.6670e-01,\n",
      "         -5.4766e-01, -7.0225e-02, -4.2273e-01,  9.5939e-02,  1.5166e-01],\n",
      "        [-1.4584e-01,  1.1092e-02, -1.8789e-01,  3.9643e-01,  1.0076e-01,\n",
      "          1.0528e-01, -2.3611e-01, -4.5066e-03, -2.9848e-01, -2.3280e-02],\n",
      "        [ 1.7973e-01,  7.3430e-02, -2.4352e-01, -2.2147e-01,  2.5876e-01,\n",
      "         -2.4515e-01,  9.6071e-02,  1.0347e-01,  3.2997e-01,  5.7871e-03],\n",
      "        [ 6.1348e-02,  6.8287e-02,  1.0416e-01, -2.7675e-02, -1.5630e-02,\n",
      "          2.1393e-01, -2.6224e-02,  3.3410e-01, -5.6138e-01, -6.2200e-02],\n",
      "        [ 4.4669e-01, -1.7143e-01,  5.5316e-01,  7.5722e-02,  6.2590e-04,\n",
      "         -1.3757e-01,  4.2687e-01, -1.6242e-01, -3.7899e-02,  4.4299e-01],\n",
      "        [-1.6022e-01,  5.8442e-03, -2.3478e-01,  4.5048e-01,  2.4468e-01,\n",
      "         -5.8143e-02, -1.8915e-01,  4.4522e-01, -1.0874e-01, -3.1808e-01],\n",
      "        [ 3.0309e-01,  3.1461e-01,  1.5886e-01,  5.3106e-02, -2.5148e-01,\n",
      "          2.5071e-01, -1.1351e-01, -3.5209e-01,  3.7303e-01,  3.4455e-01]],\n",
      "       requires_grad=True)\n",
      "modelB ffn weight 6: Parameter containing:\n",
      "tensor([[ 0.0718,  0.5302, -0.1884, -0.4743, -0.2065,  0.3196, -0.0956, -0.1737,\n",
      "          0.3988, -0.3175],\n",
      "        [ 0.0946,  0.1483, -0.3059, -0.1085, -0.1594, -0.3802, -0.0080, -0.3279,\n",
      "          0.4240,  0.0776],\n",
      "        [-0.2922,  0.1411, -0.3643,  0.2038, -0.5021, -0.1348,  0.1293, -0.3083,\n",
      "         -0.0740,  0.2352],\n",
      "        [ 0.0081, -0.5660, -0.3287,  0.4307,  0.3423, -0.0346,  0.3142,  0.0420,\n",
      "         -0.6643,  0.0583],\n",
      "        [ 0.2031, -0.0311, -0.0086,  0.0522, -0.1510,  0.3382, -0.3238,  0.0950,\n",
      "          0.1998, -0.1800],\n",
      "        [-0.0243, -0.3730, -0.1764, -0.0681, -0.3266, -0.1457,  0.4424, -0.1046,\n",
      "          0.1493, -0.3591],\n",
      "        [ 0.5369,  0.3390,  0.1019,  0.0341,  0.3934,  0.0234, -0.2031,  0.1808,\n",
      "         -0.3341, -0.2896],\n",
      "        [-0.3875, -0.2196, -0.4704,  0.5803, -0.4050, -0.2841,  0.4725, -0.1292,\n",
      "          0.0407,  0.3980],\n",
      "        [-0.0115,  0.1242,  0.0707, -0.1838, -0.3099,  0.0357, -0.2065,  0.0091,\n",
      "          0.1420, -0.1008],\n",
      "        [-0.0778, -0.4722, -0.3061,  0.2909,  0.1047, -0.3681,  0.0843,  0.4199,\n",
      "         -0.5675, -0.0468]], requires_grad=True)\n",
      "loss: 4.513323783874512\n",
      "modelA fc weight 7: Parameter containing:\n",
      "tensor([[-0.1134,  0.3912,  0.4583,  0.6449,  0.0469],\n",
      "        [-0.2151, -0.1249, -0.2395,  0.7927, -0.1676],\n",
      "        [ 0.2363, -0.0479,  0.0367,  0.0356, -0.2296],\n",
      "        [ 0.0978,  0.0951, -0.1657,  1.0486, -0.5037],\n",
      "        [ 0.4653,  0.2719,  0.2177, -0.5600,  0.3207],\n",
      "        [ 0.1404,  0.0261,  0.1794, -0.1180,  0.1496],\n",
      "        [-0.0577, -0.3084,  0.3546, -0.5338,  0.5170],\n",
      "        [ 0.0340, -0.0439,  0.5421,  0.3927, -0.1873],\n",
      "        [ 0.3449, -0.2638, -0.1205, -0.2562, -0.5272],\n",
      "        [-0.1969,  0.5174,  0.1840,  0.5291,  0.0445]], requires_grad=True)\n",
      "modelB fc weight 7: Parameter containing:\n",
      "tensor([[-0.1134,  0.3912,  0.4583,  0.6449,  0.0469],\n",
      "        [-0.2151, -0.1249, -0.2395,  0.7927, -0.1676],\n",
      "        [ 0.2363, -0.0479,  0.0367,  0.0356, -0.2296],\n",
      "        [ 0.0978,  0.0951, -0.1657,  1.0486, -0.5037],\n",
      "        [ 0.4653,  0.2719,  0.2177, -0.5600,  0.3207],\n",
      "        [ 0.1404,  0.0261,  0.1794, -0.1180,  0.1496],\n",
      "        [-0.0577, -0.3084,  0.3546, -0.5338,  0.5170],\n",
      "        [ 0.0340, -0.0439,  0.5421,  0.3927, -0.1873],\n",
      "        [ 0.3449, -0.2638, -0.1205, -0.2562, -0.5272],\n",
      "        [-0.1969,  0.5174,  0.1840,  0.5291,  0.0445]], requires_grad=True)\n",
      "modelA ffn weight 7: Parameter containing:\n",
      "tensor([[-0.4958, -0.4063, -0.2386,  0.0592,  0.3551,  0.1120, -0.3873,  0.0550,\n",
      "         -0.2712, -0.2189],\n",
      "        [ 0.1007,  0.1768,  0.5900, -0.3241,  0.0906,  0.2493,  0.3256, -0.3742,\n",
      "         -0.0594,  0.2471],\n",
      "        [ 0.1558,  0.2923,  0.3485,  0.0892, -0.2805,  0.1215,  0.2257, -0.1784,\n",
      "          0.0569,  0.1689],\n",
      "        [ 0.2468,  0.1373,  0.6884, -0.2635, -0.1389, -0.5701, -0.0808, -0.4365,\n",
      "          0.0736,  0.1938],\n",
      "        [-0.1555,  0.0195, -0.1993,  0.3865,  0.0847,  0.0955, -0.2216, -0.0045,\n",
      "         -0.2951, -0.0346],\n",
      "        [ 0.1971,  0.0792, -0.2640, -0.2139,  0.3072, -0.2729,  0.0907,  0.1014,\n",
      "          0.3100,  0.0304],\n",
      "        [ 0.0334,  0.0873,  0.1343, -0.0556, -0.0734,  0.2594,  0.0037,  0.3371,\n",
      "         -0.5391, -0.1031],\n",
      "        [ 0.4543, -0.1751,  0.5671,  0.0832,  0.0041, -0.1278,  0.4155, -0.1637,\n",
      "         -0.0366,  0.4505],\n",
      "        [-0.1809,  0.0047, -0.2589,  0.4474,  0.2385, -0.0551, -0.1809,  0.4585,\n",
      "         -0.1104, -0.3388],\n",
      "        [ 0.2928,  0.2954,  0.1629,  0.0522, -0.2529,  0.2556, -0.1161, -0.3582,\n",
      "          0.3861,  0.3354]], requires_grad=True)\n",
      "modelB ffn weight 7: Parameter containing:\n",
      "tensor([[ 6.8925e-02,  5.1487e-01, -2.0824e-01, -4.9677e-01, -1.8456e-01,\n",
      "          3.1451e-01, -8.6575e-02, -2.1774e-01,  3.7651e-01, -3.1628e-01],\n",
      "        [ 9.7615e-02,  1.3665e-01, -3.3290e-01, -1.1920e-01, -1.3668e-01,\n",
      "         -3.9387e-01, -7.7620e-03, -3.8514e-01,  3.8935e-01,  9.4773e-02],\n",
      "        [-2.8080e-01,  1.7193e-01, -3.7884e-01,  2.1885e-01, -5.4623e-01,\n",
      "         -1.4449e-01,  1.2344e-01, -3.4077e-01, -3.3982e-02,  2.4006e-01],\n",
      "        [ 1.4263e-02, -5.5700e-01, -3.2147e-01,  4.5980e-01,  3.3206e-01,\n",
      "         -3.7282e-02,  2.9865e-01,  6.1895e-02, -6.7374e-01,  7.6355e-02],\n",
      "        [ 2.0184e-01, -3.6811e-02, -2.5995e-02,  3.0576e-02, -1.4273e-01,\n",
      "          3.3656e-01, -3.1370e-01,  5.3719e-02,  1.9911e-01, -1.8496e-01],\n",
      "        [-1.0971e-02, -3.2525e-01, -1.6797e-01, -6.0789e-02, -3.8252e-01,\n",
      "         -1.6936e-01,  4.3506e-01, -1.0545e-01,  2.2564e-01, -3.6849e-01],\n",
      "        [ 5.3453e-01,  2.9466e-01,  1.1572e-01, -5.0198e-05,  4.6492e-01,\n",
      "          4.3988e-02, -2.0019e-01,  2.0499e-01, -4.0516e-01, -2.9859e-01],\n",
      "        [-3.8985e-01, -1.7767e-01, -4.8079e-01,  6.2071e-01, -4.7744e-01,\n",
      "         -3.0529e-01,  4.7277e-01, -1.2670e-01,  1.2129e-01,  3.8786e-01],\n",
      "        [-1.1880e-02,  1.0832e-01,  4.8076e-02, -2.0467e-01, -2.8661e-01,\n",
      "          3.4370e-02, -1.9906e-01, -3.9616e-02,  1.1879e-01, -9.6336e-02],\n",
      "        [-7.7173e-02, -4.6368e-01, -2.8883e-01,  3.1232e-01,  9.1714e-02,\n",
      "         -3.6732e-01,  7.5490e-02,  4.6327e-01, -5.5936e-01, -4.4974e-02]],\n",
      "       requires_grad=True)\n",
      "loss: 4.593624114990234\n",
      "modelA fc weight 8: Parameter containing:\n",
      "tensor([[-1.1659e-01,  3.7909e-01,  4.6720e-01,  6.1169e-01,  6.0059e-02],\n",
      "        [-2.3504e-01, -1.2708e-01, -2.3404e-01,  7.7005e-01, -1.6248e-01],\n",
      "        [ 2.3992e-01, -5.5439e-02,  4.1889e-02,  1.7561e-02, -2.2515e-01],\n",
      "        [ 1.0628e-01,  6.7610e-02, -1.3368e-01,  1.1259e+00, -5.0124e-01],\n",
      "        [ 4.3837e-01,  2.4449e-01,  2.3192e-01, -5.8461e-01,  3.3586e-01],\n",
      "        [ 1.3417e-01, -3.1270e-05,  2.0690e-01, -1.1248e-01,  1.6662e-01],\n",
      "        [-3.1396e-02, -2.8833e-01,  3.3022e-01, -5.5013e-01,  5.1432e-01],\n",
      "        [ 2.0708e-02, -6.4318e-02,  5.6798e-01,  4.3437e-01, -1.8802e-01],\n",
      "        [ 3.5854e-01, -2.2678e-01, -1.5535e-01, -2.9997e-01, -5.2736e-01],\n",
      "        [-1.7065e-01,  5.0031e-01,  1.9752e-01,  5.5783e-01,  4.9514e-02]],\n",
      "       requires_grad=True)\n",
      "modelB fc weight 8: Parameter containing:\n",
      "tensor([[-1.1659e-01,  3.7909e-01,  4.6720e-01,  6.1169e-01,  6.0059e-02],\n",
      "        [-2.3504e-01, -1.2708e-01, -2.3404e-01,  7.7005e-01, -1.6248e-01],\n",
      "        [ 2.3992e-01, -5.5439e-02,  4.1889e-02,  1.7561e-02, -2.2515e-01],\n",
      "        [ 1.0628e-01,  6.7610e-02, -1.3368e-01,  1.1259e+00, -5.0124e-01],\n",
      "        [ 4.3837e-01,  2.4449e-01,  2.3192e-01, -5.8461e-01,  3.3586e-01],\n",
      "        [ 1.3417e-01, -3.1270e-05,  2.0690e-01, -1.1248e-01,  1.6662e-01],\n",
      "        [-3.1396e-02, -2.8833e-01,  3.3022e-01, -5.5013e-01,  5.1432e-01],\n",
      "        [ 2.0708e-02, -6.4318e-02,  5.6798e-01,  4.3437e-01, -1.8802e-01],\n",
      "        [ 3.5854e-01, -2.2678e-01, -1.5535e-01, -2.9997e-01, -5.2736e-01],\n",
      "        [-1.7065e-01,  5.0031e-01,  1.9752e-01,  5.5783e-01,  4.9514e-02]],\n",
      "       requires_grad=True)\n",
      "modelA ffn weight 8: Parameter containing:\n",
      "tensor([[-0.5220, -0.3818, -0.2580,  0.0551,  0.2947,  0.1052, -0.3799,  0.0793,\n",
      "         -0.2478, -0.2583],\n",
      "        [ 0.1034,  0.1619,  0.6143, -0.3218,  0.1017,  0.2734,  0.3193, -0.3819,\n",
      "         -0.0587,  0.2518],\n",
      "        [ 0.1692,  0.2995,  0.3622,  0.1022, -0.2842,  0.1395,  0.2105, -0.1698,\n",
      "          0.0477,  0.1816],\n",
      "        [ 0.2816,  0.1650,  0.7193, -0.2608, -0.1145, -0.5822, -0.0847, -0.4524,\n",
      "          0.0553,  0.2291],\n",
      "        [-0.1584,  0.0364, -0.2249,  0.3849,  0.0710,  0.0696, -0.2157,  0.0045,\n",
      "         -0.2951, -0.0400],\n",
      "        [ 0.2059,  0.0721, -0.2555, -0.2164,  0.3495, -0.2734,  0.0945,  0.0885,\n",
      "          0.2959,  0.0467],\n",
      "        [ 0.0335,  0.1341,  0.1209, -0.0519, -0.1235,  0.2437,  0.0024,  0.3669,\n",
      "         -0.5303, -0.1218],\n",
      "        [ 0.4583, -0.1834,  0.5893,  0.0861,  0.0068, -0.1098,  0.4089, -0.1695,\n",
      "         -0.0339,  0.4547],\n",
      "        [-0.1967,  0.0081, -0.2870,  0.4481,  0.2333, -0.0594, -0.1768,  0.4735,\n",
      "         -0.1134, -0.3551],\n",
      "        [ 0.2821,  0.2752,  0.1725,  0.0493, -0.2542,  0.2663, -0.1164, -0.3665,\n",
      "          0.3983,  0.3261]], requires_grad=True)\n",
      "modelB ffn weight 8: Parameter containing:\n",
      "tensor([[ 6.6444e-02,  5.0336e-01, -2.2600e-01, -5.1737e-01, -1.6924e-01,\n",
      "          3.0988e-01, -7.8621e-02, -2.5662e-01,  3.5739e-01, -3.1542e-01],\n",
      "        [ 1.0056e-01,  1.3124e-01, -3.5720e-01, -1.3051e-01, -1.2765e-01,\n",
      "         -4.0638e-01, -7.5921e-03, -4.3543e-01,  3.6009e-01,  1.0958e-01],\n",
      "        [-2.7116e-01,  1.9106e-01, -3.9128e-01,  2.3665e-01, -5.6404e-01,\n",
      "         -1.5259e-01,  1.1832e-01, -3.7054e-01, -4.2504e-04,  2.4651e-01],\n",
      "        [ 1.9953e-02, -5.4505e-01, -3.1521e-01,  4.8449e-01,  3.1565e-01,\n",
      "         -3.9844e-02,  2.8481e-01,  8.0063e-02, -6.8081e-01,  9.2014e-02],\n",
      "        [ 2.0106e-01, -3.5493e-02, -4.1857e-02,  9.4108e-03, -1.4819e-01,\n",
      "          3.3463e-01, -3.0475e-01,  1.7865e-02,  2.0025e-01, -1.9004e-01],\n",
      "        [-1.9401e-03, -3.1908e-01, -1.5744e-01, -3.8067e-02, -3.6703e-01,\n",
      "         -1.8577e-01,  4.2889e-01, -1.1482e-01,  2.7974e-01, -3.7059e-01],\n",
      "        [ 5.3375e-01,  2.8195e-01,  1.2716e-01, -4.4221e-02,  4.6538e-01,\n",
      "          6.1444e-02, -1.9784e-01,  2.2938e-01, -4.5931e-01, -3.1271e-01],\n",
      "        [-3.9332e-01, -1.6526e-01, -4.8915e-01,  6.7056e-01, -4.8124e-01,\n",
      "         -3.2322e-01,  4.7320e-01, -1.2744e-01,  1.8416e-01,  3.8350e-01],\n",
      "        [-1.1619e-02,  1.0601e-01,  2.7186e-02, -2.2737e-01, -2.9063e-01,\n",
      "          3.2221e-02, -1.9252e-01, -8.1310e-02,  1.0164e-01, -9.3647e-02],\n",
      "        [-7.7017e-02, -4.6326e-01, -2.7310e-01,  3.3362e-01,  9.4612e-02,\n",
      "         -3.6608e-01,  6.7732e-02,  5.0085e-01, -5.5416e-01, -4.2647e-02]],\n",
      "       requires_grad=True)\n",
      "loss: 4.490304946899414\n",
      "modelA fc weight 9: Parameter containing:\n",
      "tensor([[-0.1342,  0.3544,  0.4891,  0.6096,  0.0671],\n",
      "        [-0.2661, -0.1338, -0.2242,  0.7574, -0.1656],\n",
      "        [ 0.2351, -0.0761,  0.0600,  0.0299, -0.2227],\n",
      "        [ 0.1202,  0.0519, -0.1133,  1.1712, -0.4971],\n",
      "        [ 0.3970,  0.2177,  0.2481, -0.5984,  0.3336],\n",
      "        [ 0.1134, -0.0233,  0.2322, -0.1061,  0.1713],\n",
      "        [ 0.0050, -0.2723,  0.3091, -0.5634,  0.5213],\n",
      "        [ 0.0036, -0.0762,  0.5861,  0.4602, -0.1933],\n",
      "        [ 0.3835, -0.2018, -0.1804, -0.3270, -0.5168],\n",
      "        [-0.1417,  0.4757,  0.2186,  0.6050,  0.0596]], requires_grad=True)\n",
      "modelB fc weight 9: Parameter containing:\n",
      "tensor([[-0.1342,  0.3544,  0.4891,  0.6096,  0.0671],\n",
      "        [-0.2661, -0.1338, -0.2242,  0.7574, -0.1656],\n",
      "        [ 0.2351, -0.0761,  0.0600,  0.0299, -0.2227],\n",
      "        [ 0.1202,  0.0519, -0.1133,  1.1712, -0.4971],\n",
      "        [ 0.3970,  0.2177,  0.2481, -0.5984,  0.3336],\n",
      "        [ 0.1134, -0.0233,  0.2322, -0.1061,  0.1713],\n",
      "        [ 0.0050, -0.2723,  0.3091, -0.5634,  0.5213],\n",
      "        [ 0.0036, -0.0762,  0.5861,  0.4602, -0.1933],\n",
      "        [ 0.3835, -0.2018, -0.1804, -0.3270, -0.5168],\n",
      "        [-0.1417,  0.4757,  0.2186,  0.6050,  0.0596]], requires_grad=True)\n",
      "modelA ffn weight 9: Parameter containing:\n",
      "tensor([[-0.5378, -0.3788, -0.2881,  0.0530,  0.2696,  0.0886, -0.3851,  0.0946,\n",
      "         -0.2344, -0.2798],\n",
      "        [ 0.1033,  0.1541,  0.6430, -0.3203,  0.1005,  0.3009,  0.3169, -0.3857,\n",
      "         -0.0558,  0.2512],\n",
      "        [ 0.1809,  0.3064,  0.3756,  0.1137, -0.2895,  0.1563,  0.1972, -0.1618,\n",
      "          0.0398,  0.1924],\n",
      "        [ 0.3117,  0.1934,  0.7509, -0.2587, -0.0986, -0.5907, -0.0860, -0.4655,\n",
      "          0.0400,  0.2587],\n",
      "        [-0.1582,  0.0455, -0.2548,  0.3840,  0.0709,  0.0401, -0.2140,  0.0092,\n",
      "         -0.2975, -0.0395],\n",
      "        [ 0.2108,  0.0727, -0.2375, -0.2192,  0.3699, -0.2664,  0.1022,  0.0807,\n",
      "          0.2861,  0.0555],\n",
      "        [ 0.0440,  0.1538,  0.0954, -0.0471, -0.1411,  0.2169, -0.0107,  0.3838,\n",
      "         -0.5305, -0.1215],\n",
      "        [ 0.4603, -0.1874,  0.6142,  0.0884,  0.0017, -0.0900,  0.4051, -0.1728,\n",
      "         -0.0301,  0.4555],\n",
      "        [-0.2095,  0.0082, -0.3155,  0.4489,  0.2361, -0.0660, -0.1750,  0.4856,\n",
      "         -0.1174, -0.3671],\n",
      "        [ 0.2715,  0.2602,  0.1853,  0.0465, -0.2598,  0.2796, -0.1149, -0.3723,\n",
      "          0.4102,  0.3159]], requires_grad=True)\n",
      "modelB ffn weight 9: Parameter containing:\n",
      "tensor([[ 0.0641,  0.4925, -0.2420, -0.5357, -0.1546,  0.3057, -0.0714, -0.2913,\n",
      "          0.3400, -0.3147],\n",
      "        [ 0.1040,  0.1300, -0.3783, -0.1409, -0.1257, -0.4175, -0.0084, -0.4803,\n",
      "          0.3358,  0.1230],\n",
      "        [-0.2645,  0.2000, -0.4036,  0.2535, -0.5654, -0.1600,  0.1170, -0.3972,\n",
      "          0.0262,  0.2507],\n",
      "        [ 0.0269, -0.5250, -0.3086,  0.5060,  0.2883, -0.0420,  0.2703,  0.0963,\n",
      "         -0.6821,  0.1066],\n",
      "        [ 0.2020, -0.0267, -0.0549, -0.0100, -0.1643,  0.3331, -0.2987, -0.0141,\n",
      "          0.2048, -0.1940],\n",
      "        [-0.0112, -0.3476, -0.1593, -0.0127, -0.3227, -0.2024,  0.4423, -0.1239,\n",
      "          0.2957, -0.3790],\n",
      "        [ 0.5415,  0.3004,  0.1403, -0.0882,  0.4327,  0.0774, -0.2084,  0.2514,\n",
      "         -0.4857, -0.3188],\n",
      "        [-0.4031, -0.1770, -0.4989,  0.7186, -0.4568, -0.3395,  0.4829, -0.1283,\n",
      "          0.2242,  0.3760],\n",
      "        [-0.0076,  0.1193,  0.0114, -0.2489, -0.3156,  0.0307, -0.1913, -0.1184,\n",
      "          0.0943, -0.0900],\n",
      "        [-0.0787, -0.4713, -0.2603,  0.3532,  0.1097, -0.3651,  0.0630,  0.5343,\n",
      "         -0.5535, -0.0412]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(5, 5)\n",
    "print(f\"orginal tensor: {test}\")\n",
    "\n",
    "modelA = SimpleModelA()\n",
    "modelB = SimpleModelB()\n",
    "criterion = nn.MSELoss()\n",
    "label = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "\n",
    "optimizerA = torch.optim.Adam(\n",
    "    list(modelA.parameters()) + list(modelB.parameters()), \n",
    "    lr=0.1\n",
    ")\n",
    "\n",
    "_set_param(modelB.fc, \"weight\", modelA.fc.weight)\n",
    "\n",
    "print(f\"modelA fc weight init: {modelA.fc.weight}\")\n",
    "print(f\"modelB fc weight init: {modelB.fc.weight}\")\n",
    "\n",
    "for i in range(10):\n",
    "    optimizerA.zero_grad()\n",
    "    outputA = modelA(test)\n",
    "    outputB = modelB(test)\n",
    "    \n",
    "    lossA = criterion(outputA, label)\n",
    "    lossB = criterion(outputB, label)\n",
    "    \n",
    "    loss = lossA + lossB\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizerA.step()\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(f\"modelA fc weight {i}: {modelA.fc.weight}\")\n",
    "    print(f\"modelB fc weight {i}: {modelB.fc.weight}\")\n",
    "    print(f\"modelA ffn weight {i}: {modelA.ffn[0].weight}\")\n",
    "    print(f\"modelB ffn weight {i}: {modelB.ffn[0].weight}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T14:17:47.138267430Z",
     "start_time": "2024-01-11T14:17:47.108232056Z"
    }
   },
   "id": "f88d053a7e2caded",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7edb755c51390e5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" 인스턴스 상태로 임베딩 셰어링 하는 것과 개별 가중치 매트릭스 단위로 접근해서 셰여링 하는게 좋은지 \"\"\"\n",
    "\n",
    "\n",
    "class GeneratorEmbedding(nn.Module):\n",
    "    \"\"\" BERT Embedding Module class\n",
    "    This module has option => whether or not to use ALBERT Style Factorized Embedding\n",
    "    This Module set & initialize 3 Embedding Layers:\n",
    "        1) Word Embedding 2) Absolute Positional Embedding\n",
    "    Args:\n",
    "        cfg: configuration.py\n",
    "    Notes:\n",
    "        Absolute Positional Embedding added at bottom layers\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: CFG) -> None:\n",
    "        super(GeneratorEmbedding, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.max_seq = cfg.max_seq\n",
    "        self.word_embedding = nn.Embedding(len(cfg.tokenizer), cfg.dim_model)\n",
    "        self.abs_pos_emb = nn.Embedding(cfg.max_seq, cfg.dim_model)  # Absolute Position Embedding for EMD Layer\n",
    "        self.layer_norm1 = nn.LayerNorm(cfg.dim_model, eps=cfg.layer_norm_eps)  # for word embedding\n",
    "        self.layer_norm2 = nn.LayerNorm(cfg.dim_model, eps=cfg.layer_norm_eps)  # for word embedding\n",
    "        self.hidden_dropout = nn.Dropout(p=cfg.hidden_dropout_prob)\n",
    "\n",
    "        # ALBERT Style Factorized Embedding\n",
    "        if self.cfg.is_mf_embedding:\n",
    "            self.word_embedding = nn.Embedding(len(cfg.tokenizer), int(cfg.dim_model/6))\n",
    "            self.projector = nn.Linear(int(cfg.dim_model/6), cfg.dim_model)  # project to original hidden dim\n",
    "\n",
    "    def forward(self, inputs: Tensor) -> Tuple[nn.Embedding, nn.Embedding]:\n",
    "        if self.cfg.is_mf_embedding:\n",
    "            word_embeddings = self.hidden_dropout(\n",
    "                self.layer_norm1(self.projector(self.word_embedding(inputs)))\n",
    "            )\n",
    "        else:\n",
    "            word_embeddings = self.hidden_dropout(\n",
    "                self.layer_norm1(self.word_embedding(inputs))\n",
    "            )\n",
    "        abs_pos_emb = self.hidden_dropout(\n",
    "            self.layer_norm2(self.abs_pos_emb(torch.arange(inputs.shape[1], device=\"cuda\").repeat(inputs.shape[0]).view(inputs.shape[0], -1)))\n",
    "        )\n",
    "        return word_embeddings, abs_pos_emb\n",
    "    \n",
    "class DiscriminatorEmbedding(nn.Module):\n",
    "    \"\"\" BERT Embedding Module class\n",
    "    This module has option => whether or not to use ALBERT Style Factorized Embedding\n",
    "    This Module set & initialize 3 Embedding Layers:\n",
    "        1) Word Embedding 2) Absolute Positional Embedding\n",
    "    Args:\n",
    "        cfg: configuration.py\n",
    "    Notes:\n",
    "        Absolute Positional Embedding added at bottom layers\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: CFG) -> None:\n",
    "        super(DiscriminatorEmbedding, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.max_seq = cfg.max_seq\n",
    "        self.word_embedding = nn.Embedding(len(cfg.tokenizer), 1024)\n",
    "        self.abs_pos_emb = nn.Embedding(cfg.max_seq, 1024)  # Absolute Position Embedding for EMD Layer\n",
    "        self.layer_norm1 = nn.LayerNorm(cfg.dim_model, eps=1e-9)  # for word embedding\n",
    "        self.layer_norm2 = nn.LayerNorm(cfg.dim_model, eps=1e-9)  # for word embedding\n",
    "        self.hidden_dropout = nn.Dropout(p=cfg.hidden_dropout_prob)\n",
    "\n",
    "        # ALBERT Style Factorized Embedding\n",
    "        if self.cfg.is_mf_embedding:\n",
    "            self.word_embedding = nn.Embedding(len(cfg.tokenizer), int(cfg.dim_model/6))\n",
    "            self.projector = nn.Linear(int(cfg.dim_model/6), cfg.dim_model)  # project to original hidden dim\n",
    "\n",
    "    def forward(self, inputs: Tensor) -> Tuple[nn.Embedding, nn.Embedding]:\n",
    "        if self.cfg.is_mf_embedding:\n",
    "            word_embeddings = self.hidden_dropout(\n",
    "                self.layer_norm1(self.projector(self.word_embedding(inputs)))\n",
    "            )\n",
    "        else:\n",
    "            word_embeddings = self.hidden_dropout(\n",
    "                self.layer_norm1(self.word_embedding(inputs))\n",
    "            )\n",
    "        abs_pos_emb = self.hidden_dropout(\n",
    "            self.layer_norm2(self.abs_pos_emb(torch.arange(inputs.shape[1], device=\"cuda\").repeat(inputs.shape[0]).view(inputs.shape[0], -1)))\n",
    "        )\n",
    "        return word_embeddings, abs_pos_emb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d314e9b16b92c2",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generator = GeneratorEmbedding(CFG)\n",
    "discriminator = DiscriminatorEmbedding(CFG)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86c70ba065cddf4b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(GeneratorEmbedding(\n   (word_embedding): Embedding(128001, 768)\n   (abs_pos_emb): Embedding(512, 768)\n   (layer_norm1): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n   (layer_norm2): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n   (hidden_dropout): Dropout(p=0.1, inplace=False)\n ),\n DiscriminatorEmbedding(\n   (word_embedding): Embedding(128001, 1024)\n   (abs_pos_emb): Embedding(512, 1024)\n   (layer_norm1): LayerNorm((768,), eps=1e-09, elementwise_affine=True)\n   (layer_norm2): LayerNorm((768,), eps=1e-09, elementwise_affine=True)\n   (hidden_dropout): Dropout(p=0.1, inplace=False)\n ))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator, discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:53:13.117428Z",
     "start_time": "2024-01-10T07:53:13.113247Z"
    }
   },
   "id": "692738750e576838"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "GeneratorEmbedding(\n  (word_embedding): Embedding(128001, 768)\n  (abs_pos_emb): Embedding(512, 768)\n  (layer_norm1): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n  (layer_norm2): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n  (hidden_dropout): Dropout(p=0.1, inplace=False)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 인스턴스 자체를 공유하는 경우, 해당 인스턴 내부에 포함된 다른 모듈 정보도 복사,\n",
    "이것을 원치 않는다면 임베딩 관련 attr만 찍어서 셰어링 할 것\n",
    "\"\"\"\n",
    "\n",
    "discriminator = generator\n",
    "discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:52:53.430582Z",
     "start_time": "2024-01-10T07:52:53.426237Z"
    }
   },
   "id": "2f6258b1317f5d3b"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "discriminator.word_embedding.weight = generator.word_embedding.weight\n",
    "discriminator.abs_pos_emb.weight = generator.abs_pos_emb.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T08:00:27.741798Z",
     "start_time": "2024-01-10T08:00:27.738637Z"
    }
   },
   "id": "3532a2a4c87b1f8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[ 2.2952, -1.1103, -0.6854,  ..., -0.4859,  0.7391,  0.0829],\n         [-0.0511,  0.2567,  0.4269,  ...,  0.3777, -0.4286, -1.1887],\n         [ 1.4421,  0.0392,  0.1582,  ..., -0.8192, -0.0563,  0.0259],\n         ...,\n         [-1.1109, -1.9360,  0.7205,  ...,  0.8326,  0.7596, -0.2808],\n         [-0.5263,  1.5916, -1.1737,  ..., -2.0828,  1.2085, -0.7531],\n         [ 0.2427, -1.7848, -1.4473,  ...,  1.2797,  1.2451, -1.5539]],\n        requires_grad=True),\n Parameter containing:\n tensor([[ 2.2952, -1.1103, -0.6854,  ..., -0.4859,  0.7391,  0.0829],\n         [-0.0511,  0.2567,  0.4269,  ...,  0.3777, -0.4286, -1.1887],\n         [ 1.4421,  0.0392,  0.1582,  ..., -0.8192, -0.0563,  0.0259],\n         ...,\n         [-1.1109, -1.9360,  0.7205,  ...,  0.8326,  0.7596, -0.2808],\n         [-0.5263,  1.5916, -1.1737,  ..., -2.0828,  1.2085, -0.7531],\n         [ 0.2427, -1.7848, -1.4473,  ...,  1.2797,  1.2451, -1.5539]],\n        requires_grad=True))"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.word_embedding.weight, discriminator.word_embedding.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T08:00:28.871261Z",
     "start_time": "2024-01-10T08:00:28.867034Z"
    }
   },
   "id": "bdcc42681a72634d"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[-0.1623,  1.3104, -0.6516,  ..., -0.5250, -0.0222, -1.2774],\n         [ 0.3852,  0.7240, -0.7078,  ..., -0.6339,  0.3923, -0.4718],\n         [-0.4134, -0.7664,  1.3895,  ..., -1.0974,  1.5678, -0.4249],\n         ...,\n         [ 0.7117,  1.4549, -0.5336,  ...,  0.1409,  0.2749,  1.7711],\n         [-0.5776, -0.6636,  1.5503,  ..., -1.1855,  0.1657,  0.4000],\n         [ 1.3280, -1.6936, -1.2606,  ..., -0.4680,  0.9651, -0.9574]],\n        requires_grad=True),\n Parameter containing:\n tensor([[-0.1623,  1.3104, -0.6516,  ..., -0.5250, -0.0222, -1.2774],\n         [ 0.3852,  0.7240, -0.7078,  ..., -0.6339,  0.3923, -0.4718],\n         [-0.4134, -0.7664,  1.3895,  ..., -1.0974,  1.5678, -0.4249],\n         ...,\n         [ 0.7117,  1.4549, -0.5336,  ...,  0.1409,  0.2749,  1.7711],\n         [-0.5776, -0.6636,  1.5503,  ..., -1.1855,  0.1657,  0.4000],\n         [ 1.3280, -1.6936, -1.2606,  ..., -0.4680,  0.9651, -0.9574]],\n        requires_grad=True))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.abs_pos_emb.weight, discriminator.abs_pos_emb.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T08:00:29.336231Z",
     "start_time": "2024-01-10T08:00:29.332259Z"
    }
   },
   "id": "f958393868070ec2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[ 0.0128,  0.4399,  0.2408, -0.3927,  0.1460],\n         [-0.0897,  0.1777, -0.0144,  0.2699,  0.3550],\n         [-0.3313, -0.3217,  0.1335,  0.2754, -0.0162],\n         [ 0.1812, -0.0031, -0.0985,  0.0917,  0.4457],\n         [ 0.4281, -0.1821,  0.3798, -0.3857,  0.0316]], requires_grad=True),\n Parameter containing:\n tensor([[ 0.0360, -0.2234, -0.3651, -0.3511, -0.2490],\n         [ 0.2894, -0.3327,  0.2404,  0.3974, -0.3460],\n         [ 0.0452,  0.0221, -0.1934, -0.3077,  0.0728],\n         [ 0.4087,  0.2177, -0.2958, -0.2741, -0.1044],\n         [ 0.0724,  0.2305,  0.1937, -0.0123, -0.2719]], requires_grad=True))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = nn.Linear(5, 5)\n",
    "test2 = nn.Linear(5, 5)\n",
    "\n",
    "test.weight, test2.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:56:17.714137Z",
     "start_time": "2024-01-10T07:56:17.708362Z"
    }
   },
   "id": "415fc9765dd56b43"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.4118, -0.1691,  0.0908, -0.0913,  0.3356],\n        [ 0.2840, -0.2020,  0.3218, -0.1826,  0.3488],\n        [-0.4029,  0.2939, -0.1424,  0.0622,  0.3741],\n        [ 0.1679,  0.1159, -0.0755,  0.2663, -0.2795],\n        [-0.3321,  0.1732,  0.3661,  0.0217,  0.2214]], requires_grad=True)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.weight = test2.weight\n",
    "test.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:55:16.094903Z",
     "start_time": "2024-01-10T07:55:16.077311Z"
    }
   },
   "id": "3c260576288c56a2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\"\"\" to cuda 하기 싫으면 이거 쓰기 \"\"\"\n",
    "\n",
    "test.register_buffer(\"test\", torch.ones(5))\n",
    "test.test.requires_grad = True\n",
    "test.test.requires_grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:57:06.468956Z",
     "start_time": "2024-01-10T07:57:06.454226Z"
    }
   },
   "id": "113b438b81abac0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
