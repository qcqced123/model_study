{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:38:22.771280Z",
     "start_time": "2024-01-05T09:38:17.968295Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/qcqced/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import icecream as ic\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from typing import Dict, List, Tuple, Callable, Any\n",
    "from configuration import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 모듈 이름 추출\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45ad080d044388b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "DeBERTa(\n  (embeddings): Embedding(\n    (word_embedding): Embedding(128001, 128)\n    (rel_pos_emb): Embedding(1024, 768)\n    (abs_pos_emb): Embedding(512, 768)\n    (layer_norm1): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    (layer_norm2): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    (layer_norm3): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    (hidden_dropout): Dropout(p=0.1, inplace=False)\n    (projector): Linear(in_features=128, out_features=768, bias=True)\n  )\n  (encoder): DeBERTaEncoder(\n    (hidden_dropout): Dropout(p=0.1, inplace=False)\n    (layer): ModuleList(\n      (0-11): 12 x DeBERTaEncoderLayer(\n        (self_attention): MultiHeadAttention(\n          (attention_heads): ModuleList(\n            (0-11): 12 x AttentionHead(\n              (attention_dropout): Dropout(p=0.1, inplace=False)\n              (fc_q): Linear(in_features=768, out_features=64, bias=True)\n              (fc_k): Linear(in_features=768, out_features=64, bias=True)\n              (fc_v): Linear(in_features=768, out_features=64, bias=True)\n              (fc_qr): Linear(in_features=768, out_features=64, bias=True)\n              (fc_kr): Linear(in_features=768, out_features=64, bias=True)\n            )\n          )\n          (fc_concat): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (layer_norm1): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n        (layer_norm2): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n        (hidden_dropout): Dropout(p=0.1, inplace=False)\n        (ffn): FeedForward(\n          (ffn): Sequential(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.1, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (layer_norm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n  )\n  (emd_encoder): EnhancedMaskDecoder(\n    (layer_norm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n  )\n)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib.util\n",
    "\n",
    "file_path = 'experiment/models/attention/deberta.py'\n",
    "module_name = 'deberta'\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "YourClass = getattr(module, 'DeBERTa')\n",
    "instance_of_your_class = YourClass(CFG)\n",
    "\n",
    "# 이제 생성한 인스턴스를 사용할 수 있습니다.\n",
    "instance_of_your_class\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:00:55.643637Z",
     "start_time": "2024-01-05T10:00:53.976247Z"
    }
   },
   "id": "563a2d26fca3fb8c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Tokenizer Output: ['trained', 'Ġtrain', 'ĠPret', 'rained', 'ĠPret', 'raining', 'ĠPret', 'rained']\n",
      "\n",
      "Bert Tokenizer in HF Output: ['trained', 'train', 'pre', '##train', '##ed', 'pre', '##train', '##ing', 'pre', '##train', '##ed']\n",
      "\n",
      "Sentencepiece Tokenizer (BPE) Output: ['▁trained', '▁train', '▁Pre', 'trained', '▁Pre', 'training', '▁Pre', 'trained']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\" Huggingface Tokenizer Experiment \"\"\"\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "bpe_tokenizer = AutoTokenizer.from_pretrained('gpt2')  # roberta, gpt2\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # bert\n",
    "sentencepiece_tokenizer = CFG.tokenizer  # deberta, T5\n",
    "\n",
    "text = \"trained train Pretrained Pretraining Pretrained\"\n",
    "print(f'BPE Tokenizer Output: {bpe_tokenizer.tokenize(text)}', end=\"\\n\\n\")\n",
    "print(f'Bert Tokenizer in HF Output: {bert_tokenizer.tokenize(text)}', end=\"\\n\\n\")\n",
    "print(f'Sentencepiece Tokenizer (BPE) Output: {sentencepiece_tokenizer.tokenize(text)}', end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:20:38.006323474Z",
     "start_time": "2024-01-02T09:20:36.666640061Z"
    }
   },
   "id": "c7e65f62f7d6a0b4",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'XLMRobertaTokenizerFast'"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Find tokenizer type in huggingface pretrained tokenizer \"\"\"\n",
    "\n",
    "bpe_tokenizer.__class__.__name__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:20:04.546099915Z",
     "start_time": "2024-01-02T09:20:04.521939394Z"
    }
   },
   "id": "524e610523bc7790",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'spm.model'\n",
    "test[-6:] == '.model'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:55:58.847131806Z",
     "start_time": "2024-01-02T08:55:58.838471859Z"
    }
   },
   "id": "497cb9783a5cba8f",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Helper Function \"\"\"\n",
    "\n",
    "def select_alphanumeric_and_non_english(text: str) -> str:\n",
    "    pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "    result = pattern.sub('', text)\n",
    "    return result\n",
    "\n",
    "def select_tokens(tokens: List[str]) -> List[str]:\n",
    "    selected_tokens = [token for token in tokens if re.match(r'^[\\w\\d\\s]+$', token) and '_' not in token]\n",
    "    return selected_tokens\n",
    "\n",
    "def select_post_string(token: str) -> str:\n",
    "    pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "    flag = False if re.match(pattern, token) else True\n",
    "    return flag\n",
    "\n",
    "def select_src_string(token: str) -> bool:\n",
    "    \"\"\" set flag value for selecting src tokens to mask in sub-word\n",
    "    Args:\n",
    "        token: str, token to check\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    if tokenizer_type == 'SPM':\n",
    "        flag = True if token.startswith(\"▁\") else False\n",
    "\n",
    "    elif tokenizer_type == 'BPE':\n",
    "        flag = True if token.startswith(\"Ġ\") else False\n",
    "\n",
    "    elif tokenizer_type == 'WORDPIECE':\n",
    "        pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "        flag = False if re.match(pattern, token) else True\n",
    "    return flag\n",
    "\n",
    "\n",
    "text = \"_Hello, World! 123 / Example_____ 테스트 文字列\"\n",
    "test = \"나는는\"\n",
    "result = select_alphanumeric_and_non_english(text)\n",
    "print(select_post_string(test))\n",
    "print(select_src_string(test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T11:11:34.876383122Z",
     "start_time": "2024-01-02T11:11:34.872362866Z"
    }
   },
   "id": "b5cfbf1438f64e13"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/qcqced/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[64], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m masked_tokens \u001B[38;5;241m=\u001B[39m DataCollatorForWholeWordMask(tokenizer)([input_tokens])\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Convert masked tokens back to text for visualization\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m masked_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(\u001B[43mmasked_tokens\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Print results\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput Text:\u001B[39m\u001B[38;5;124m\"\u001B[39m, input_text)\n",
      "\u001B[0;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForWholeWordMask\n",
    "import torch\n",
    "\n",
    "# Example input text\n",
    "input_text = \"This is an example sentence for Span Masking algorithm. It is important to keep the token length below 100 for demonstration purposes.\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')\n",
    "\n",
    "# Tokenize input text\n",
    "input_tokens = tokenizer.tokenize(input_text)\n",
    "\n",
    "# Whole Word Masking: Create a list of random labels (1 for [MASK], 0 for others)\n",
    "mask_labels = [1 if token.startswith(\"▁\") else 0 for token in input_tokens]\n",
    "\n",
    "# Whole Word Masking: Apply masking to input tokens\n",
    "input_tokens = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "masked_tokens = DataCollatorForWholeWordMask(tokenizer)([input_tokens], mask_labels=mask_labels)\n",
    "\n",
    "# Convert masked tokens back to text for visualization\n",
    "masked_text = tokenizer.decode(masked_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Input Text:\", input_text)\n",
    "print(\"Masked Text:\", masked_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T16:36:44.754214Z",
     "start_time": "2024-01-01T16:36:42.941551Z"
    }
   },
   "id": "cf7725e28162b34d"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [3], [5, 6], [8, 9], [11, 12], [14, 15], [17, 18], [20, 21], [23, 24], [26, 27], [29, 30], [32, 33], [35, 36], [38, 39], [41, 42], [44, 45], [47, 48], [50, 51], [53, 54], [56, 57], [59, 60], [62, 63], [65, 66], [68, 69], [71, 72], [74, 75], [77, 78], [80, 81], [83, 84, 85], [87, 88], [90, 91], [93, 94], [96, 97], [99, 100], [102, 103], [105, 106], [108, 109], [111, 112], [114, 115], [117, 118], [120, 121], [123, 124], [126, 127], [129, 130], [132, 133], [135, 136], [138, 139], [141, 142], [144, 145], [147, 148], [150, 151], [153, 154], [156, 157], [159, 160], [162, 163], [165, 166], [168, 169], [171, 172], [174, 175], [177, 178], [180, 181], [183, 184]]\n",
      "tensor([[     1,   3266,    300,   2184,    300, 128000, 128000,    302,   3810,\n",
      "          18782,    260,   3810,  16676,    260,   3810,  18782,    260,   3810,\n",
      "          16676,    261,   3810,  18782,    261,   3810,  16676,    261,   3810,\n",
      "          18782,    261,   3810,  16676,    261,   3810,  18782,    261,   3810,\n",
      "          16676,    261,   3810,  18782,    261,   3810,  16676,    300,   3810,\n",
      "         112895,    300,   3810,  16676,    261,   3810,  18782,    261, 128000,\n",
      "          32195,    261,  48120,  93464,    261,   3810,  16676,    261,   3810,\n",
      "          18782,    261, 128000, 128000,    261,   3810,  18782,    261,   3810,\n",
      "          16676,    261,   3810,  18782,    302,   3810,  16676,    302,   3810,\n",
      "          18782,    261,    840,  17108,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261, 128000, 128000,    261, 128000, 128000,    261,\n",
      "           3810,  18782,    260, 128000, 128000,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261, 128000, 128000,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261, 128000, 128000,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261, 128000, 128000,    261,  20634, 128000,    261,\n",
      "         128000,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261,   3810,  18782,    261,\n",
      "         128000, 128000,    261,   3810,  18782,      2]])\n",
      "\n",
      "tensor([[ -100,  -100,  -100,  -100,  -100,  3810, 16676,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  3810, 18782,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  3810, 16676,  -100,  3810, 18782,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  3810, 16676,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  3810, 18782,  -100,  3810, 16676,  -100,  -100,\n",
      "          -100,  -100,  3810, 16676,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  3810, 16676,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  3810, 18782,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  3810, 16676,  -100,  3810,\n",
      "         18782,  -100,  3810, 16676,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          3810, 16676,  -100,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# \"\"\" Test for Whole Word Masking \"\"\"\n",
    "# \n",
    "# mlm_probability = 0.15\n",
    "# # input_tokens = \"\"\"\n",
    "# # trained train Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining trained train Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining trained train Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining Pretrained Pretraining  \n",
    "# # \"\"\"\n",
    "# input_tokens = \"trained! train! Pretrained? Pretraining. Pretrained. Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained! Pretraining! Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining? Pretrained? Pretraining, /Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining\"\n",
    "# \n",
    "# \n",
    "# # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer = CFG.tokenizer\n",
    "# input_tokens = tokenizer(\n",
    "#     input_tokens,\n",
    "# )\n",
    "# input_tokens[\"input_ids\"]\n",
    "# tokenizer_type = 'SPM'\n",
    "# \n",
    "# \n",
    "# def select_post_string(token: str) -> bool:\n",
    "#     \"\"\" set flag value for selecting post tokens to mask in sub-word\n",
    "#     Args:\n",
    "#         token: str, token to check\n",
    "#     \"\"\"\n",
    "#     flag = False\n",
    "#     if tokenizer_type == 'SPM':\n",
    "#         pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "#         flag = False if re.match(pattern, token[0]) else True\n",
    "# \n",
    "#     elif tokenizer_type == 'BPE':\n",
    "#         flag = False if token.startswith(\"Ġ\") else True\n",
    "# \n",
    "#     elif tokenizer_type == 'WORDPIECE':\n",
    "#         flag = True if token.startswith(\"##\") else False\n",
    "# \n",
    "#     return flag\n",
    "# \n",
    "# def select_src_string(token: str) -> bool:\n",
    "#     \"\"\" set flag value for selecting src tokens to mask in sub-word\n",
    "#     Args:\n",
    "#         token: str, token to check\n",
    "#     \"\"\"\n",
    "#     flag = False\n",
    "#     if tokenizer_type == 'SPM':\n",
    "#         flag = True if token.startswith(\"▁\") else False\n",
    "# \n",
    "#     elif tokenizer_type == 'BPE':\n",
    "#         flag = True if token.startswith(\"Ġ\") else False\n",
    "# \n",
    "#     elif tokenizer_type == 'WORDPIECE':\n",
    "#         pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "#         flag = False if re.match(pattern, token) else True\n",
    "#     return flag\n",
    "# \n",
    "# \n",
    "# def get_padding_mask(input_id: Tensor) -> Tensor:\n",
    "#     return torch.zeros(input_id.shape).bool()\n",
    "# \n",
    "# \n",
    "# def _whole_word_mask(\n",
    "#         input_tokens: List[str],\n",
    "#         max_predictions: int = CFG.max_seq\n",
    "# ) -> List[int]:\n",
    "#     \"\"\" \n",
    "#     1) split input_tokens by space into single token\n",
    "#     2) check if token is src token or post token\n",
    "#         - if cand_indexes not empty and token is post token, append index to cand_indexes\n",
    "#         - if token is src token, append index list to cand_indexes\n",
    "#     \"\"\"\n",
    "#     cand_indexes = []\n",
    "#     for i, token in enumerate(input_tokens):\n",
    "#         if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "#             continue\n",
    "#         if len(cand_indexes) >= 1 and select_post_string(token): \n",
    "#             cand_indexes[-1].append(i)\n",
    "#         elif select_src_string(token):\n",
    "#             cand_indexes.append([i])\n",
    "#     print(cand_indexes)  # 여기서부터 변형해서 만들면 되겠다.\n",
    "#     random.shuffle(cand_indexes)  # shuffle cand_indexes list\n",
    "#     num_to_predict = min(max_predictions, max(1, int(round(len(input_tokens) * mlm_probability))))\n",
    "#     masked_lms = []\n",
    "#     covered_indexes = set()\n",
    "#     for index_set in cand_indexes:\n",
    "#         if len(masked_lms) >= num_to_predict:\n",
    "#             break\n",
    "#         if len(masked_lms) + len(index_set) > num_to_predict:\n",
    "#             continue\n",
    "#         is_any_index_covered = False\n",
    "#         for index in index_set:\n",
    "#             if index in covered_indexes:\n",
    "#                 is_any_index_covered = True\n",
    "#                 break\n",
    "#         if is_any_index_covered:\n",
    "#             continue\n",
    "#         for index in index_set:\n",
    "#             covered_indexes.add(index)\n",
    "#             masked_lms.append(index)\n",
    "# \n",
    "#     if len(covered_indexes) != len(masked_lms):\n",
    "#         raise ValueError(\"Length of covered_indexes is not equal to length of masked_lms.\")\n",
    "#     mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\n",
    "#     return mask_labels\n",
    "# \n",
    "# def get_mask_tokens(inputs, mask_labels):\n",
    "#     \"\"\" Prepare masked tokens inputs/labels for masked language modeling(15%):\n",
    "#     80% MASK, 10% random, 10% original. Set 'mask_labels' means we use whole word mask (wwm), we directly mask idxs according to it's ref\n",
    "#     \"\"\"\n",
    "#     labels = inputs.clone()\n",
    "#     probability_matrix = mask_labels\n",
    "# \n",
    "#     special_tokens_mask = [\n",
    "#         tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "#     ]\n",
    "#     probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "#     if tokenizer.pad_token is not None:\n",
    "#         padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "#         probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "# \n",
    "#     masked_indices = probability_matrix.bool()\n",
    "#     labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "# \n",
    "#     # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "#     indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "#     inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "# \n",
    "#     # 10% of the time, we replace masked input tokens with random word\n",
    "#     indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "#     random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "#     inputs[indices_random] = random_words[indices_random]\n",
    "# \n",
    "#     # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "#     return inputs, labels\n",
    "# \n",
    "# def testing(batched):\n",
    "#     \"\"\" Masking for MLM with whole-word tokenizing \"\"\"\n",
    "#     batched = batched[\"input_ids\"]\n",
    "#     input_ids = [torch.tensor(batched)]\n",
    "#     padding_mask = [get_padding_mask(x) for x in input_ids]\n",
    "#     padding_mask = pad_sequence(padding_mask, batch_first=True, padding_value=True)\n",
    "#     input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "# \n",
    "#     mask_labels = []\n",
    "#     ref_tokens = []\n",
    "#     for input_id in batched:\n",
    "#         token = tokenizer._convert_id_to_token(input_id)\n",
    "#         ref_tokens.append(token)\n",
    "#     mask_labels.append(_whole_word_mask(ref_tokens))\n",
    "# \n",
    "#     mask_labels = [torch.tensor(x) for x in mask_labels]\n",
    "#     mask_labels = pad_sequence(mask_labels, batch_first=True, padding_value=0)\n",
    "#     inputs, labels = get_mask_tokens(\n",
    "#         input_ids,\n",
    "#         mask_labels\n",
    "#     )\n",
    "#     return inputs, labels\n",
    "# \n",
    "# inputs, labels = testing(input_tokens)\n",
    "# print(inputs, end=\"\\n\\n\")\n",
    "# print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T16:31:59.267631Z",
     "start_time": "2024-01-02T16:31:59.262276Z"
    }
   },
   "id": "b68423c9f9b82f9f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     1,   3266,    300,   2184,    300,   3810,  16676,    302, 128000,\n",
      "         128000, 128000, 128000, 128000, 128000, 128000, 128000, 128000, 128000,\n",
      "         128000, 128000,   3810,  18782,    261,   3810,  16676,    261,   3810,\n",
      "          18782,    261,   3810,  16676,    261,   3810,  18782,    261,   3810,\n",
      "          16676,    261,   3810,  18782,    261,   3810,  16676,    300,   3810,\n",
      "          18782,    300,   3810,  16676,    261,   3810,  18782,    261,   3810,\n",
      "          16676,    261,   3810,  18782,    261,   3810,  16676,    261,   3810,\n",
      "          18782,    261,   3810,  16676,    261,   3810,  18782,    261,   3810,\n",
      "          16676,    261, 128000, 128000,    302,   3810,  16676,    302,   3810,\n",
      "          18782,    261,    840,  17108,  16676,    261, 128000, 128000, 128000,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    260,   3810,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261, 128000, 128000, 128000, 128000, 128000, 128000,\n",
      "         128000, 128000, 128000, 128000,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,    261,   3810,  16676,    261,\n",
      "           3810,  18782,    261,   3810,  16676,    261,   3810,  18782,    261,\n",
      "           3810,  16676,    261,   3810,  18782,      2]])\n",
      "\n",
      "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  3810, 18782,\n",
      "           260,  3810, 16676,   260,  3810, 18782,   260,  3810, 16676,   261,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  3810, 18782,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  3810, 18782,   261,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  3810, 16676,\n",
      "           261,  3810, 18782,   261,  3810, 16676,   261,  3810,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test for Span Masking Algorithm \"\"\"\n",
    "\n",
    "input_tokens = \"trained! train! Pretrained? Pretraining. Pretrained. Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained! Pretraining! Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining? Pretrained? Pretraining, /Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining\"\n",
    "\n",
    "mlm_probability = 0.15\n",
    "masking_budget = 0.15\n",
    "span_probability = 0.2\n",
    "max_span_length = 10\n",
    "\n",
    "tokenizer = CFG.tokenizer\n",
    "input_tokens = tokenizer(\n",
    "    input_tokens,\n",
    ")\n",
    "input_tokens[\"input_ids\"]\n",
    "tokenizer_type = 'SPM'\n",
    "\n",
    "\n",
    "def random_non_negative_integer(max_value: int):\n",
    "    return random.randint(0, max_value)\n",
    "\n",
    "\n",
    "def select_post_string(token: str) -> bool:\n",
    "    \"\"\" set flag value for selecting post tokens to mask in sub-word\n",
    "    Args:\n",
    "        token: str, token to check\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    if tokenizer_type == 'SPM':\n",
    "        pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "        flag = False if re.match(pattern, token[0]) else True\n",
    "\n",
    "    elif tokenizer_type == 'BPE':\n",
    "        flag = False if token.startswith(\"Ġ\") else True\n",
    "\n",
    "    elif tokenizer_type == 'WORDPIECE':\n",
    "        flag = True if token.startswith(\"##\") else False\n",
    "\n",
    "    return flag\n",
    "\n",
    "def select_src_string(token: str) -> bool:\n",
    "    \"\"\" set flag value for selecting src tokens to mask in sub-word\n",
    "    Args:\n",
    "        token: str, token to check\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    if tokenizer_type == 'SPM':\n",
    "        flag = True if token.startswith(\"▁\") else False\n",
    "\n",
    "    elif tokenizer_type == 'BPE':\n",
    "        flag = True if token.startswith(\"Ġ\") else False\n",
    "\n",
    "    elif tokenizer_type == 'WORDPIECE':\n",
    "        pattern = re.compile(r'[^\\w\\d\\s]|_')\n",
    "        flag = False if re.match(pattern, token) else True\n",
    "    return flag\n",
    "\n",
    "\n",
    "def get_padding_mask(input_id: Tensor) -> Tensor:\n",
    "    return torch.zeros(input_id.shape).bool()\n",
    "\n",
    "\n",
    "def _whole_word_mask(\n",
    "        input_tokens: List[str],\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    0) apply Whole Word Masking Algorithm for make gathering original token index in natural language \n",
    "    1) calculate number of convert into masking tokens with masking budget*len(input_tokens)\n",
    "    2) define span length of this iteration\n",
    "        - span length follow geometric distribution\n",
    "        - span length is limited by max_span_length\n",
    "    \"\"\"\n",
    "    cand_indexes = []\n",
    "    for i, token in enumerate(input_tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if len(cand_indexes) >= 1 and select_post_string(token): \n",
    "            cand_indexes[-1].append(i)\n",
    "        elif select_src_string(token):\n",
    "            cand_indexes.append([i])\n",
    "    \n",
    "    l = len(input_tokens)\n",
    "    src_l = len(cand_indexes)\n",
    "    num_convert_tokens = int(masking_budget * l)  # 27\n",
    "    budget = num_convert_tokens  # int is immutable object, so not need to copy manually \n",
    "    masked_lms = []\n",
    "    covered_indexes = set()\n",
    "    while budget:\n",
    "        span_length = max(1, min(10, int(torch.distributions.Geometric(probs=span_probability).sample())))\n",
    "        src_index = random_non_negative_integer(src_l-1)\n",
    "        if span_length > budget:\n",
    "            if budget < 5:  # 남은 예산이 너무 적은 경우 수많은 Iteration 발생을 막기 위해서 스팬 길이를 budget으로 설정\n",
    "                span_length = budget\n",
    "            else:\n",
    "                continue \n",
    "        if cand_indexes[src_index][0] + span_length > l-1:  # 스팬의 마지막 토큰의 인덱스가 시퀀스 범위를 벗어나는 경우\n",
    "            continue\n",
    "        if len(cand_indexes[src_index]) > span_length:  # 처음부터 형태소를 마스킹하게 되는 경우\n",
    "            continue\n",
    "        span_token_index = cand_indexes[src_index][0]  # init span token index: src\n",
    "        while span_length:    \n",
    "            if span_length == 0:\n",
    "                break\n",
    "            if span_token_index in covered_indexes:  # 이미 마스킹 된 index 만나면 끝내고, 다음 순회 시작\n",
    "                break\n",
    "            else:  # 스팬 길이가 처음 선택 되었던 시작 토큰 인덱스가 해당되는 리스트 길이를 넘는 경우, 이후 선택되는 토큰은 wwm 위배 가능성\n",
    "                covered_indexes.add(span_token_index)\n",
    "                masked_lms.append(span_token_index)\n",
    "                span_length -= 1\n",
    "                budget -= 1\n",
    "                span_token_index += 1\n",
    "                continue\n",
    "\n",
    "    if len(covered_indexes) != len(masked_lms):\n",
    "        raise ValueError(\"Length of covered_indexes is not equal to length of masked_lms.\")\n",
    "    mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\n",
    "    return mask_labels\n",
    "\n",
    "def get_mask_tokens(inputs, mask_labels):\n",
    "    \"\"\" All of masking tokens are replaced by tokenizer.mask_token ([MASK]) unlikely BERT \n",
    "    \"\"\"\n",
    "    labels = inputs.clone()\n",
    "    probability_matrix = mask_labels\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    if tokenizer.pad_token is not None:\n",
    "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "        \n",
    "    masked_indices = probability_matrix.bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "    inputs[masked_indices] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "    return inputs, labels\n",
    "\n",
    "def testing(batched):\n",
    "    \"\"\" Masking for MLM with whole-word tokenizing \"\"\"\n",
    "    batched = batched[\"input_ids\"]\n",
    "    input_ids = [torch.tensor(batched)]\n",
    "    padding_mask = [get_padding_mask(x) for x in input_ids]\n",
    "    padding_mask = pad_sequence(padding_mask, batch_first=True, padding_value=True)\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "\n",
    "    mask_labels = []\n",
    "    ref_tokens = []\n",
    "    for input_id in batched:\n",
    "        token = tokenizer._convert_id_to_token(input_id)\n",
    "        ref_tokens.append(token)\n",
    "    mask_labels.append(_whole_word_mask(ref_tokens))\n",
    "    mask_labels = [torch.tensor(x) for x in mask_labels]\n",
    "    mask_labels = pad_sequence(mask_labels, batch_first=True, padding_value=0)\n",
    "    inputs, labels = get_mask_tokens(\n",
    "        input_ids,\n",
    "        mask_labels\n",
    "    )\n",
    "    return inputs, labels, mask_labels\n",
    "\n",
    "inputs, labels, mask_labels = testing(input_tokens)\n",
    "print(inputs, end=\"\\n\\n\")\n",
    "print(labels)\n",
    "print(mask_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:24:42.868046Z",
     "start_time": "2024-01-03T09:24:42.857047Z"
    }
   },
   "id": "4230c7917521186e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'start': 8, 'end': 19}, {'start': 74, 'end': 75}, {'start': 87, 'end': 89}, {'start': 138, 'end': 147}]]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def find_consecutive_groups(mask_labels: Tensor, target_value: int = 1) -> List[List[Dict]]:\n",
    "    \"\"\" Get the start and end positions of consecutive groups in tensor for the target value\n",
    "    This method is used for SBO Objective Function \n",
    "    \"\"\"\n",
    "    all_consecutive_groups = []\n",
    "    for mask_label in mask_labels:\n",
    "        consecutive_groups = []\n",
    "        current_group = None\n",
    "        for i, value in enumerate(mask_label):\n",
    "            if value == target_value:\n",
    "                if current_group is None:\n",
    "                    current_group = {\"start\": i, \"end\": i}\n",
    "                else:\n",
    "                    current_group[\"end\"] = i\n",
    "            else:\n",
    "                if current_group is not None:\n",
    "                    consecutive_groups.append(current_group)\n",
    "                    current_group = None\n",
    "        if current_group is not None:\n",
    "            consecutive_groups.append(current_group)\n",
    "        all_consecutive_groups.append(consecutive_groups)\n",
    "    return all_consecutive_groups\n",
    "consecutive_groups_result = find_consecutive_groups(mask_labels, target_value=1)\n",
    "print(consecutive_groups_result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:24:46.518709Z",
     "start_time": "2024-01-03T09:24:46.509215Z"
    }
   },
   "id": "1f316cc725289246"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(Embedding(27, 512),\n Parameter containing:\n tensor([[ 0.2646, -0.2359,  0.4529,  ..., -0.5603,  0.3245,  0.3620],\n         [-0.0196, -0.8800,  1.0720,  ...,  1.2667, -0.2152, -0.3769],\n         [-0.7504,  0.3307,  1.1889,  ...,  0.4162, -0.3113,  0.6106],\n         ...,\n         [ 0.3115,  0.8518, -1.4766,  ..., -0.2669, -0.1727,  0.5351],\n         [ 1.9991, -0.9528,  0.7093,  ...,  0.6325,  1.7774, -0.5017],\n         [ 0.3916, -0.3263,  0.0557,  ..., -0.9548, -1.7859,  0.2108]],\n        requires_grad=True))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Experiment for SBO Objective Function \"\"\"\n",
    "\n",
    "span_rel_emb = nn.Embedding(27, 512)  # must init for masking budget\n",
    "span_rel_emb, span_rel_emb.weight "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:24:47.600097Z",
     "start_time": "2024-01-03T09:24:47.592882Z"
    }
   },
   "id": "fe7e5735c64bf3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 186])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T07:22:41.850169Z",
     "start_time": "2024-01-03T07:22:41.833759Z"
    }
   },
   "id": "45a1b8ba14347245"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[-1.1521, -0.2392,  1.7351,  ...,  0.3129, -1.4128, -0.2144],\n          [ 0.0886, -0.3603, -1.0633,  ..., -0.4820, -0.2329,  0.0023],\n          [-1.3156,  1.4609, -0.9066,  ...,  0.7630, -0.7709, -0.4347],\n          ...,\n          [ 0.9064, -0.1078,  1.0082,  ..., -0.7056,  0.5967, -0.5739],\n          [ 1.0572,  0.2125,  0.1565,  ..., -0.0061, -0.7173, -0.4669],\n          [-1.3963, -1.9874, -0.2289,  ..., -1.8658, -1.8191, -0.6267]]]),\n tensor([[[ 0.1526,  0.5567, -1.3974,  ...,  0.8499,  0.1055, -2.5686],\n          [-0.5793,  3.0329,  0.5896,  ...,  0.7329,  1.1213,  0.6678],\n          [ 1.3690, -0.0392, -0.3986,  ...,  0.5848, -3.5014, -0.6479],\n          ...,\n          [-1.4222, -0.5831, -1.0043,  ..., -1.4952, -2.0334, -0.6246],\n          [-0.3715,  0.3789, -1.2255,  ...,  1.3738,  1.4021, -0.6949],\n          [-0.1482,  1.3755, -0.9278,  ...,  1.1829, -0.6609,  0.7503]]]))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs, sbo_inputs = torch.randn(1, 186, 512), torch.randn(1, 186, 1536)\n",
    "test_inputs, sbo_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:24:49.419391Z",
     "start_time": "2024-01-03T09:24:49.408197Z"
    }
   },
   "id": "9a6da386a1189266"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n tensor([[[-1.5058, -0.8496,  0.5403,  ..., -0.3646,  0.4450, -0.0917],\n          [-0.0246,  1.1698,  0.0467,  ...,  0.0660,  0.3899,  0.2518],\n          [ 0.1115, -0.9914,  0.6660,  ...,  0.1868,  0.0953,  0.3323],\n          ...,\n          [-1.2342,  1.3564, -0.3766,  ...,  0.3142, -0.4999, -0.2016],\n          [-0.7498, -1.1740, -0.5121,  ...,  0.5185, -0.9757,  0.2735],\n          [ 0.5789,  0.1172,  0.0544,  ..., -1.0499,  0.3183, -1.6551]]],\n        grad_fn=<EmbeddingBackward0>))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(inputs.shape[1]).repeat(inputs.shape[0]).view(inputs.shape[0], -1)\n",
    "idx = torch.arange(10).repeat(1).view(1, -1)\n",
    "pos_emb = span_rel_emb(idx)\n",
    "idx, pos_emb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T05:57:21.638341Z",
     "start_time": "2024-01-03T05:57:21.626714Z"
    }
   },
   "id": "1f64206946e7a692"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 7, end: 20\n",
      "start embedding: tensor([ 3.7031e-02, -1.3583e+00,  4.7276e-01,  6.2011e-01, -1.1235e+00,\n",
      "        -1.2694e+00,  1.0071e+00,  5.4310e-01,  1.0459e+00, -1.6113e+00,\n",
      "         6.4043e-01, -1.1919e+00, -1.6053e+00, -4.1883e-02, -1.0268e+00,\n",
      "         3.7953e-01,  9.5768e-01, -1.1539e+00, -1.3631e-01, -3.3494e-02,\n",
      "        -5.6035e-01, -8.8598e-01,  8.1725e-02,  1.7373e+00,  9.8985e-01,\n",
      "         3.2198e-01, -5.9679e-01,  7.6877e-01,  1.4909e+00, -9.6218e-01,\n",
      "         6.6162e-01,  4.2091e-01,  4.8263e-01,  1.7744e-01, -8.2634e-01,\n",
      "        -9.7398e-01,  6.6667e-01, -1.1811e-01,  1.3083e+00,  1.0871e+00,\n",
      "         5.3886e-01, -5.0587e-01, -1.6625e+00,  4.7040e-02, -2.2170e-01,\n",
      "         1.7113e-01, -3.8081e-01,  4.4583e-01,  9.4881e-01, -2.7438e-02,\n",
      "        -1.9873e-02,  8.5958e-01,  2.9861e-01,  2.5216e-02, -1.4235e+00,\n",
      "        -1.7888e-01, -4.8233e-01,  5.2773e-01, -1.2633e+00, -7.1751e-01,\n",
      "         8.8365e-01, -5.9685e-01,  1.3916e-01,  1.3091e+00, -4.9461e-02,\n",
      "         4.3480e-01, -1.0687e+00, -1.9342e+00,  1.3422e+00,  1.6177e-01,\n",
      "         1.9566e-01,  3.7254e-01,  2.1068e-01, -5.0807e-01,  2.2769e-01,\n",
      "        -6.7201e-01, -7.8734e-01, -1.0337e+00,  1.4462e+00, -1.4396e+00,\n",
      "         1.5335e+00,  3.4995e-01,  2.2367e-02,  8.1153e-01, -3.4088e-01,\n",
      "         1.4958e+00,  2.8963e-01, -1.2311e+00,  7.6172e-01, -7.1401e-01,\n",
      "        -1.5524e+00,  8.3823e-01, -7.4715e-01, -8.9820e-01,  4.5057e-01,\n",
      "         9.4919e-02,  6.5313e-01,  1.6599e-01,  7.1060e-01,  6.0792e-01,\n",
      "         9.4607e-02, -8.1420e-01, -3.7447e-01,  1.4660e+00,  1.0953e+00,\n",
      "         1.7567e-01,  1.3360e+00, -5.6586e-01,  1.1182e+00, -4.2863e-01,\n",
      "         5.2048e-01, -5.7151e-01,  2.8014e-01,  1.0195e+00,  3.5265e-02,\n",
      "         8.0678e-01, -5.7731e-01,  4.1276e-01, -1.5534e-01,  4.0403e-02,\n",
      "        -2.4982e+00, -1.7474e+00,  2.2003e-01, -5.9486e-01,  2.2175e-01,\n",
      "         4.9239e-01, -1.1968e+00, -8.3144e-02, -2.8827e-02,  7.5069e-02,\n",
      "        -3.3091e-01, -3.4732e-01, -1.1201e+00, -1.4556e+00, -1.0894e+00,\n",
      "        -2.9340e-01,  1.9863e+00, -6.1485e-01, -1.2774e+00, -7.7058e-01,\n",
      "         7.3816e-03,  4.4965e-01,  6.4604e-01, -6.0527e-02, -6.4730e-01,\n",
      "         3.9479e-01, -1.3763e+00,  3.4638e-01,  7.0834e-01,  4.6863e-01,\n",
      "         8.1472e-01, -7.4312e-01,  2.7862e-01,  5.2565e-01, -7.0856e-01,\n",
      "         2.0440e-01, -2.8560e-02, -1.4351e+00,  5.0842e-01,  7.3573e-01,\n",
      "        -1.4414e-01,  6.1977e-01,  2.8569e-01,  8.3712e-01,  8.6959e-01,\n",
      "         9.1203e-01,  4.0920e-01,  1.8823e+00, -1.0603e+00,  4.3113e-01,\n",
      "         1.7725e-01,  5.3297e-01, -2.2795e+00, -4.3522e-01,  3.9290e-01,\n",
      "         4.0379e-01,  1.3138e-02,  1.2737e+00, -1.3540e+00, -1.3956e-01,\n",
      "        -4.3877e-01,  1.3455e+00, -1.7658e+00, -2.2526e-01,  2.6902e-01,\n",
      "        -4.8773e-01, -1.3334e+00,  1.4390e-01, -5.8297e-01,  4.5022e-01,\n",
      "        -6.6990e-01,  1.7441e+00, -1.3507e+00,  1.1305e-01, -1.1529e+00,\n",
      "         1.7500e+00, -9.3700e-01,  1.0658e+00,  1.2077e+00,  1.6765e+00,\n",
      "        -3.9273e-01,  7.2421e-01,  1.7509e+00,  3.7474e-01, -1.9472e+00,\n",
      "         2.4571e-01, -1.3341e+00,  3.6934e-01, -2.1079e+00, -7.6285e-01,\n",
      "        -1.1440e+00, -5.0069e-01, -1.4937e+00, -2.3597e-01, -1.3028e+00,\n",
      "        -6.8585e-02, -1.1271e+00,  9.0609e-01, -2.4702e+00, -1.4363e+00,\n",
      "         7.7556e-01, -4.4108e-03,  3.2826e-01,  6.6253e-01,  1.8348e+00,\n",
      "         2.6165e-03, -9.1230e-01, -1.0330e+00,  7.6836e-01, -6.8885e-01,\n",
      "        -1.4390e+00,  1.2048e-01,  7.9910e-01,  1.2682e+00,  1.5809e+00,\n",
      "        -1.3442e+00,  1.8443e+00, -9.1240e-01,  2.4208e+00, -7.5267e-03,\n",
      "        -2.1582e-01,  3.6617e-01, -6.8102e-01, -3.9249e-01, -2.8239e-01,\n",
      "         2.0281e+00, -8.1446e-02, -2.4289e-01,  4.8623e-01,  3.2374e-01,\n",
      "         6.1870e-01, -1.0246e+00, -2.8051e+00,  2.9092e-01,  1.0908e+00,\n",
      "        -2.5110e+00, -1.8945e+00,  5.0473e-01, -2.9025e-01, -3.6182e-01,\n",
      "         6.0657e-01,  1.2057e-01, -1.5129e+00, -2.2851e-02,  1.0225e+00,\n",
      "        -6.6015e-01,  2.2673e-01, -5.9320e-01,  6.1251e-01,  1.6320e+00,\n",
      "        -7.9776e-01,  1.2549e+00, -2.2870e+00,  1.7148e+00, -9.5267e-01,\n",
      "        -9.0084e-01,  6.7443e-01,  3.6055e-02, -1.2647e-01, -2.9789e-01,\n",
      "         5.7184e-01,  1.7136e-01, -2.4743e-01,  1.9520e-01,  2.9010e-01,\n",
      "         9.6665e-02, -1.2073e+00, -1.5991e+00,  8.4877e-01, -9.3542e-01,\n",
      "        -6.5504e-01, -5.4090e-01,  5.3909e-01, -6.9288e-01, -1.2772e+00,\n",
      "        -4.3932e-02, -5.3344e-01,  6.1498e-01, -2.0905e-01, -1.9222e+00,\n",
      "         1.7372e+00, -5.0516e-01, -2.1267e+00,  1.4507e-01, -3.5342e-01,\n",
      "         1.4308e+00, -1.8175e+00,  1.4853e-01, -1.9233e-01, -2.6275e+00,\n",
      "        -1.1370e+00, -2.3161e+00,  1.0393e+00,  4.8798e-01, -1.2355e+00,\n",
      "        -1.8372e+00,  5.9844e-01,  3.3741e-02, -1.6125e+00, -8.3173e-01,\n",
      "        -2.3507e+00, -1.7031e+00, -1.4842e+00,  8.7548e-01,  6.3486e-02,\n",
      "         6.0807e-01, -4.0147e-01,  1.3449e+00, -5.8698e-01,  1.3635e+00,\n",
      "        -2.7131e-01, -7.9091e-01, -9.4410e-01,  2.6572e-01,  1.3546e+00,\n",
      "        -1.4587e+00,  2.5363e-01, -1.8766e-01, -1.0737e+00, -2.5537e-01,\n",
      "        -4.8651e-01,  1.0706e+00,  6.3927e-01, -7.2241e-01, -5.2513e-01,\n",
      "         4.2731e-01,  2.4569e-01, -8.5104e-01,  8.9305e-01, -1.4952e-01,\n",
      "         4.6216e-01,  5.1384e-01, -4.0713e-01,  4.9148e-01,  1.4841e-01,\n",
      "        -1.2064e-01, -9.5947e-01,  6.3444e-01,  2.0936e+00,  1.3912e+00,\n",
      "        -1.1339e+00,  4.0064e-02,  3.9839e-01,  7.2909e-01, -1.0417e+00,\n",
      "         8.2830e-01, -7.4989e-01,  2.7405e+00, -2.9817e-01,  3.0548e-01,\n",
      "         1.9019e+00,  1.4409e+00,  7.0029e-01,  1.1474e+00,  3.1703e-01,\n",
      "         9.2029e-03, -4.7639e-01, -1.8583e-01,  2.1355e+00, -1.4775e-01,\n",
      "         9.3101e-01, -7.4459e-01,  1.9154e-01, -1.2295e+00, -8.6231e-02,\n",
      "        -5.8431e-01,  1.0598e+00,  7.7098e-01,  1.3032e+00,  7.4323e-01,\n",
      "        -1.0067e+00,  9.1235e-01,  1.0747e+00, -5.3853e-01, -9.0378e-01,\n",
      "        -1.3981e+00, -2.4700e-01,  1.5934e+00,  3.9908e-01,  2.1017e+00,\n",
      "         4.9119e-01, -8.8034e-01, -8.3435e-01,  1.0296e-01, -2.6525e-01,\n",
      "         1.3341e+00,  7.7217e-01,  8.1520e-02, -2.4594e-01,  1.5538e+00,\n",
      "         1.4799e+00,  4.1285e-01,  1.9028e+00,  5.1346e-01, -9.9650e-01,\n",
      "        -4.0175e-01,  4.9824e-01,  3.3625e-01,  3.4577e-01, -1.9301e+00,\n",
      "         9.5781e-01,  9.3228e-02, -4.3467e-01, -2.4833e-01,  2.9521e-01,\n",
      "        -1.1124e+00,  1.0228e+00,  7.7987e-01,  7.3544e-01, -3.2073e-01,\n",
      "         8.8007e-01, -9.2469e-02,  2.6109e-01,  1.3840e-01,  8.6075e-01,\n",
      "         9.9035e-01,  7.8590e-01, -1.0626e+00,  4.2532e-01,  2.9068e-01,\n",
      "        -7.1543e-01,  1.2876e+00, -1.9590e-01, -8.3123e-02, -8.3770e-01,\n",
      "        -2.1331e-01,  2.9292e+00,  4.2720e-01,  1.0925e+00, -1.7731e-01,\n",
      "         9.6968e-01,  3.7300e-01,  1.7383e+00, -1.2773e+00, -2.3224e+00,\n",
      "        -7.9285e-01,  3.2356e-01, -2.1096e-02,  1.1313e-01, -6.6153e-01,\n",
      "         3.9564e-01,  1.1986e+00, -8.8787e-01, -3.1084e-01,  4.5325e-01,\n",
      "         2.3034e-01, -2.6535e-01, -3.7775e-02,  1.4851e+00, -1.0570e+00,\n",
      "        -1.5099e+00, -6.6719e-01,  4.1995e-01,  5.3018e-01,  6.1741e-01,\n",
      "         2.5813e-01,  1.1223e-01,  1.0703e+00,  4.9640e-02,  1.8625e+00,\n",
      "         1.8764e+00,  1.0982e+00,  1.4867e+00, -2.5243e+00,  3.5707e-01,\n",
      "        -1.4308e+00, -1.0901e+00, -1.0409e+00,  1.1399e+00,  1.0833e+00,\n",
      "         3.3544e-01,  8.4823e-01, -1.8048e-01, -7.3355e-01, -2.2456e-01,\n",
      "         1.7820e+00,  1.7632e-01,  9.2047e-01,  5.9132e-01, -4.2227e-01,\n",
      "        -1.1861e+00,  2.2404e-01,  3.1036e+00, -1.0896e-01,  8.7485e-02,\n",
      "        -4.8746e-01, -4.5627e-03,  4.1285e-01,  1.2080e+00,  1.4894e+00,\n",
      "        -8.2502e-01, -2.2612e+00]), end embedding: tensor([-1.4603e+00, -8.1400e-01, -3.0339e-01,  2.0886e-01,  1.7141e+00,\n",
      "        -5.9233e-01, -1.6284e+00, -1.3782e+00, -5.8163e-01, -2.9670e-01,\n",
      "         7.3157e-01, -9.3487e-02,  9.2204e-01,  6.7857e-01, -3.9500e-01,\n",
      "         1.5544e+00, -1.5262e-01, -2.0492e-01,  4.8749e-01,  5.3421e-01,\n",
      "        -4.5981e-02, -3.5856e-01,  1.2309e-01,  1.3350e-01, -1.0525e+00,\n",
      "         5.5811e-01, -2.2075e-01, -4.2866e-01, -3.4798e-03, -7.3473e-01,\n",
      "         8.5209e-01, -2.8833e-01, -7.7922e-01, -4.2090e-01,  6.2030e-01,\n",
      "         4.4543e-02, -5.4252e-01, -2.2089e-01,  9.3383e-02, -2.6349e-01,\n",
      "         3.5180e-01, -1.0446e+00, -4.2593e-02,  4.0839e-01, -2.0344e-01,\n",
      "        -8.9412e-01,  1.3890e+00,  1.0152e+00,  5.4275e-01,  7.4883e-02,\n",
      "         8.9843e-03,  6.6295e-01, -5.0344e-01, -2.4573e-01, -1.2700e-01,\n",
      "        -2.3616e-01, -3.7183e-01,  1.1055e+00,  1.9971e+00, -5.0909e-01,\n",
      "        -6.2233e-01,  2.8355e+00, -4.5619e-01, -5.9063e-01,  2.4843e-01,\n",
      "        -1.1358e+00,  1.2805e-01,  1.0790e+00,  7.4366e-01, -8.4992e-01,\n",
      "        -1.8011e-01, -2.2660e+00,  7.4316e-01, -6.5128e-01,  1.3668e+00,\n",
      "        -4.2958e-01, -8.0926e-02,  5.9121e-01,  4.7693e-01, -4.7547e-01,\n",
      "         1.1417e+00, -2.4959e-01, -4.3829e-01,  5.7346e-01,  4.3232e-01,\n",
      "        -1.8994e+00,  8.9458e-01,  1.5615e-01,  7.9100e-01, -1.6165e+00,\n",
      "        -7.0602e-01, -8.5723e-01,  1.2350e+00,  1.2240e+00, -1.2550e+00,\n",
      "         1.8722e+00,  6.5686e-01,  1.9684e+00, -3.0578e-01, -7.1854e-01,\n",
      "        -1.9083e-01, -1.1812e+00, -4.8666e-01,  6.3164e-01, -2.2504e-01,\n",
      "        -1.3001e-01,  1.9493e+00, -2.8478e-01, -5.3354e-01,  4.9392e-01,\n",
      "         1.7618e+00, -4.7160e-01,  5.5299e-01, -2.6524e-01, -3.7520e-01,\n",
      "        -9.0566e-01,  1.3361e+00,  9.6432e-01, -1.2588e+00,  9.9946e-01,\n",
      "         6.5603e-02,  7.9099e-02,  1.2914e-01, -2.0780e+00, -3.4680e-01,\n",
      "         5.6107e-02,  3.2690e-01,  6.8328e-01, -1.6495e+00,  1.3528e-01,\n",
      "         5.7737e-01,  2.1985e-01,  1.0344e+00, -1.1475e+00, -1.2573e+00,\n",
      "         1.2703e+00, -7.1992e-01, -5.7689e-02,  5.7809e-02, -4.2363e-01,\n",
      "        -2.8042e-01,  2.4901e-01, -1.9581e-02,  4.9932e-01,  5.8264e-01,\n",
      "         7.1325e-01, -1.8716e-02, -5.5291e-01, -1.3987e+00, -5.7967e-01,\n",
      "        -9.0000e-01, -2.6723e-02, -4.9960e-01, -5.2917e-01,  3.3168e-01,\n",
      "        -2.7017e-01, -1.6567e+00, -1.1137e+00, -1.9908e+00,  1.2770e+00,\n",
      "         1.3378e+00,  3.0941e-01, -5.9270e-02,  1.1923e+00, -4.1403e-01,\n",
      "         4.4333e-01,  1.4307e-01,  2.6104e-01, -3.8609e-01,  3.9844e-01,\n",
      "        -6.6643e-01,  7.1526e-01, -8.1909e-01, -1.0108e+00,  8.6297e-01,\n",
      "         1.8972e+00, -1.0452e+00, -7.1766e-01,  2.1861e-01,  1.2651e-02,\n",
      "         1.2696e+00, -1.3514e+00,  1.2174e+00,  8.1155e-01, -1.2707e+00,\n",
      "        -5.2272e-01,  7.1857e-03, -1.8263e+00, -9.4372e-01,  1.3981e-01,\n",
      "        -2.4700e+00,  3.2815e-01,  9.9846e-01,  4.9674e-01,  2.4063e+00,\n",
      "        -5.8242e-01,  4.3902e-01, -1.0494e-01, -8.0584e-01, -1.0152e+00,\n",
      "         2.2678e-01,  1.2760e-01, -3.8617e-01, -4.9760e-01, -2.8194e+00,\n",
      "         1.3846e-01, -1.8331e-01, -4.5531e-01, -2.4321e-01, -1.3994e+00,\n",
      "        -6.4797e-01, -7.2333e-01,  1.4077e+00,  8.0688e-01,  7.5103e-01,\n",
      "        -8.4223e-01,  3.0131e-01,  4.0341e-02, -7.3961e-01, -1.3898e-01,\n",
      "        -3.9575e-01,  9.5873e-01,  1.8667e+00,  2.2481e-01,  6.5644e-01,\n",
      "        -3.4017e-01, -1.5419e+00,  1.8487e-01,  1.7222e+00,  4.1442e-01,\n",
      "        -3.0799e-01, -1.8455e+00, -6.1020e-01, -4.3555e-01,  2.4780e+00,\n",
      "        -6.5521e-02,  1.6843e+00,  7.9016e-01, -1.3593e+00, -1.0223e-03,\n",
      "        -1.1834e-02, -1.7990e-01, -7.7898e-02, -6.6166e-02, -1.8844e-01,\n",
      "        -1.7949e+00, -5.4349e-01,  2.2776e-01,  3.0465e-01, -4.0337e-01,\n",
      "        -1.1973e+00,  1.6061e+00,  1.9218e+00,  1.0256e+00,  1.1350e-01,\n",
      "         2.6159e-01, -3.9623e-01, -2.2574e+00, -8.4538e-01,  9.5155e-01,\n",
      "         1.4157e-01, -1.3022e+00, -9.3447e-01, -1.2656e+00, -1.2194e-01,\n",
      "         7.2499e-01, -2.7456e+00,  4.7383e-01,  1.3374e+00, -7.8478e-01,\n",
      "         1.1512e+00,  4.4073e-01,  2.5372e-01, -8.1989e-01, -1.1934e+00,\n",
      "        -1.0957e+00,  2.2127e-01,  1.5788e+00,  4.1603e-01,  1.0617e+00,\n",
      "        -7.4444e-01,  3.1139e-01, -3.9842e-01, -2.8711e+00,  1.6899e-02,\n",
      "        -1.6794e+00, -1.7048e+00,  9.7151e-01,  8.3231e-01,  1.0372e+00,\n",
      "        -1.0502e+00, -5.7884e-01,  3.3520e-01,  1.0032e+00, -2.5121e+00,\n",
      "        -5.0987e-01,  7.6676e-01,  3.1900e-01, -1.0315e+00,  1.1293e+00,\n",
      "        -4.8115e-01,  4.4520e-01,  4.9773e-01, -2.5939e-01, -9.2797e-01,\n",
      "        -2.9796e-01, -5.6371e-01, -1.0282e+00, -8.2048e-01, -6.2651e-01,\n",
      "         5.4335e-01,  8.8239e-01, -3.2345e-01, -5.0435e-01,  4.9537e-01,\n",
      "        -3.4736e-01, -7.2762e-01,  6.1229e-01, -1.0026e+00,  4.0367e-01,\n",
      "        -8.8591e-01, -4.5046e-02,  6.8539e-01, -4.8091e-01, -6.9396e-01,\n",
      "        -1.4540e+00, -1.1278e+00,  1.0252e+00, -3.7240e-01, -1.4953e+00,\n",
      "         8.4710e-01, -2.3346e-01, -8.8387e-01,  1.3905e-01, -1.7644e+00,\n",
      "         3.8995e-03, -3.9003e-01, -8.2438e-01, -2.6411e-01,  6.1053e-01,\n",
      "        -1.3612e+00,  1.1185e+00, -1.3575e+00,  1.1745e-01, -1.3847e+00,\n",
      "        -1.0875e+00,  9.9041e-01, -6.4820e-01,  1.7043e-01, -2.2997e-01,\n",
      "        -1.3049e+00,  1.1130e+00, -4.8587e-01,  9.1528e-01,  1.8487e+00,\n",
      "         5.5740e-01, -3.2824e-01, -5.5981e-01, -1.6817e-01, -1.0752e+00,\n",
      "         2.2411e+00,  3.7758e-01, -9.8675e-01,  4.5058e-01, -6.9683e-01,\n",
      "         1.3509e+00,  1.4898e+00,  1.2053e+00, -1.1713e+00, -2.3022e+00,\n",
      "        -1.5420e+00, -6.6418e-01,  1.0304e+00,  2.7951e-01,  1.4810e-01,\n",
      "        -8.3669e-01, -2.3817e+00,  8.4241e-01,  2.8563e+00,  1.2719e+00,\n",
      "         8.6548e-01,  1.0394e+00,  9.1061e-01,  3.5668e-01,  9.1997e-01,\n",
      "        -8.3977e-01,  1.4958e-01, -1.0803e+00, -1.1197e+00,  1.0975e+00,\n",
      "        -4.4904e-01,  1.0900e-02, -3.7619e-01, -1.3136e+00, -1.0823e-02,\n",
      "         9.2218e-03, -3.7102e-01,  9.1891e-02, -1.8587e+00,  1.5316e-01,\n",
      "        -6.6190e-01, -6.8032e-01, -1.3277e+00,  1.6149e+00, -3.4782e-01,\n",
      "         1.4563e+00,  1.1365e+00,  8.4888e-01,  8.4028e-01,  2.1103e-01,\n",
      "         5.5613e-01,  6.4620e-01, -6.8258e-02,  6.2956e-01,  3.4960e-02,\n",
      "         8.3136e-01,  4.4910e-01, -6.4815e-01, -1.2384e+00, -6.0961e-01,\n",
      "        -2.4923e-01, -5.9102e-01, -1.1995e-01, -4.2848e-02, -2.1309e-01,\n",
      "         5.6473e-01,  4.3184e-01, -4.5426e-01,  2.2853e-01,  6.4692e-01,\n",
      "        -9.5476e-01,  4.9469e-01,  8.5923e-01, -1.0582e-01,  1.2846e+00,\n",
      "         5.2043e-01,  2.0730e-01, -1.4540e+00, -7.7292e-01,  4.0990e-01,\n",
      "         1.8176e-01, -4.6853e-01,  5.2688e-01, -3.4250e-03, -5.8300e-01,\n",
      "         8.6557e-01, -7.0611e-02,  9.7277e-01,  7.0213e-01, -9.1626e-01,\n",
      "        -5.4336e-01,  1.7603e-02,  3.0972e-01, -2.1720e+00,  6.3495e-01,\n",
      "         6.8559e-01, -1.1809e+00,  4.2883e-01, -3.0405e-01,  1.5803e-01,\n",
      "        -5.4058e-01, -2.1720e+00, -4.2548e-01,  1.3244e+00, -6.7403e-02,\n",
      "        -7.0402e-01, -5.7064e-01,  1.0197e+00, -1.0274e-01, -1.6665e+00,\n",
      "         2.2843e+00, -8.6522e-01,  3.0371e-01, -5.3812e-01, -4.9174e-01,\n",
      "        -5.5512e-01,  1.8431e+00, -1.8300e+00, -1.3293e+00, -2.3088e+00,\n",
      "        -1.5618e-02,  1.4597e-01,  6.1307e-01,  6.3522e-01,  1.0152e+00,\n",
      "         1.5793e-01, -1.3057e+00, -2.6226e-01, -3.1972e-01,  4.1337e-02,\n",
      "         3.5215e-01,  5.6773e-01, -6.6727e-01,  1.2172e+00,  1.0895e+00,\n",
      "         1.7128e+00, -7.9799e-01, -3.2645e-01,  6.5691e-01,  1.0220e+00,\n",
      "         7.3878e-01,  3.4665e-01, -7.3789e-01, -2.9273e-02, -7.1324e-01,\n",
      "         2.0697e+00,  5.2118e-01,  5.2595e-01,  3.0894e-01,  7.0848e-01,\n",
      "        -3.0393e-01,  1.6547e+00])\n",
      "span length: 12\n",
      "span position embedding: tensor([[ 0.2646, -0.2359,  0.4529,  ..., -0.5603,  0.3245,  0.3620],\n",
      "        [-0.0196, -0.8800,  1.0720,  ...,  1.2667, -0.2152, -0.3769],\n",
      "        [-0.7504,  0.3307,  1.1889,  ...,  0.4162, -0.3113,  0.6106],\n",
      "        ...,\n",
      "        [ 1.3378, -1.7574,  0.7789,  ...,  0.4283,  0.7124, -0.6670],\n",
      "        [ 0.8589, -0.6631,  1.4327,  ..., -1.0784, -1.0616, -0.7995],\n",
      "        [-0.7618,  1.3674, -0.6860,  ..., -0.7203, -0.8612,  0.6092]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "span position embedding shape: torch.Size([12, 512])\n",
      "p_h: tensor([ 2.6463e-01, -2.3591e-01,  4.5285e-01, -1.1136e-01,  3.0407e-01,\n",
      "        -2.3966e-01, -2.7644e-02,  1.2563e+00,  3.6182e-01,  1.9652e-01,\n",
      "        -8.6246e-01, -7.1119e-01, -1.1506e+00, -8.6195e-01,  1.2013e+00,\n",
      "         1.3645e+00, -4.7164e-01, -1.0417e-02,  5.2249e-01,  1.8408e-01,\n",
      "        -1.4745e-01,  1.5400e+00, -1.0897e+00,  1.2691e+00, -1.9417e+00,\n",
      "        -2.5694e-01,  5.3591e-01,  4.6418e-01, -1.1935e+00,  1.5731e+00,\n",
      "         4.0055e-01,  1.6647e+00,  3.1474e-01, -5.1079e-01, -4.6470e-01,\n",
      "        -1.6623e+00, -1.9396e-02, -1.8199e+00, -4.0583e-01,  8.2175e-02,\n",
      "        -5.3666e-02, -6.3857e-01,  2.9397e-01,  5.2579e-01, -2.1096e+00,\n",
      "         1.7281e+00,  3.8924e-01,  3.7421e-01,  8.1201e-01,  6.8693e-01,\n",
      "        -1.9785e+00,  2.4820e-01,  6.1537e-01, -2.1311e+00,  1.0837e+00,\n",
      "         5.3762e-01,  4.5211e-01,  1.4208e+00,  1.8105e+00,  9.5980e-01,\n",
      "         6.4874e-01,  1.0742e+00,  1.9713e-01, -6.1546e-01, -3.3916e-01,\n",
      "        -3.3302e-02, -1.1120e+00,  1.2290e+00,  3.2036e-01,  4.7312e-01,\n",
      "        -1.0821e-01, -1.0119e+00,  7.7355e-01, -7.3499e-01, -1.4620e+00,\n",
      "         6.8714e-01, -1.4982e+00,  3.4491e-01, -1.1672e+00,  4.2549e-01,\n",
      "         1.1212e+00, -1.4065e+00,  2.5087e-01,  3.4171e-01,  3.1139e-01,\n",
      "         8.3637e-01,  1.2320e+00,  1.0655e-01,  8.9789e-01,  2.3202e-01,\n",
      "        -1.8274e+00,  3.1027e-01,  2.1902e-01, -2.4660e-01,  9.7873e-01,\n",
      "         3.6632e-01,  5.2638e-01,  4.3381e-01, -5.1404e-02,  9.4305e-02,\n",
      "         5.2549e-01, -5.7886e-01,  9.5275e-01, -9.3557e-01,  4.2693e-01,\n",
      "         1.2856e+00,  1.7819e-01,  1.1278e+00, -6.1495e-01,  1.0691e-01,\n",
      "         1.4019e+00, -1.9541e-01, -2.7272e-01, -5.9999e-01,  1.3753e+00,\n",
      "         4.8390e-01, -5.9446e-01,  6.2681e-01,  1.0675e-01,  2.6720e+00,\n",
      "        -4.6258e-01,  1.1697e+00,  1.0102e-01,  5.9059e-01, -1.1562e-01,\n",
      "         1.8833e+00, -1.9221e+00,  8.4052e-01,  1.2141e+00, -1.5262e+00,\n",
      "         1.3867e+00,  5.7718e-01,  7.7591e-01,  1.4728e+00,  2.4874e+00,\n",
      "        -5.0059e-01,  9.5103e-03,  3.5364e-01,  1.4312e+00, -4.0655e-01,\n",
      "         1.3028e+00, -2.3050e-01,  4.9509e-01, -1.8871e-03,  6.7407e-01,\n",
      "         1.6877e+00,  7.6270e-01, -1.0258e+00, -1.0028e+00, -7.8825e-01,\n",
      "         2.5775e-01, -7.2426e-01,  2.5744e-03, -2.3219e+00,  6.9216e-01,\n",
      "         2.6199e-01, -6.8344e-01,  1.6513e+00,  8.0119e-01, -9.5820e-01,\n",
      "         1.4848e-01,  4.2119e-01,  5.4669e-01, -5.4224e-01,  1.3896e+00,\n",
      "         5.5137e-01, -2.9887e+00, -8.5112e-01, -8.3678e-01,  4.3097e-01,\n",
      "        -8.2797e-01,  1.8303e-01, -8.1399e-01,  3.0334e-01,  4.3765e-01,\n",
      "        -1.6117e+00,  4.6604e-01, -1.1909e+00, -1.7815e-01,  4.5396e-01,\n",
      "         1.3874e+00,  1.3422e+00, -7.1142e-02, -5.3129e-01,  4.9093e-01,\n",
      "         8.8818e-01,  6.9741e-01, -4.1026e-01, -4.8009e-01,  7.1111e-01,\n",
      "        -3.7213e-01, -4.3906e-01,  1.4767e+00,  7.1079e-02, -1.7537e-01,\n",
      "        -1.1809e+00,  5.6096e-01, -6.4618e-01,  1.1893e+00,  1.5120e+00,\n",
      "         1.3990e+00, -6.8395e-01,  1.5880e-01, -5.5990e-01, -2.6268e-01,\n",
      "         5.4497e-01, -1.2274e+00,  2.7820e-01, -3.6112e-01,  9.7976e-01,\n",
      "         2.9502e-01,  5.4370e-01,  8.3105e-01,  1.8538e+00, -5.3877e-01,\n",
      "        -9.5267e-01, -9.1673e-01,  1.2531e-03, -2.0213e+00,  9.8051e-01,\n",
      "        -8.8374e-01, -4.2150e-02, -1.6528e+00,  1.9307e-01,  1.5692e+00,\n",
      "        -1.4780e+00, -9.2722e-01,  6.9250e-01, -1.8756e+00,  5.8865e-01,\n",
      "         4.9594e-01,  1.3061e+00, -7.3392e-01,  7.4737e-01,  5.5305e-01,\n",
      "        -1.4458e+00,  6.7631e-01, -2.8349e-01, -4.1311e-02,  9.9215e-01,\n",
      "        -7.9370e-01, -1.3216e+00, -3.7143e-01, -1.9428e-01,  1.7150e+00,\n",
      "        -8.5702e-01,  7.9772e-01,  8.0723e-01,  5.9285e-01, -1.7337e+00,\n",
      "        -3.6545e-01, -3.0930e-02,  9.5934e-02,  7.5442e-01,  2.2453e+00,\n",
      "         6.7726e-01, -1.8739e+00,  3.4552e-01,  1.1640e+00, -3.9320e-01,\n",
      "         5.5008e-01, -6.4734e-01,  2.0954e-01, -1.1305e+00, -7.5992e-01,\n",
      "         8.4470e-01,  1.9466e+00, -1.0329e+00,  1.2538e+00, -1.1546e-01,\n",
      "         1.4509e-01,  1.6514e+00, -1.4655e+00, -7.7295e-01,  1.8134e-01,\n",
      "        -1.8199e-01, -2.2637e-01, -1.4556e+00,  4.7327e-01,  5.7220e-01,\n",
      "         1.1069e+00,  5.3194e-01, -1.1256e+00, -3.2274e+00,  6.3759e-01,\n",
      "         4.2993e-03,  1.2920e-01, -3.1513e-03,  8.9170e-01,  5.2861e-01,\n",
      "        -2.7012e-01, -9.0175e-01, -1.6887e+00, -9.3186e-01,  3.1375e-01,\n",
      "        -1.5741e-01, -1.2657e+00, -2.7680e-03, -6.1508e-01,  1.6279e+00,\n",
      "         1.0891e-01, -1.2797e-01, -1.7622e+00, -1.5778e+00, -4.4926e-01,\n",
      "        -2.8947e-01, -2.0997e-01, -1.2714e+00, -3.0723e-01, -1.7475e+00,\n",
      "        -4.5016e-01, -2.0889e+00, -5.9639e-02, -1.2555e-01,  2.8605e-01,\n",
      "        -1.1658e+00,  1.7329e-02, -1.2733e+00,  6.8152e-01, -7.8875e-01,\n",
      "        -3.6547e-01, -2.8417e-01, -7.3583e-01, -6.6815e-01, -2.2105e-01,\n",
      "        -2.5366e-01, -6.1688e-01,  1.3577e+00, -4.7580e-03, -4.3801e-01,\n",
      "         1.0144e+00,  9.6206e-02,  1.1831e+00, -1.0204e+00, -7.2906e-01,\n",
      "         1.1042e+00,  1.0556e+00, -3.3137e-01, -5.8628e-02,  1.6092e+00,\n",
      "         6.9107e-01,  9.4272e-01, -4.0911e-01,  4.8866e-01, -9.8013e-01,\n",
      "        -5.3689e-01,  1.5416e-01, -4.8419e-01, -1.2030e+00, -1.8621e-01,\n",
      "         1.4200e+00, -5.6757e-01, -1.2296e+00, -8.0300e-01,  8.2033e-01,\n",
      "         9.9433e-01,  3.8412e-01, -2.9066e-01,  1.2961e+00, -5.4361e-01,\n",
      "        -1.3810e-01,  2.6702e-01,  3.3126e-01, -3.1704e-01, -9.3242e-01,\n",
      "         3.7303e-01, -3.5497e-01, -6.0568e-01,  6.2027e-01,  2.3453e-01,\n",
      "        -4.7209e-01,  3.3481e-02,  2.1820e-02, -5.8500e-01, -5.3081e-01,\n",
      "        -6.4882e-01,  2.2216e+00, -7.2217e-01, -2.9424e-01, -1.1246e+00,\n",
      "        -9.9307e-01, -8.4144e-01, -1.7093e+00,  7.5401e-01,  2.0645e-01,\n",
      "        -4.3273e-01, -1.7653e+00, -2.1502e-01,  4.2585e-01, -6.9993e-01,\n",
      "        -1.1024e+00,  9.1361e-01, -1.4485e-01, -1.9265e-01, -1.3256e+00,\n",
      "        -2.3604e-02, -1.9355e+00, -1.0227e+00,  1.1890e+00,  5.9773e-01,\n",
      "        -8.6292e-01, -3.0950e-03, -8.2854e-01,  5.9784e-01, -6.1528e-01,\n",
      "        -1.2698e+00,  5.7545e-01, -8.4002e-01,  1.3896e-01, -9.3209e-02,\n",
      "         7.3866e-01,  7.1812e-01, -6.1141e-01, -3.4375e-02, -1.0954e+00,\n",
      "         1.8022e-01,  3.2163e-01,  7.7503e-02, -1.0133e+00,  1.1984e+00,\n",
      "         9.1484e-01, -4.9774e-01,  2.1523e+00, -1.2008e-01,  3.3075e-02,\n",
      "        -4.0801e-01,  9.1579e-01, -6.9246e-01,  1.2818e+00, -1.7857e+00,\n",
      "         1.8785e+00,  7.0748e-02,  1.3929e+00,  2.0655e-01, -1.2619e+00,\n",
      "        -2.3901e-01,  1.2071e+00,  1.6173e+00, -1.3642e+00,  2.3291e+00,\n",
      "        -6.8836e-01,  8.9147e-01,  1.5207e+00, -1.8084e-01, -1.9412e-01,\n",
      "         7.5915e-01, -1.8645e+00,  5.3172e-01, -8.7955e-01, -2.4235e+00,\n",
      "        -1.0345e+00, -5.3043e-01, -1.7635e+00,  4.9432e-01, -1.3330e+00,\n",
      "         1.0709e+00,  9.4012e-02,  6.9564e-02, -5.0142e-01,  4.6696e-01,\n",
      "        -9.9967e-01,  9.0375e-01,  5.6307e-01, -1.6594e+00, -1.1686e-01,\n",
      "         2.4648e+00,  1.8703e+00,  1.4332e+00,  7.1619e-01,  2.5616e+00,\n",
      "        -2.2084e+00,  1.5308e+00, -1.2692e+00,  1.3647e-01,  1.0541e+00,\n",
      "         3.5369e-01,  1.0998e+00, -1.7216e-01,  1.3324e+00,  4.7375e-01,\n",
      "        -1.0231e+00,  7.9570e-01,  1.3606e+00,  2.0566e-02,  8.9172e-01,\n",
      "        -1.8407e+00,  1.8103e-01,  8.0128e-01,  9.9860e-01,  7.4569e-02,\n",
      "        -6.2979e-01, -1.1183e+00,  7.5391e-01,  2.5534e-01, -1.0144e+00,\n",
      "        -4.8885e-01, -1.3235e-01, -5.8060e-01,  5.4132e-02, -1.5560e+00,\n",
      "        -2.2478e+00,  9.4176e-01, -1.2558e+00,  4.1022e-01, -8.7279e-01,\n",
      "         8.9475e-02,  5.2558e-01, -1.1772e+00, -9.8584e-01, -5.6031e-01,\n",
      "         3.2450e-01,  3.6195e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.9598e-02, -8.8004e-01,  1.0720e+00, -2.7167e-01, -1.1181e-01,\n",
      "         1.2305e+00, -7.0031e-01, -4.4509e-01, -1.0202e+00,  1.7274e+00,\n",
      "         2.6604e-01, -2.7644e+00, -2.9702e-01,  7.5236e-01, -5.5668e-01,\n",
      "        -5.4757e-01,  1.4329e+00,  3.3933e-01, -2.2905e+00, -6.3927e-02,\n",
      "        -3.9277e-01, -1.3286e+00, -1.0442e+00,  6.3118e-01, -3.9864e-01,\n",
      "         1.1672e+00,  4.9961e-01, -2.4401e+00,  2.0224e+00,  1.4115e-01,\n",
      "         2.9880e-01, -1.7060e-01, -1.0577e+00,  7.1500e-01,  2.9370e-01,\n",
      "        -4.2851e-02, -3.0085e-01, -1.7421e-03, -4.0230e-01,  5.1137e-01,\n",
      "         7.4943e-01, -1.8208e-01,  2.6125e-01, -5.7877e-01,  2.7831e+00,\n",
      "         2.1889e+00, -1.2854e+00,  1.0939e+00,  2.9090e+00, -1.5365e+00,\n",
      "        -1.7057e+00,  1.0591e+00,  2.0244e+00,  2.2355e+00, -1.9716e+00,\n",
      "         1.3339e+00, -1.1843e+00, -1.5504e+00,  3.8147e-01, -1.5133e-01,\n",
      "         2.9308e-01,  9.4728e-01,  5.1063e-01, -9.4425e-01,  4.7430e-01,\n",
      "         3.3420e-01,  4.3306e-01, -1.4448e+00,  1.1767e-01,  2.6016e+00,\n",
      "        -1.0885e+00,  7.2074e-01, -8.0917e-01,  6.9210e-01, -5.1269e-01,\n",
      "         5.4817e-01, -3.4270e-02,  7.2508e-01,  4.0123e-01,  6.3323e-01,\n",
      "         1.3014e+00, -2.5752e-01, -3.7336e-01,  2.4239e-01, -7.1877e-01,\n",
      "        -1.3336e-01,  8.0229e-01,  1.1414e+00,  3.2048e-01, -1.1728e+00,\n",
      "         5.7086e-01, -1.9970e-01, -9.0181e-01, -7.4187e-01, -1.1517e+00,\n",
      "        -4.8143e-01,  3.5825e-02,  8.8615e-01, -8.7241e-01,  7.4572e-01,\n",
      "        -1.0059e+00, -1.2884e+00, -1.4603e+00, -8.2570e-01, -1.4340e-01,\n",
      "        -6.6732e-01, -5.6294e-01,  1.2165e+00,  1.0110e+00, -2.2715e+00,\n",
      "         5.6288e-01, -2.4479e-01,  1.4545e+00,  4.1549e-01, -1.3575e+00,\n",
      "        -7.9776e-02,  1.3199e+00,  5.7921e-01, -7.9095e-01,  9.1039e-01,\n",
      "         2.1433e+00, -1.6521e+00, -1.1074e+00, -5.2481e-01, -2.3083e-01,\n",
      "         1.4427e+00,  6.8813e-01,  9.2377e-01, -4.3607e-01, -6.7831e-01,\n",
      "         1.6607e+00, -6.0901e-01, -1.2238e+00, -1.2792e+00,  7.7615e-01,\n",
      "         1.7335e+00, -3.0826e-01, -1.6324e+00, -2.2841e-02,  7.7872e-01,\n",
      "        -2.3813e-01,  1.7590e+00, -2.6300e+00, -2.2589e+00, -5.7844e-01,\n",
      "        -1.0014e+00, -4.4668e-01, -1.0133e+00,  2.3634e-01, -5.3267e-01,\n",
      "        -9.9985e-01, -2.1989e+00, -3.7624e-01,  6.5364e-01,  7.5254e-01,\n",
      "        -1.3376e+00,  9.7770e-01,  1.1336e+00,  4.7673e-01,  2.9082e-01,\n",
      "        -1.3255e-01,  1.1891e+00, -1.3592e+00,  1.4276e+00,  1.0099e+00,\n",
      "        -2.0686e-01,  4.7024e-01,  6.6699e-01, -1.2182e+00,  4.1511e-01,\n",
      "         3.4016e-01, -1.3129e+00,  6.7744e-01, -9.9545e-01, -1.2289e+00,\n",
      "         1.6814e+00,  1.7367e-01,  4.4566e-01, -3.4744e-01,  7.7216e-01,\n",
      "        -7.9999e-01,  1.0696e+00, -1.9791e+00,  7.5679e-01, -6.2594e-01,\n",
      "         3.3649e-01,  3.2236e-01,  9.3129e-01, -2.6896e-01, -1.1185e+00,\n",
      "         1.2515e+00, -1.4685e-01, -7.1486e-02, -4.7896e-01,  2.8939e-02,\n",
      "        -1.6243e-01,  2.5263e-01,  7.6768e-01,  6.1950e-01, -9.7351e-01,\n",
      "        -8.4524e-01,  1.6915e+00, -7.3563e-01, -3.6067e-02, -1.9589e+00,\n",
      "        -8.4760e-02, -1.7551e-01,  2.5339e+00,  1.2955e+00, -2.5083e+00,\n",
      "         1.0164e+00, -2.3493e+00,  4.3328e-01, -4.7192e-01,  3.8348e-02,\n",
      "         2.2390e-01, -6.9014e-02, -1.4051e-01,  7.9474e-01, -1.8916e-01,\n",
      "         1.6112e-01, -1.3122e+00,  1.0782e+00, -8.3441e-01,  4.5891e-01,\n",
      "        -9.0378e-01,  1.0776e+00,  3.5492e-01,  6.7974e-01,  8.5984e-01,\n",
      "         6.2570e-02,  4.7049e-01,  4.9977e-02, -5.9910e-02,  5.8082e-01,\n",
      "         7.0209e-01,  1.8570e+00,  3.3905e-01, -3.4004e-01,  9.5000e-02,\n",
      "        -7.0462e-01, -1.1546e+00,  2.6067e+00,  2.8814e-01,  9.5239e-01,\n",
      "        -6.3638e-01, -2.4426e-01, -1.0868e+00,  4.2619e-01,  1.0016e-01,\n",
      "        -7.8702e-01, -5.4084e-01, -1.4274e-01, -1.9805e-02, -7.1918e-01,\n",
      "         1.7290e-01, -1.2436e+00,  3.1620e-01, -1.0714e+00,  6.6434e-02,\n",
      "        -4.5941e-01,  7.2912e-02,  6.2007e-01,  5.5581e-01,  1.1954e+00,\n",
      "         2.0939e-01, -5.0785e-01,  2.0959e+00, -8.1876e-02,  4.2700e-01,\n",
      "         5.0943e-01,  1.4900e+00,  4.3161e-01,  1.8884e+00,  6.2704e-01,\n",
      "        -1.4820e+00,  2.1680e-01,  8.0652e-01, -2.0691e-01,  6.6663e-02,\n",
      "        -4.1691e-01,  1.7703e+00,  6.1042e-01,  1.5419e+00, -3.6541e-01,\n",
      "         1.2856e+00, -8.3941e-01, -3.8372e-02,  7.4279e-01, -2.1912e-01,\n",
      "         1.5360e+00,  4.8248e-01,  8.2361e-01,  1.0086e+00, -8.2352e-01,\n",
      "         4.2431e-01,  8.4797e-01, -1.1859e+00, -4.4374e-01,  1.7759e+00,\n",
      "         2.6485e+00, -1.6682e+00,  1.4951e+00,  1.2841e-01,  9.0137e-01,\n",
      "        -5.5399e-01, -5.4908e-01, -1.6300e-01,  5.8974e-02,  7.7423e-01,\n",
      "        -1.1408e+00, -2.3258e+00,  1.7219e+00,  1.4725e+00,  4.4545e-01,\n",
      "         1.3608e-01, -3.4079e-01,  8.4047e-01, -1.5302e+00, -1.3600e+00,\n",
      "        -1.1235e+00, -1.1894e+00, -3.1683e-01, -8.8800e-01, -1.8915e+00,\n",
      "        -2.5639e-01, -2.3428e+00,  4.5652e-01, -4.4602e-01,  5.0303e-01,\n",
      "         7.9082e-01, -5.1529e-01, -7.5383e-01,  1.2808e+00, -1.0749e+00,\n",
      "        -6.3119e-01, -5.7263e-01,  2.3266e-01,  1.6130e+00, -2.6413e-01,\n",
      "        -1.5035e+00,  6.3873e-01,  3.8395e-01, -3.2821e-01, -9.4901e-01,\n",
      "         8.1626e-01,  1.2318e+00, -5.8183e-01,  7.6981e-01,  1.2267e+00,\n",
      "         2.7440e-01,  6.3441e-01, -1.2575e+00, -8.4964e-01, -1.4209e+00,\n",
      "        -2.0525e+00,  8.5586e-01, -2.0060e+00,  5.1493e-01,  4.4926e-02,\n",
      "        -1.1243e+00,  1.6439e+00,  3.8856e-02, -2.6801e-01,  3.7889e-01,\n",
      "        -1.6657e+00,  2.1121e+00,  4.7003e-01,  1.6673e+00,  1.4359e+00,\n",
      "         3.1666e-01, -1.8693e-01,  4.3260e-01, -7.3865e-01, -1.6888e-01,\n",
      "        -8.2745e-01,  4.4106e-01, -9.3589e-01, -6.0546e-01, -1.1373e+00,\n",
      "        -6.7438e-01,  6.9004e-01, -1.2898e+00, -8.5722e-01,  1.2332e+00,\n",
      "        -2.8805e-01, -5.1052e-01,  7.3412e-01,  6.2072e-01, -1.3678e-01,\n",
      "        -1.4201e-01, -7.5883e-03, -2.6767e+00, -7.6234e-01,  8.5236e-01,\n",
      "         5.6856e-02, -7.2773e-01,  1.2267e-01, -9.7834e-01,  5.1376e-01,\n",
      "         3.3411e-01,  1.3300e+00, -4.7372e-01, -1.1496e+00,  1.8684e+00,\n",
      "         7.2719e-01, -6.1977e-02, -1.3151e+00, -6.8870e-01,  8.6271e-01,\n",
      "         3.0699e-01,  5.7380e-01, -9.4069e-02,  4.6136e-01,  8.2800e-01,\n",
      "         3.8674e-01,  1.2559e-01, -4.6637e-01, -6.6718e-01,  7.6186e-01,\n",
      "         5.8211e-01,  1.2183e+00,  1.0905e-01,  3.3896e-01,  1.3243e+00,\n",
      "         2.9844e-01,  1.4861e+00,  4.9099e-01, -1.4104e+00,  1.1438e+00,\n",
      "        -1.6922e+00, -9.0433e-01, -7.5813e-01, -8.7738e-01, -3.2076e-01,\n",
      "        -4.6825e-01, -7.2635e-01,  1.1144e-03, -7.2225e-01, -3.4616e-01,\n",
      "         6.9479e-01,  1.1173e+00,  1.8688e+00,  2.0539e-01, -1.7454e-01,\n",
      "         6.0237e-01, -5.1255e-01, -7.0896e-01,  7.4415e-01,  6.1457e-01,\n",
      "        -1.3599e+00, -1.3151e+00, -9.6092e-01,  2.3501e-01,  4.3561e-01,\n",
      "        -5.8040e-01,  4.6350e-01,  1.0027e+00,  5.3332e-01,  6.2659e-01,\n",
      "         4.7085e-01, -2.4516e+00,  2.2334e-01, -7.2773e-01, -1.5475e-01,\n",
      "        -3.6478e-01, -5.8729e-01, -1.0755e+00,  8.3631e-01,  4.4258e-01,\n",
      "        -4.9116e-01, -1.7064e+00,  6.5128e-01, -1.7775e-01,  5.9177e-01,\n",
      "        -1.7584e+00,  2.9596e-01,  5.9606e-01, -1.0755e+00, -1.2221e+00,\n",
      "         1.5103e+00, -1.7211e+00, -3.5132e-01,  1.9871e+00,  8.4459e-01,\n",
      "         9.5885e-01,  2.2156e-01,  1.2679e+00, -2.6715e-02, -1.1446e-01,\n",
      "        -1.8737e+00, -3.3209e-01, -1.2168e+00, -1.2257e+00,  2.2572e-01,\n",
      "         1.2483e+00, -3.1807e-01,  9.7262e-01,  2.4968e-01,  6.2445e-01,\n",
      "         8.6025e-01,  5.9226e-01, -7.8353e-01, -1.0757e+00,  1.5338e+00,\n",
      "         1.4497e+00,  2.9066e-01,  1.6366e+00, -8.5775e-01,  1.2667e+00,\n",
      "        -2.1525e-01, -3.7695e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-0.7504,  0.3307,  1.1889, -0.1797,  0.4551, -0.2385,  0.3020,  0.3964,\n",
      "        -0.5703, -1.2782, -0.0379, -1.4034,  0.9590,  0.0099,  0.9522,  1.4344,\n",
      "        -1.1014, -1.8471,  0.1693, -0.9546,  1.4319,  0.8903,  0.8522, -1.3764,\n",
      "         0.2885, -0.0727, -1.9786, -1.7993,  0.1210,  0.5786, -0.8996, -0.2015,\n",
      "        -0.2142,  1.3566, -1.0467, -0.2777,  0.9662, -0.9339, -0.8660,  0.5690,\n",
      "        -1.6367, -1.2919, -0.3426, -0.9690,  0.4440, -0.9708,  0.5877, -0.9867,\n",
      "         1.0085,  0.6473,  0.8648,  0.0203, -1.8394,  1.0840,  1.4080,  0.6950,\n",
      "        -0.8276,  0.1367,  1.5239, -0.0234,  1.5090, -0.9798,  0.1744,  0.2268,\n",
      "        -1.1804, -1.1009,  0.1866, -0.2109, -1.2063,  0.4134,  0.6401,  0.8016,\n",
      "        -0.2500,  0.0466, -0.1226,  1.6164,  0.4022, -0.5826, -0.0856,  1.3567,\n",
      "         0.4002, -0.3948,  0.9759,  0.3123,  0.8401, -0.1592,  0.4744,  1.3961,\n",
      "        -0.0657, -0.1925,  0.8939,  0.0873,  1.0628,  1.7551, -0.6340,  0.4578,\n",
      "         0.2988, -0.2587,  0.6627,  1.9613, -1.1302, -0.9525,  0.5244,  0.6685,\n",
      "        -0.7214, -0.2801, -0.5120,  1.4162, -0.5164,  0.8006, -0.6180, -1.2510,\n",
      "        -0.0455, -1.7446,  0.3919,  0.0274, -2.4785,  0.5470, -0.7437, -0.0895,\n",
      "        -0.4452, -0.5428, -0.7256, -0.5121,  0.3895, -0.8705, -1.3791,  0.7412,\n",
      "        -0.4045,  1.1329,  0.5078, -0.6499, -0.9989,  0.3185,  0.8239, -2.3652,\n",
      "         2.0420,  1.1559, -0.2084,  1.9962, -0.9739,  0.9744, -1.1922, -1.8917,\n",
      "         0.9056,  0.1586,  0.7926, -0.6207,  0.8054, -0.1170,  1.2409,  0.6600,\n",
      "         2.1661, -0.1774,  0.1110,  0.4225, -0.0848,  0.3466, -0.7631, -2.1882,\n",
      "         0.2719,  0.1662,  0.2923, -1.0385,  0.4762,  0.7655,  0.4460, -0.2891,\n",
      "        -0.3066, -1.2684,  1.3048, -0.1688, -0.4136,  1.8192, -1.2687,  0.1156,\n",
      "        -0.3577,  0.9496,  0.3266,  0.1149, -1.4874,  1.4921,  0.3631,  0.0513,\n",
      "         0.9077, -0.0278, -0.2975,  0.2053, -0.7905,  1.5896, -1.3326,  1.4535,\n",
      "         1.5136,  0.6979, -0.7753, -0.0797,  0.8933, -1.5865, -2.8705, -0.2598,\n",
      "        -0.5357,  0.9557,  1.5877, -1.3100, -0.8385, -0.4479, -1.5694, -0.5087,\n",
      "         0.9920, -0.0290, -0.4488, -1.1622,  0.7778, -1.0847,  1.1099,  0.3768,\n",
      "        -0.6814,  1.6994,  0.3495,  0.1313, -1.2125, -0.4133,  0.3382, -1.4008,\n",
      "         1.6466,  0.4950, -0.3221,  1.3289,  0.7555,  0.3506, -0.8889, -0.1805,\n",
      "        -0.5240,  0.4309, -0.7121, -0.6457, -0.3073,  0.7066, -1.7207, -2.0986,\n",
      "         0.5175, -0.3444, -0.6635,  0.0468, -1.8558,  0.0919, -0.7158,  0.3148,\n",
      "         1.3764, -0.7770, -0.2787, -0.6062, -0.4592, -0.6404,  1.0975, -1.2084,\n",
      "        -0.0559, -0.7027, -1.0166, -1.8683,  0.3301,  0.7017,  0.4275, -1.1290,\n",
      "         0.1254,  0.9455, -0.4284, -1.2824, -0.2163,  2.0310, -0.5892, -2.6387,\n",
      "         0.2871,  0.9723,  0.8353, -0.0239,  1.5444, -0.7838, -0.6200, -0.2476,\n",
      "        -2.2379,  1.1104, -0.3804,  0.0345,  0.9600, -0.1915,  1.1250,  1.5672,\n",
      "         0.0503, -0.5717,  0.5345, -0.2425,  0.4562, -0.4484, -0.6491,  1.1844,\n",
      "        -1.0267,  1.0339,  0.3380, -0.2015,  0.6605,  0.0422,  0.1583,  1.1028,\n",
      "        -1.3520, -0.3794,  1.2837,  0.6935,  2.4659,  0.0182,  0.6813, -1.8906,\n",
      "         0.5508, -1.3803, -0.5619, -0.5565,  1.9952,  1.2809,  0.3816,  0.3348,\n",
      "         0.7241,  0.2163, -3.2037, -0.0758,  0.0477,  0.9328,  1.1508,  1.6287,\n",
      "        -0.5876, -0.3290, -0.5660,  0.6235,  0.8290,  0.4471,  1.4814, -0.6217,\n",
      "        -1.0007, -0.4594, -1.1678,  0.9717, -1.2264,  1.0469,  0.5557, -0.5625,\n",
      "         0.9440, -0.9814, -0.7207, -0.8293,  0.3572, -0.3558,  0.6082, -0.8350,\n",
      "        -0.1453,  0.9702, -0.2615, -1.0350,  1.1619, -0.9494, -1.1617, -2.2713,\n",
      "        -1.3153,  2.1866, -0.5869,  0.5863,  0.5625,  0.9849, -0.5078, -0.2339,\n",
      "        -1.0275, -0.7601,  0.1333, -0.8738, -0.6843,  1.6700,  1.2572,  0.2745,\n",
      "        -1.6771, -0.1209,  1.0814, -0.3502, -0.8827,  0.3480, -0.2602,  0.6152,\n",
      "         0.1692,  0.6783, -0.6858, -0.1144,  0.1485, -0.9948, -0.1695, -0.6526,\n",
      "         0.4156,  1.9687, -0.5675,  0.2630, -0.6254,  0.7081, -0.9420, -0.8826,\n",
      "        -1.8052,  0.5378,  0.0949, -0.4008,  1.2614,  1.3561, -0.5987, -0.0456,\n",
      "         0.3407,  0.7499,  0.2387, -0.5059, -0.3471, -1.6377, -1.8931, -0.5449,\n",
      "        -0.8162,  0.0195, -2.5477, -0.0890,  1.1402,  2.0917,  1.0522,  1.5690,\n",
      "        -1.3152,  0.0594,  0.6033, -0.8900,  0.8229, -0.7064, -0.4799, -0.1496,\n",
      "         0.1460, -0.6779, -1.1489,  0.7961, -2.4001,  0.4305,  2.0857,  0.4562,\n",
      "        -0.4430, -0.1794, -0.6101, -0.4280,  0.3718,  2.2594, -0.6633, -0.2723,\n",
      "         1.7358, -0.7143, -0.8630, -0.0437, -0.2681, -1.5857,  2.6693,  0.8341,\n",
      "         1.5734,  0.9690, -0.8671,  0.0320, -1.4927,  0.3371, -1.1928,  1.0526,\n",
      "         0.3028,  0.3294,  0.0487,  0.0846,  0.9330,  0.8237, -0.5224, -1.4377,\n",
      "        -2.4455,  0.0306, -1.2102,  0.0402,  0.9468, -0.1233,  1.1659,  0.6326,\n",
      "        -0.2395, -0.4908, -0.0631,  0.6146,  1.2287,  0.9718, -1.3850,  1.0913,\n",
      "        -0.6968, -2.5954,  0.6071,  0.6172,  0.6222,  1.1954, -1.2100, -0.6661,\n",
      "         1.3550,  1.5153, -0.8437, -0.6585, -1.5876,  1.0028,  0.6496, -1.2787,\n",
      "        -1.5123,  0.3077, -2.7209, -0.4437,  2.0181,  0.4162, -0.3113,  0.6106],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 0.7531, -0.7363,  0.8928, -0.6926, -0.9729, -0.9755,  1.0935,  1.0393,\n",
      "        -0.9137,  0.5936,  0.9871, -0.3495,  0.7887,  0.1816,  0.4229,  0.9720,\n",
      "        -0.3118, -1.5541, -0.6221,  0.4309,  0.6774, -0.5444,  0.3009, -0.9206,\n",
      "        -0.0292,  0.4168, -1.0160,  0.4018, -1.3898,  0.8555, -1.0936, -0.9428,\n",
      "        -0.3020,  0.3498,  0.1285,  0.0478, -0.2251,  1.2518, -1.7093, -0.5349,\n",
      "        -0.4390, -0.4821,  1.5870, -0.9253, -0.7118,  0.2389,  0.1552, -0.1675,\n",
      "        -0.0340, -0.9234,  0.4944,  0.8247, -0.8528, -0.8063, -0.0886,  0.5622,\n",
      "         0.5651,  0.9036,  2.2625,  0.9145,  0.1182, -1.7542, -0.2661, -0.3209,\n",
      "         0.0141, -1.1732,  0.4513, -1.7826, -0.7659,  1.0393, -0.7496, -0.3706,\n",
      "        -0.4737,  0.4156, -1.3194, -0.0606, -0.1240, -0.3378,  0.1365,  0.4346,\n",
      "        -0.0226,  0.3109, -0.6643,  0.1879,  0.2790, -0.6583, -0.3708, -1.4896,\n",
      "        -1.2785, -1.6092, -0.2999,  0.5370, -0.5264, -0.7987, -1.6887, -0.8052,\n",
      "         1.6229, -2.0226,  0.7470, -1.8787, -0.2243, -1.7264,  0.5807,  0.3209,\n",
      "        -0.0954,  0.0412, -0.6439,  0.3075, -1.9031,  1.1356,  0.1921, -0.9154,\n",
      "         0.5824,  0.0662, -0.4993, -0.1421, -1.1804, -0.0766,  1.3365, -0.9382,\n",
      "        -1.2681,  0.3607, -0.4597, -0.0202, -0.1164, -0.7065, -0.5318,  1.0709,\n",
      "         0.4391, -0.4096, -0.6896,  0.5782,  0.3683,  0.3523,  0.2609, -0.5519,\n",
      "        -1.0848,  0.0516, -0.2046,  0.0396, -0.1243, -2.1491,  1.6711,  0.8034,\n",
      "         0.6021, -0.2712,  0.3674, -0.7799,  0.4861, -1.5102, -1.1974, -0.0139,\n",
      "         1.6280,  0.9664, -0.2378, -1.8276,  0.8376,  0.3006, -0.7687, -0.3457,\n",
      "         0.3601,  0.1684, -1.3267,  0.6908, -0.1530,  1.6892,  0.1517, -1.4973,\n",
      "        -0.0112,  1.5692,  0.7724,  0.2470,  1.5443,  1.7797,  0.7531,  1.0053,\n",
      "        -0.0217,  0.7802,  0.8498,  2.0872, -0.3318,  0.5337, -0.2782, -0.0662,\n",
      "         0.5003, -1.7339, -0.6287, -0.7887, -1.8656,  1.0569,  1.4321, -0.6949,\n",
      "        -0.4006,  1.0018, -0.2719,  1.1059, -0.5218, -1.1461,  0.1634,  1.0861,\n",
      "        -0.5496,  1.5562, -0.9962,  0.0463,  0.1726,  0.5462, -0.6034, -0.5219,\n",
      "         0.8430,  1.0978,  1.2473,  0.5526,  1.6220, -0.6585, -1.6148, -0.4585,\n",
      "        -0.1562, -0.1353, -0.5096,  0.6394, -1.2088, -0.5361, -1.1708, -0.3309,\n",
      "        -0.8581, -1.0179,  0.5968, -0.9728, -0.3434, -0.1339, -0.6434,  0.4880,\n",
      "         2.2742, -0.0944,  2.0528, -2.7674,  1.3111, -0.2010,  1.1696, -0.2611,\n",
      "         0.8821, -0.6592, -0.7563,  0.4887, -0.6544, -1.1268, -1.3197,  0.9344,\n",
      "         1.7936, -1.6109, -0.2454, -0.9013,  0.0880,  0.5533,  1.0549, -0.9758,\n",
      "        -0.1407,  2.8095, -0.9099, -0.7303, -0.3417,  0.6089,  0.9300,  1.0198,\n",
      "        -1.1946,  0.2425,  0.6574,  0.0875,  0.2764,  0.4373,  0.9318,  0.2355,\n",
      "        -0.5537,  0.5667,  2.8802, -1.3356,  0.8170, -0.4472,  0.4926,  0.5994,\n",
      "         0.4054,  0.6441,  0.5927,  1.8441, -1.5811,  0.3903, -0.4566, -1.6355,\n",
      "         1.1076, -0.4159, -0.6460, -0.6793, -1.5635, -0.9606,  1.1145, -0.5555,\n",
      "         0.4238,  0.4527,  0.2129, -2.1143, -0.9769,  0.6322, -0.3952, -0.5822,\n",
      "         0.7836,  1.3863, -1.2708, -0.5403, -0.9627,  0.0259,  0.6504, -0.3424,\n",
      "        -0.7688,  0.3877, -1.0616,  0.4675,  0.6993, -0.1053, -0.5111, -0.7019,\n",
      "        -0.4515, -0.7530, -2.1695, -1.7280,  0.7451, -0.9084,  1.5538, -1.5810,\n",
      "        -0.5175, -1.4113,  0.8039,  0.5204, -0.9799, -0.1805, -0.4348,  1.4107,\n",
      "         0.3819,  1.4586,  0.1360, -0.9129,  1.0682,  0.3539, -0.6722, -1.7417,\n",
      "         0.5952, -0.1645,  1.2694,  0.2523, -0.2948,  0.0218, -0.0507,  0.6350,\n",
      "         0.7397,  0.0163, -0.7734, -0.4175,  0.2264, -1.0855, -1.7458, -0.2367,\n",
      "        -0.7154,  0.7537, -0.0368, -0.0862,  0.0316, -1.5801,  0.7899, -1.0933,\n",
      "        -1.0679,  0.5226,  0.6205,  2.6632, -0.5921, -1.1175, -1.2108,  2.3375,\n",
      "         0.1418, -0.6485,  1.8897, -1.5954, -1.4534, -1.1107, -1.1256, -0.8515,\n",
      "         0.8228, -0.8361, -0.0713,  0.5084,  0.3113,  1.0339, -0.8551, -0.5366,\n",
      "        -0.4159,  0.8081, -1.2260, -0.2649,  0.5234, -0.3557, -0.3537,  0.1824,\n",
      "         0.6466, -0.0899,  1.2596,  1.6836, -1.1636,  0.1605, -1.3545, -0.3573,\n",
      "         0.6436, -1.5709,  1.4277,  0.5909, -0.4769, -1.0870, -0.8652, -0.5768,\n",
      "         0.7664, -0.5004, -0.2625,  0.8998,  0.1734,  0.1667,  0.7461, -0.4351,\n",
      "         1.4735,  1.0565, -0.2099, -0.2343,  1.9185, -0.6999, -0.3322,  0.5428,\n",
      "         1.7023, -0.4736, -0.9804,  0.2349, -0.4837, -0.4915, -0.0168, -0.2390,\n",
      "         0.0975, -0.9108, -0.6732, -0.8357,  0.5374,  0.8895, -0.1526,  2.2781,\n",
      "        -2.0240, -0.1147, -0.1071, -0.9650,  0.8701, -0.5172,  1.5668,  1.0746,\n",
      "         0.5556,  0.5889, -1.1191, -0.1289,  3.0657,  0.8460, -0.3935,  0.5152,\n",
      "         0.5259,  1.7780, -1.0691,  0.7091, -1.0254,  2.3092, -2.1163, -0.5794,\n",
      "         1.1337,  0.0414, -0.4115,  1.2584, -0.2627,  0.8886, -1.8166,  0.1700,\n",
      "         2.4251,  0.6248,  0.3373,  0.6689,  0.7182, -0.6244,  0.2550, -1.6057,\n",
      "         0.6256, -0.5297, -1.6698,  1.1108, -0.5659, -0.0678, -0.5951,  0.3956,\n",
      "         0.3492, -0.6980, -0.2782, -0.3279, -0.3704, -1.4156,  0.1850,  0.8713,\n",
      "         0.3335,  0.5357, -1.3410, -0.5683,  1.7524,  1.1073,  1.1675, -0.4112],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-0.7338, -1.6763, -0.3549, -0.1941,  0.3507,  0.3863,  1.3906, -0.9792,\n",
      "         0.1711,  0.0990, -1.9581, -0.5358, -1.1627,  2.4011, -0.4018,  0.3463,\n",
      "        -0.1664,  0.4906, -0.5144,  0.7186, -0.2562,  1.0769,  0.0741, -1.4500,\n",
      "         0.3929,  0.5912,  3.0157, -0.0272,  0.1921, -0.6166, -1.9523,  0.3198,\n",
      "        -1.1175,  2.1696,  0.5832,  0.2077,  0.1342,  0.0925,  0.3341,  0.1134,\n",
      "        -0.6895, -0.7507,  0.2076,  0.5485,  0.3010, -0.3393, -1.3200, -0.0404,\n",
      "        -0.1357,  1.4580,  0.2741,  0.2274, -0.0402, -1.3432,  0.3028, -0.2210,\n",
      "         0.2724, -2.1004,  1.5401, -1.6025, -0.2388,  0.4070,  0.0787,  1.2822,\n",
      "        -1.1841, -0.5006,  0.4060,  0.8559, -0.6285, -0.8204, -1.2236,  0.1593,\n",
      "         1.4061, -0.9433, -0.5365, -0.5187, -1.4857, -0.8593, -0.2498,  0.1610,\n",
      "        -0.7126,  1.8801,  0.8612,  2.0391,  1.0779, -1.6493,  0.9477,  0.4302,\n",
      "         1.4652, -1.4035,  0.5981,  1.3011,  0.1538, -2.1954,  0.0304, -0.6577,\n",
      "        -0.5688,  1.2119,  1.8449, -0.0929, -0.2530, -0.6101, -1.6535, -0.2272,\n",
      "        -0.3697, -0.5863, -0.7604, -0.1907, -0.9142,  1.1486,  0.1790,  0.7350,\n",
      "         0.2150, -0.7916, -2.3360, -0.1395,  1.1555,  1.2025,  0.3322, -0.0598,\n",
      "         0.7787, -2.1193,  2.3882,  0.1306, -2.3048,  0.8446,  0.1590,  0.9846,\n",
      "        -1.2836, -0.8413,  0.6786,  0.8275,  1.1225, -0.9149, -0.6512,  1.1000,\n",
      "        -0.0643, -1.4170, -1.1849,  0.6092,  1.9047, -0.5397, -1.6372,  1.1076,\n",
      "         0.0221,  0.2886, -0.6413, -1.2043, -1.3903,  0.6350,  0.2534, -0.9842,\n",
      "        -1.4864, -0.6768, -0.7498,  1.2174, -0.1388,  0.9520, -0.3750,  2.2531,\n",
      "        -0.5735,  0.2455,  0.3494,  0.6056,  0.4169,  1.3836, -1.1760,  0.1170,\n",
      "         0.4367, -0.8242,  1.3980, -1.5933, -1.1925,  1.1181,  0.1971, -0.8573,\n",
      "        -0.9522,  0.6428,  1.5156,  0.0772,  0.3084, -0.4216, -1.9453, -0.7647,\n",
      "         0.4886,  1.0581,  0.5702,  0.0923,  0.4273,  0.2854, -0.3893, -0.7235,\n",
      "        -0.8131,  0.8662, -1.3173,  0.1910,  0.6195, -0.6078,  0.6392,  0.0195,\n",
      "         0.3726, -0.7921,  0.4373,  0.8827,  1.3645, -1.5965, -0.6290, -0.8963,\n",
      "        -0.6834, -0.2782, -1.2055,  0.1063,  1.8505,  0.4095,  0.4303, -0.2768,\n",
      "        -0.4975, -2.0144, -0.1946, -1.6336,  0.9752,  1.0738,  0.1957,  0.0630,\n",
      "        -0.7218, -0.3753, -0.5283, -0.0433,  0.5155, -0.5307,  1.5380, -0.5625,\n",
      "         1.2306,  1.5754,  0.7936, -0.1982,  1.4018, -1.6278,  2.4439, -0.1695,\n",
      "         0.8430,  0.3452, -0.2385, -1.4015,  0.3448,  0.3881,  1.0378,  0.1916,\n",
      "         2.2678,  0.5522,  0.1512,  0.3308, -0.3852, -2.0678,  1.3751,  0.9036,\n",
      "         0.9258, -0.0641, -0.2367,  1.5500,  0.9170, -0.9806,  1.1248,  0.6027,\n",
      "         1.9543,  0.0732, -0.8426,  1.1737, -0.2688,  0.0542,  0.5795, -1.5697,\n",
      "         1.1623, -1.3557, -0.3886,  1.1713,  0.1084, -0.4921, -0.8760, -0.7379,\n",
      "         1.0748, -0.8175,  1.4752, -1.5153, -0.4777,  0.2789, -0.4888, -0.0713,\n",
      "        -0.2453, -1.2795, -0.3798, -2.0271,  0.4051, -0.4117,  0.7516,  0.0076,\n",
      "         0.4287, -0.3696,  0.9039, -1.2289,  0.4509, -0.1373,  0.1655,  0.1205,\n",
      "        -0.8257,  0.4885,  1.4767, -0.2893,  1.3626, -1.0587,  0.8032,  0.4658,\n",
      "         0.7951, -0.0034,  1.4459, -1.4115, -0.1051,  0.1208, -1.5846, -0.5750,\n",
      "         1.6063, -0.6273,  1.0118, -1.7413,  0.4996,  2.3617, -1.8307,  0.1838,\n",
      "        -0.8856,  0.7201, -0.6958, -0.3077, -0.2590,  1.4315, -0.4085, -0.4394,\n",
      "        -0.1711,  0.4258,  0.7069,  0.8904,  0.0216,  0.9054,  0.5254, -1.7269,\n",
      "         0.3079,  1.4548, -2.2236,  1.8306, -0.1132,  1.7285,  1.8789,  1.0517,\n",
      "         1.5911, -0.0982,  1.8796, -0.3041,  2.0230,  0.1169, -0.4599, -0.5594,\n",
      "         0.4784,  0.4133, -0.5586, -1.3170, -1.3394,  0.2354,  0.2709,  2.2993,\n",
      "        -2.2636, -0.3295,  1.6524, -1.0919, -1.1053, -1.2513,  0.8901, -0.7066,\n",
      "         0.1894,  1.0276, -0.3520,  0.1459,  1.2593, -0.2546,  1.4322, -0.9330,\n",
      "         1.1960, -0.0747,  1.2727, -1.6243, -1.0163,  1.1843,  0.4317,  0.3775,\n",
      "         1.2234, -0.1683,  0.1165,  0.4793,  0.7389, -0.0092,  0.2473,  1.2257,\n",
      "         0.3983,  1.2734,  1.8937,  0.4771,  0.0320,  0.5802, -0.0719, -0.0478,\n",
      "         0.3242,  0.7125, -0.8031,  0.5583,  0.2270,  0.6165,  0.3771, -0.6013,\n",
      "         1.2926, -0.6156,  0.5517, -0.2977, -0.9133, -0.1515,  0.8524, -2.1772,\n",
      "        -0.9094, -0.9203, -1.3816,  0.0569,  1.5110, -1.6256,  0.5694, -0.8779,\n",
      "        -0.1757,  3.2988,  1.3390,  0.2852, -1.2785, -0.1847,  0.7580,  0.3324,\n",
      "        -0.5955,  0.7144,  0.2778,  0.4948,  0.3947,  0.2881, -1.2016, -1.1354,\n",
      "         1.4017,  0.0230, -0.2190,  0.1290, -2.3471,  0.9612,  0.4295, -0.2501,\n",
      "         1.5302, -0.0325, -1.6149, -1.7699, -0.5582,  0.7023, -0.7368, -1.3348,\n",
      "         0.1609,  0.4887,  0.0353,  0.3208,  1.6906, -0.6111,  1.5532,  0.4070,\n",
      "         1.2926,  1.6172, -2.4906,  0.1140,  0.1138,  0.0368,  2.0958, -1.2861,\n",
      "         0.6318,  1.2962,  1.3057, -0.3549, -1.0906,  0.5602, -1.4186,  1.3241,\n",
      "        -0.1216,  0.3878, -0.5689,  1.0375, -0.2962, -0.3892, -0.0404, -0.3786,\n",
      "        -0.6090, -1.0190,  0.6503, -0.7232, -1.3875, -0.3297,  0.8695, -0.2434,\n",
      "         1.0456, -0.6400,  0.4192,  0.7664, -0.3389, -0.2505, -0.5215,  0.2441],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.8494e-01, -5.3083e-01,  5.0437e-01, -2.2348e+00,  1.2542e+00,\n",
      "         1.5338e+00,  7.8169e-01, -2.3317e-01,  1.5286e+00,  1.3569e-01,\n",
      "         4.0290e-01,  1.8493e+00, -7.9454e-01, -1.5602e+00, -1.8538e-01,\n",
      "        -9.3167e-01, -1.3116e+00,  8.5722e-01,  5.9915e-03,  3.6848e-01,\n",
      "         4.7708e-02,  5.7125e-01, -1.5200e+00,  2.2264e-01, -9.6997e-02,\n",
      "         1.2475e+00, -3.0700e-01,  1.5349e+00,  1.4274e+00, -1.0634e+00,\n",
      "         1.1297e+00,  8.9071e-01, -1.1357e+00, -2.3466e+00,  1.3380e+00,\n",
      "         7.3773e-01, -5.5525e-01,  3.3381e-01, -5.3148e-02, -1.8414e+00,\n",
      "        -7.1288e-01, -1.4630e+00,  2.5522e-01, -2.5110e-01,  6.3704e-01,\n",
      "         7.2710e-01,  2.5356e-01, -1.7897e+00,  1.8913e-01,  2.4156e+00,\n",
      "         1.2734e+00, -5.2081e-01, -1.6202e-01, -4.2685e-01,  6.4619e-01,\n",
      "        -1.2554e+00,  4.4385e-01, -9.7687e-02,  7.7042e-01,  6.5347e-01,\n",
      "         5.2222e-01,  9.4024e-02, -1.1131e+00, -6.5163e-01, -9.9953e-01,\n",
      "         1.6715e-01, -2.3913e-01,  2.3532e-01,  2.0519e+00, -1.0220e+00,\n",
      "        -1.1361e+00,  2.4424e-01, -1.5875e+00,  7.2025e-01, -1.1364e-02,\n",
      "        -8.6575e-01,  1.0265e+00,  4.2020e-01,  1.1184e-02,  4.5980e-01,\n",
      "         5.0124e-01, -6.4380e-01,  2.0758e+00, -2.9185e-01, -5.6476e-01,\n",
      "        -2.4026e-01,  1.0855e-01, -1.3413e+00,  3.3621e-02, -5.7377e-01,\n",
      "        -8.1297e-01,  8.5123e-01, -9.8318e-02, -1.6718e+00, -9.8202e-01,\n",
      "         7.3319e-01,  1.3893e+00,  1.0714e+00,  2.0570e-01, -1.3056e-01,\n",
      "         1.4529e-01, -1.2653e-01, -2.0280e+00,  1.4347e+00, -2.7985e-01,\n",
      "        -1.1501e+00, -3.0113e-01,  1.2010e+00, -1.3659e+00, -2.1032e+00,\n",
      "        -1.7644e-01, -2.3151e-01, -4.8522e-01,  1.6083e+00, -8.8058e-01,\n",
      "        -9.8956e-01,  2.5451e-01,  1.0917e+00,  4.6900e-01,  1.2549e+00,\n",
      "        -1.9479e+00, -3.1013e-01,  1.0314e-02,  7.5544e-01,  1.6273e+00,\n",
      "        -2.0081e+00,  3.9316e-01,  6.0180e-01,  4.5822e-02,  8.9867e-01,\n",
      "        -2.6616e-01, -8.7266e-01, -6.8965e-01, -1.0193e-01,  5.6791e-01,\n",
      "        -2.8493e+00, -1.3319e+00, -2.2998e-01,  7.0324e-01,  6.6508e-01,\n",
      "         1.1100e+00,  5.5022e-01, -6.8976e-01,  1.5039e+00,  1.4083e+00,\n",
      "         8.7571e-01,  2.9360e+00,  1.0661e-02, -1.0201e-01,  2.5496e-01,\n",
      "         1.1868e+00,  9.9701e-01,  2.5359e+00,  6.3222e-01, -1.1614e+00,\n",
      "        -9.9059e-01, -1.0969e+00,  2.6930e+00,  9.7306e-03, -3.8605e-01,\n",
      "         1.2273e+00, -9.9410e-01, -1.1639e+00,  2.3151e+00, -2.1877e-01,\n",
      "         1.1039e+00,  6.7242e-01, -3.9824e-01, -1.8376e-01,  2.7450e-01,\n",
      "        -8.2624e-01, -2.6267e+00, -1.9227e+00, -5.4743e-01,  4.5923e-01,\n",
      "         1.1836e+00, -1.0979e+00, -1.1686e+00,  6.0074e-01,  9.9204e-01,\n",
      "        -1.0314e+00,  6.6879e-01, -6.7411e-01, -2.4292e+00, -2.0132e+00,\n",
      "         1.3071e+00, -2.2148e+00,  7.4446e-01,  8.1050e-01, -6.7657e-01,\n",
      "        -3.7547e-01,  5.5803e-02,  7.6287e-01,  8.0579e-01, -9.9187e-01,\n",
      "         7.2487e-01,  2.1018e+00, -8.2545e-01,  1.2863e-01,  1.2077e+00,\n",
      "         7.7330e-01, -1.8775e-01,  2.5892e-01,  2.7393e-01, -2.1341e+00,\n",
      "        -2.1400e-01,  4.3941e-01,  1.2994e+00, -3.3512e-01,  1.0251e+00,\n",
      "        -3.1259e-01,  1.6658e+00,  8.1700e-01,  1.1019e+00, -2.0538e-01,\n",
      "        -7.2627e-01, -2.9143e-01,  6.1002e-01,  2.8126e+00, -2.6082e-01,\n",
      "        -2.3117e-01,  1.0460e+00,  5.2025e-01, -2.3104e-01, -4.8281e-01,\n",
      "         1.2033e+00,  1.7325e+00, -5.1106e-01,  1.0929e+00,  1.2990e+00,\n",
      "        -1.0250e+00,  1.8018e+00,  1.2824e+00,  2.1462e+00, -7.9390e-01,\n",
      "         4.7252e-01, -1.7480e+00, -1.3392e+00, -8.6747e-01, -8.2664e-02,\n",
      "         2.3397e+00, -4.6811e-01,  8.8751e-01, -1.4594e+00, -5.6935e-01,\n",
      "         5.0961e-01,  8.3484e-01,  1.7012e-01,  1.3390e+00, -6.1806e-02,\n",
      "        -5.7468e-01,  1.3116e+00,  5.4598e-01, -2.5181e+00,  2.1035e-01,\n",
      "        -1.8985e-03,  1.6371e+00,  3.3547e-01,  6.7048e-01, -9.6956e-01,\n",
      "         5.4599e-01,  1.0069e+00, -2.2140e+00, -8.6218e-02,  3.5032e-01,\n",
      "         1.0314e-01,  6.6352e-01,  1.2339e+00, -1.0548e+00, -3.1536e-01,\n",
      "         4.5344e-01,  9.0382e-01,  1.6796e-01,  1.9390e-01, -7.0939e-02,\n",
      "         1.0526e+00,  8.8158e-02, -1.7172e+00,  1.0594e+00,  7.3139e-01,\n",
      "         2.4339e-01, -5.5323e-01, -1.8158e+00, -1.1148e+00, -7.9146e-01,\n",
      "         9.5212e-01, -7.7432e-01, -1.0271e-01, -5.3889e-01, -4.3248e-02,\n",
      "         6.1978e-01, -4.4540e-01,  1.6308e+00, -2.9676e-01, -2.2510e-01,\n",
      "         5.5301e-01, -7.5100e-02,  7.3965e-01,  2.1249e-01, -9.0268e-01,\n",
      "         1.6348e-01,  5.9654e-01, -1.4402e+00, -7.2802e-01,  8.4184e-01,\n",
      "        -1.4770e+00, -1.4944e-01, -8.6175e-01,  4.4818e-01, -5.7287e-01,\n",
      "        -5.7963e-01,  8.1081e-01, -1.4113e+00,  7.0815e-01, -1.5359e-01,\n",
      "         9.4431e-01,  1.5226e-01, -2.4177e-01,  1.8355e+00,  3.8035e-01,\n",
      "         1.4277e+00,  3.5892e-01,  5.1784e-01, -1.0406e+00, -8.1807e-01,\n",
      "         9.4077e-01, -5.4342e-01,  7.4878e-01, -5.6647e-01, -2.9158e-02,\n",
      "        -8.3583e-01,  1.5249e+00,  1.6380e-01,  2.6280e-01,  1.7382e-01,\n",
      "        -8.4719e-01, -7.1524e-02,  3.5117e-01, -1.3056e+00, -2.5551e+00,\n",
      "        -2.5588e+00,  6.5705e-01, -8.3318e-01, -2.1086e-01,  6.4568e-01,\n",
      "         5.1686e-01,  2.0706e-01,  1.4585e+00, -1.1359e-01, -6.3840e-01,\n",
      "         5.9003e-01,  1.3226e+00,  1.8790e+00,  1.7409e-01, -9.7798e-01,\n",
      "        -2.1582e+00, -1.9792e-01,  1.3617e+00,  9.7169e-02, -3.4257e-01,\n",
      "         5.0364e-01,  7.0160e-01,  2.5264e-01, -3.0277e-01, -8.8872e-02,\n",
      "         1.4782e+00,  1.2595e+00,  1.7062e+00, -9.8213e-01, -8.6793e-01,\n",
      "        -5.5957e-01,  5.3964e-01,  8.2897e-01,  1.4538e+00, -5.3004e-01,\n",
      "         1.0238e+00,  3.1112e-01, -5.4034e-01,  1.2097e+00,  4.2087e-01,\n",
      "         1.3177e+00, -1.3627e+00,  1.2301e-01, -8.2273e-01,  1.3489e+00,\n",
      "         5.6412e-01,  4.4240e-01,  1.5432e+00, -6.5495e-01,  4.8399e-01,\n",
      "        -8.1070e-01,  3.4751e-02,  5.3816e-01, -3.7201e-01,  3.2387e+00,\n",
      "        -8.1723e-01,  1.0183e+00, -6.4435e-01, -2.0318e-01, -1.7039e+00,\n",
      "        -9.5705e-01,  1.0293e+00, -6.0194e-02,  3.7015e-01,  3.9594e-01,\n",
      "        -2.7618e-01, -3.8931e-01, -4.0274e-01, -1.6167e+00, -5.3803e-01,\n",
      "         8.4657e-01, -1.2888e+00,  6.8032e-02, -2.0344e+00, -1.1979e+00,\n",
      "        -1.4070e-01, -1.6259e+00, -2.6542e-01,  5.5067e-01, -3.3141e-01,\n",
      "         9.0733e-01,  2.4775e-02, -1.2490e+00, -2.9502e-02,  3.3948e-01,\n",
      "        -6.0957e-01, -2.7840e+00, -9.4870e-01, -1.0262e+00,  1.2745e+00,\n",
      "         4.8812e-01,  2.0229e-01, -9.7506e-02,  1.0950e+00, -1.0176e+00,\n",
      "        -1.0305e+00, -6.4481e-01,  6.4164e-01, -2.9828e-01, -6.4573e-01,\n",
      "         1.3924e+00,  1.8329e+00,  2.3573e-01,  1.5202e-01,  7.8046e-01,\n",
      "         1.8348e+00,  5.7221e-01,  7.9079e-01, -1.6365e+00, -7.2097e-01,\n",
      "        -4.9818e-01, -1.1362e+00, -8.6395e-01, -2.5962e+00,  2.9025e-01,\n",
      "        -1.4630e+00,  9.7318e-01,  1.8503e+00, -9.0954e-01, -1.9161e+00,\n",
      "         3.6747e-01,  4.8166e-01,  8.4021e-01,  8.0009e-01, -1.0457e+00,\n",
      "        -6.1527e-01, -2.2077e-01, -6.4154e-01, -6.8613e-01,  4.8809e-01,\n",
      "         1.0239e+00, -1.2033e+00,  2.4721e-01, -2.5116e+00, -1.1259e+00,\n",
      "         2.1770e-01, -8.7179e-01, -1.3066e+00,  1.1798e-01,  2.2069e-01,\n",
      "        -4.1657e-01, -4.2480e-01,  1.0564e+00,  1.4128e+00, -2.5341e-01,\n",
      "         4.2452e-01,  2.0375e-01,  2.5851e-01,  5.5514e-01, -1.0675e-01,\n",
      "         6.2537e-01,  1.5423e+00,  1.2052e+00, -6.9371e-01, -5.7489e-01,\n",
      "        -1.6547e+00,  3.8874e-01,  4.8932e-01,  5.3868e-01, -3.3492e-01,\n",
      "         3.8575e-01, -4.7486e-01, -4.0958e-01,  1.1256e+00, -1.0248e+00,\n",
      "         5.5547e-01, -3.0076e-01, -9.9239e-01,  1.0192e+00, -1.6432e+00,\n",
      "        -1.4299e-02, -5.4758e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.5828, -2.5850, -0.4184, -1.4366,  0.4899,  1.2690,  0.0762, -0.2088,\n",
      "        -0.2807,  1.4218, -1.6907,  0.5848,  0.4817,  1.4945, -0.6189,  1.2972,\n",
      "         0.0674, -0.0747, -0.4317, -0.1685,  0.9797, -1.6274, -0.6748,  0.4099,\n",
      "        -0.5779,  0.3418,  0.3432,  1.2628, -1.2016, -0.7941,  0.8008, -0.1901,\n",
      "        -0.4885,  0.4134,  1.3825,  1.4457, -0.9252, -0.4914, -0.4576,  1.7002,\n",
      "         0.9585,  0.7553, -0.0948,  0.1450, -0.4939,  0.7574, -2.3014, -1.3179,\n",
      "        -1.0397,  0.9058,  0.3476,  1.0643,  0.1655, -1.2083, -1.1139,  0.4503,\n",
      "        -0.5100,  1.6227, -1.3723, -2.4958,  0.0358, -1.1878, -2.1305,  0.5133,\n",
      "         0.1955, -0.2032, -0.3839, -0.0883, -0.4293,  0.3451,  0.2779,  0.3813,\n",
      "         1.0922, -0.5503, -0.1928, -1.5591,  1.5928,  0.3625, -1.3894,  0.7410,\n",
      "        -0.9530, -0.8856, -1.2927, -0.3117, -0.3066, -0.0126,  0.1811,  0.1278,\n",
      "         0.3031,  0.5067, -0.8633, -0.1588,  0.5480, -0.4393, -0.0624, -0.4171,\n",
      "         0.7000, -0.7898, -0.7727, -0.2323,  2.1912, -0.7568, -0.1447, -0.3940,\n",
      "         1.8874, -0.9683,  0.8311,  0.9498,  2.7729, -1.5473,  0.0107, -0.0945,\n",
      "        -0.6174,  0.9125, -0.6663, -0.3886, -0.9036,  0.7050, -0.4302, -0.3134,\n",
      "        -0.9042,  0.8806,  1.4535, -0.7280, -0.4544, -0.0679,  0.8120,  0.1381,\n",
      "         1.8955,  1.0214,  0.6163,  0.4770,  0.4028, -1.9344, -0.4082,  0.5134,\n",
      "         1.1876, -0.9408,  1.6259,  1.4079,  0.0990, -0.1446, -0.8125, -0.9130,\n",
      "        -1.9667,  0.7770, -0.2023,  0.7761,  0.9414, -0.6948,  0.5187, -1.5244,\n",
      "        -0.9573,  2.5048, -0.3807,  0.1852,  0.1889,  0.3015,  0.0398,  2.0591,\n",
      "         1.1935, -0.1493, -0.4827, -1.1698,  0.7542,  0.3112,  1.1759, -0.3157,\n",
      "        -0.9479,  0.5538,  0.0620, -0.2759,  0.8776,  1.7487,  0.6623,  0.1467,\n",
      "         0.5255,  0.6878, -0.4850,  1.1396,  1.1819,  0.3123,  0.0760,  0.0977,\n",
      "        -0.8294, -0.5236, -0.5486, -0.9224,  0.9445,  0.5642, -0.2666, -2.0391,\n",
      "        -1.0619,  0.0532, -0.2695,  1.2224, -0.7397, -0.0030,  0.9943, -0.0245,\n",
      "         0.7209,  0.2041, -0.3528,  0.1138, -1.0456, -1.0203, -0.2492,  1.7174,\n",
      "        -0.0498,  0.4253,  0.5539,  1.5119,  0.4033,  0.0309,  0.9902, -0.5004,\n",
      "         1.2347, -0.9031, -2.3338,  2.0800,  0.2021,  0.7355,  0.1414, -0.5528,\n",
      "        -0.8634,  0.2581, -0.4707,  0.6302, -1.2080,  0.6636, -1.5823, -2.2376,\n",
      "         0.6514, -0.2646,  0.9188,  0.1573, -0.0922, -0.4532,  0.3207,  0.8153,\n",
      "         0.6653,  1.0361,  0.1784, -0.4251, -1.0736, -0.8142, -1.9507, -2.2962,\n",
      "        -0.8754, -0.7089,  0.2072,  1.6705,  1.0408, -0.3692,  1.0904, -1.6921,\n",
      "         0.3758, -0.9309, -0.8446,  0.0804, -0.9621, -1.4788, -1.2969,  1.7944,\n",
      "        -0.9324, -0.1954, -1.7262,  0.0990,  0.5251,  0.3665,  0.5633, -0.0508,\n",
      "        -1.0322,  0.4198,  0.6945, -0.6119,  0.6567,  0.5072,  0.1868,  0.6258,\n",
      "         0.0284, -1.1335,  0.9889,  0.3544,  0.9512, -0.0577, -0.4595, -1.2572,\n",
      "         0.3570, -1.0405, -0.5893,  0.2128,  0.2447, -0.2262,  0.6286, -1.0193,\n",
      "         1.3453, -0.2571,  1.3045,  0.7340, -0.4093,  0.0394,  2.5489, -0.0644,\n",
      "        -0.7820,  0.9673, -0.4993,  0.4136,  0.3636,  0.6402, -2.2121, -0.4092,\n",
      "         0.8483,  1.5174,  1.7731, -0.9300,  0.2929, -0.2923, -1.2141, -0.9003,\n",
      "        -0.9572, -2.4981,  2.1381,  0.0636, -1.7255,  0.7167, -0.1095,  0.0799,\n",
      "        -0.3274, -0.1597, -0.5532, -0.3212,  1.9419, -1.3146,  0.5795, -0.0967,\n",
      "         0.0736,  0.0484, -0.1479,  0.0889,  0.5474,  0.5927,  0.9624,  0.4553,\n",
      "        -0.4383, -0.2208, -0.5395, -0.5973,  0.4655, -0.4649, -0.0671, -0.9617,\n",
      "         0.0676, -0.4749, -0.2652,  1.7372,  2.8410, -0.4673,  0.4714,  1.1061,\n",
      "         0.3491, -0.8600,  0.5664, -0.1018, -1.5382, -0.5899, -0.0456, -0.2153,\n",
      "        -0.3922,  0.0218,  0.0979, -0.8745,  0.8840,  1.8319,  0.3396, -0.1920,\n",
      "         1.0503, -1.2735,  0.6541,  0.4892, -1.0430, -1.6922, -1.6445,  1.3302,\n",
      "         0.0815,  0.5069,  1.0136, -1.0569, -0.1679, -0.1517,  0.0064, -2.4330,\n",
      "         0.5920,  0.7088,  0.0263, -0.0219,  0.4910, -1.7334,  1.1527, -1.2753,\n",
      "        -0.8800,  0.8794, -0.4958,  0.5104, -0.4025,  0.8056,  2.8292, -0.5673,\n",
      "        -1.2021, -0.3201, -0.5742, -1.2168,  1.4681,  2.0476, -1.1091,  1.0665,\n",
      "         1.1632, -0.0253, -0.3468, -0.0065,  0.3165, -0.7493, -1.0977, -0.5913,\n",
      "         1.6626, -0.3426, -1.6241, -0.7627, -0.6986, -0.7392,  1.5739,  1.2055,\n",
      "        -1.3409, -0.6977, -0.3443, -1.7656, -0.1550, -0.0749,  1.1653, -0.3337,\n",
      "        -0.5978, -0.1993, -0.5117, -0.6743,  0.2145, -1.5921,  0.7318, -1.2669,\n",
      "        -0.4003,  0.9041, -0.9971, -1.8852,  0.5888, -0.2214, -0.8071, -0.3920,\n",
      "         0.4100,  0.3823,  1.8321,  0.3763, -1.2166, -1.5916,  2.4214, -0.2978,\n",
      "         0.2680,  0.0908,  0.5556,  0.6589,  1.2538,  0.0254, -0.4505,  0.0394,\n",
      "         0.4848, -0.0898,  0.6251,  0.1655, -0.8924,  1.8206, -0.4292,  1.1566,\n",
      "         0.5127,  0.4901, -0.9831, -0.7782,  1.7233, -1.3599,  0.6642, -0.7032,\n",
      "         0.6932,  0.1401,  1.0949, -0.7925, -1.6023, -0.5686,  0.8661,  1.0545,\n",
      "         0.4710,  0.2157, -2.5942, -0.6999,  0.4272, -1.4660, -0.9969,  0.7555,\n",
      "         1.9208,  0.0485,  1.1973, -0.1755,  1.0845,  1.4210,  0.1811,  1.1691],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-4.1335e-01,  3.0194e-01, -8.6662e-01, -5.1956e-01,  2.0644e-02,\n",
      "         8.7843e-01,  4.6416e-01, -3.6445e-01,  5.5976e-01,  2.2415e+00,\n",
      "        -1.5920e-01, -1.5543e+00,  4.0056e-01,  1.0187e+00,  9.4412e-01,\n",
      "        -6.4578e-01, -1.3567e+00,  1.1428e+00, -1.2860e+00,  4.2874e-01,\n",
      "         5.8904e-01, -4.8331e-02, -6.7086e-01,  7.2160e-01,  2.7882e-01,\n",
      "        -5.2857e-01,  5.9314e-01,  3.8809e-01, -9.1477e-01, -9.3298e-03,\n",
      "        -1.3226e+00, -3.9493e-01,  1.8224e+00, -1.2021e+00, -2.1620e+00,\n",
      "         9.7691e-01,  9.1869e-01, -1.4267e+00,  3.4721e-01,  8.0544e-01,\n",
      "         2.2163e+00,  4.6547e-02,  1.1199e+00,  2.4461e+00, -3.9709e-02,\n",
      "         6.9700e-01,  5.4505e-02, -1.2430e+00,  9.6754e-02,  1.5747e+00,\n",
      "         2.5621e-01,  5.5351e-01,  9.3672e-01,  3.2950e-01, -2.7166e-02,\n",
      "         6.3785e-01,  9.3300e-01,  1.0223e+00, -3.6151e-01, -5.4905e-01,\n",
      "        -1.1431e+00, -1.9924e-01, -3.2397e-01, -1.1236e+00, -2.6307e-01,\n",
      "        -5.1192e-01,  6.0801e-01, -6.7362e-01,  1.0835e+00,  6.4580e-01,\n",
      "        -3.8988e-01,  1.3635e+00,  5.1380e-01, -1.7313e+00,  8.1522e-01,\n",
      "        -1.0845e+00,  7.7664e-01, -6.8341e-02, -9.3345e-01, -2.3089e-01,\n",
      "        -4.5868e-01, -3.0104e-01,  2.4353e-01, -1.4776e+00,  9.6629e-01,\n",
      "        -5.1185e-01, -8.7357e-03, -5.6503e-01, -1.2521e-01, -8.0175e-01,\n",
      "        -1.8740e+00, -1.8989e+00,  3.9713e-01, -8.2771e-01,  4.5705e-02,\n",
      "         4.7766e-01,  1.1524e-01,  1.2772e+00, -9.5006e-01,  1.3849e+00,\n",
      "        -2.4613e+00,  1.2244e+00,  1.1899e-01, -7.2924e-01,  5.8722e-01,\n",
      "        -1.1759e+00,  1.6305e+00, -1.4126e+00, -6.6637e-01,  3.5115e-02,\n",
      "         5.9192e-01,  8.5371e-01, -5.4469e-01, -2.3474e-01,  1.5379e-01,\n",
      "        -1.0321e+00, -4.1937e-01,  2.4457e+00, -6.9040e-01, -6.0176e-04,\n",
      "         7.1143e-01, -1.3871e+00,  1.2326e+00,  7.2407e-01, -3.6976e-01,\n",
      "        -9.9232e-01,  1.3184e+00,  3.7834e-01,  6.5659e-01, -1.4258e+00,\n",
      "         4.6254e-01,  1.3403e+00, -6.5844e-01,  3.6992e-01, -1.9558e-01,\n",
      "        -7.5600e-01,  5.0978e-02, -8.0274e-02, -1.8317e+00,  1.3535e-01,\n",
      "        -2.1433e-01,  1.7002e+00,  5.2727e-01,  4.1556e-01,  2.8203e-01,\n",
      "        -4.0308e-01, -5.1460e-01, -1.0282e+00,  9.1132e-01, -6.9203e-01,\n",
      "         9.5491e-01, -4.8312e-01, -2.0151e+00,  3.9984e-01, -3.9439e-01,\n",
      "         1.1244e-01, -1.3616e+00,  2.8091e-01,  4.8651e-01,  1.9647e+00,\n",
      "         1.1098e+00,  1.4086e-01, -9.8093e-01, -1.4961e-01,  1.8313e+00,\n",
      "        -4.8995e-02,  3.6877e-02,  6.6078e-01, -3.3763e-02, -1.3888e-02,\n",
      "        -2.0514e+00,  5.6821e-01,  7.6813e-02,  1.5756e+00,  3.0344e-01,\n",
      "         5.2650e-01,  1.9541e-02,  5.2943e-01, -7.8409e-02, -3.7240e-01,\n",
      "        -9.0894e-01, -4.2264e-01, -2.0834e+00, -1.4424e+00, -1.5131e+00,\n",
      "        -1.6616e-01,  1.9593e+00,  9.1752e-01,  2.0256e-01,  2.1732e+00,\n",
      "        -2.0630e+00,  2.9367e-01,  2.2575e+00, -1.2909e+00,  5.4846e-01,\n",
      "        -6.8178e-01, -1.4412e-01, -8.6090e-01,  2.0179e-02, -5.0194e-02,\n",
      "        -1.0183e+00,  5.0720e-01,  9.9006e-01,  1.6785e+00,  1.8008e-01,\n",
      "         1.1972e+00, -2.1119e+00,  1.7205e-01, -1.4419e+00,  2.4696e-01,\n",
      "        -3.8177e-02,  2.2978e-01,  1.8492e+00, -1.4650e+00, -4.7577e-01,\n",
      "        -4.8931e-01, -9.5392e-02, -1.4543e+00,  4.0232e-01, -9.6220e-01,\n",
      "        -3.2430e-01, -3.5116e-01, -1.3372e+00,  4.3064e-01,  9.9846e-02,\n",
      "        -7.0995e-01, -1.1239e+00,  1.2466e+00, -1.2288e+00, -1.4926e+00,\n",
      "         3.3931e-01, -2.8187e-01,  8.7579e-01,  6.8007e-01, -5.6920e-01,\n",
      "        -9.9680e-01, -8.4879e-01, -1.2740e+00,  7.0993e-01,  8.6184e-01,\n",
      "        -5.8467e-01, -6.3103e-01, -4.1728e-01,  2.4824e+00, -4.5224e-01,\n",
      "         1.4914e-01, -2.1037e-01, -9.5287e-01,  1.6116e-01, -4.9333e-01,\n",
      "        -4.5950e-01,  9.8948e-01,  9.6986e-01, -5.0328e-01,  1.3626e-01,\n",
      "        -5.7057e-01,  2.3906e-01,  3.8331e-01, -1.3116e+00, -1.2842e+00,\n",
      "         1.2588e+00, -1.2924e-01,  1.0400e-01, -1.9237e+00, -1.1332e-02,\n",
      "         1.2617e+00,  6.1810e-01,  1.0584e-01,  9.6540e-01,  1.4493e-01,\n",
      "         3.8850e-01, -1.9402e+00,  8.3756e-02, -2.4229e-01,  8.7467e-01,\n",
      "         9.2331e-01,  6.0489e-01,  5.0711e-01,  8.4319e-02,  2.8285e-01,\n",
      "         1.3660e-01, -1.9480e-01,  3.3564e-01,  6.0156e-01,  1.5566e+00,\n",
      "        -4.6052e-01, -1.3313e-01, -4.3425e-01, -2.1645e-01, -4.5560e-01,\n",
      "         1.1711e-02, -3.8922e-01,  1.2593e+00, -9.5279e-01,  4.8343e-01,\n",
      "        -1.1958e-01, -1.8046e-01, -2.3377e+00,  9.3903e-01, -2.9313e-01,\n",
      "         1.5197e+00, -2.5872e-01,  1.2901e+00,  4.8193e-01, -5.1689e-01,\n",
      "         2.4458e-01, -4.6502e-01,  4.7922e-01,  5.2395e-01, -8.5800e-01,\n",
      "         2.5151e-01, -9.2566e-01,  5.7566e-01,  1.7971e+00, -1.3775e+00,\n",
      "        -3.0756e-01,  1.0986e+00,  1.3814e+00, -1.0144e+00,  2.1327e+00,\n",
      "         8.4659e-01,  3.7139e-01,  1.9258e+00, -1.6683e+00, -2.9113e-01,\n",
      "        -1.0880e+00, -7.8000e-01, -1.2050e+00, -7.9468e-01, -1.6691e+00,\n",
      "         9.9575e-01, -1.0240e+00,  6.0198e-01, -4.1158e-01,  5.6293e-01,\n",
      "        -6.3020e-03, -1.3453e-03, -3.4628e-02,  1.6458e-01, -1.2524e+00,\n",
      "         1.1385e+00,  1.6364e+00,  6.4809e-01, -2.6707e-03, -3.6337e-01,\n",
      "         4.8156e-01, -5.3286e-01,  1.6644e+00, -3.5725e-01, -2.9376e-01,\n",
      "        -1.7470e+00,  2.0427e+00, -1.0019e+00, -1.0024e+00, -3.0126e-01,\n",
      "         1.0444e+00, -6.1765e-01, -9.9216e-01,  6.3791e-01, -1.6509e+00,\n",
      "        -8.8304e-03, -9.0588e-02, -1.0946e+00, -3.1794e-01, -5.4478e-01,\n",
      "        -1.4985e+00,  4.6722e-01, -1.8330e+00, -7.8114e-01, -3.6914e-01,\n",
      "        -1.1258e+00,  1.4083e-01, -2.4867e-01,  4.3832e-01, -3.1052e-01,\n",
      "        -3.4069e-01, -2.6882e-01,  1.5560e+00,  7.1809e-02,  6.4502e-01,\n",
      "        -7.8866e-02, -2.8762e-01, -1.1773e-02, -9.7713e-02,  1.2261e+00,\n",
      "        -1.2088e+00, -2.3335e-01, -1.4423e+00, -7.1285e-01,  8.3110e-01,\n",
      "         2.8207e-01,  1.0377e+00,  1.3427e+00, -6.4276e-02,  9.1108e-01,\n",
      "         1.8732e-01, -2.2964e-01, -1.1929e+00, -6.7086e-01, -1.7078e-01,\n",
      "        -1.3651e+00, -8.7463e-01,  5.2636e-02,  7.4194e-01, -2.1247e-01,\n",
      "         1.7840e+00,  1.2896e+00,  8.1151e-01, -1.8439e+00,  1.1458e+00,\n",
      "         3.7538e-01, -2.0001e+00,  2.0142e-01,  2.7754e-02,  1.6740e+00,\n",
      "        -1.2785e+00,  7.4206e-01, -2.8672e-01,  1.4824e-01,  3.2577e-01,\n",
      "        -1.4911e+00,  1.2554e+00, -1.9318e-01, -2.8900e+00, -2.8427e+00,\n",
      "        -7.8476e-02,  1.2897e+00,  1.0982e+00, -4.1798e-01,  1.7098e-01,\n",
      "         6.5278e-01, -8.3212e-01,  1.2142e-01, -1.6468e+00, -1.6267e+00,\n",
      "        -3.0198e-02,  9.4695e-01,  4.7775e-01, -6.6321e-01, -1.1824e+00,\n",
      "         3.9484e-02, -9.9277e-01, -1.0724e-01,  2.0841e-01, -8.3189e-02,\n",
      "         9.2519e-01, -1.6020e+00, -5.6388e-01, -1.8250e+00,  8.1990e-01,\n",
      "         1.0130e+00, -1.4518e+00, -1.5830e-01,  3.6712e-01, -8.3498e-01,\n",
      "         7.5342e-01, -2.6071e-01,  1.3795e+00, -1.6581e+00, -1.6116e+00,\n",
      "         1.6775e-01,  1.8619e-01,  2.4087e-01, -1.0784e+00, -7.2980e-01,\n",
      "         4.9069e-01, -9.0804e-01, -1.2049e+00,  7.9558e-02,  1.0112e+00,\n",
      "         1.1919e+00, -2.8646e-01,  1.8098e+00, -7.7600e-01,  7.4352e-01,\n",
      "        -6.7261e-02,  4.2826e-01, -1.4841e-01,  2.2695e-02, -1.0356e+00,\n",
      "        -1.2856e-01,  9.0108e-01,  2.5476e+00, -5.5252e-01, -1.3899e+00,\n",
      "         4.0998e-01, -7.2052e-01, -3.3714e-01,  1.1965e+00,  1.8183e-01,\n",
      "        -2.4641e-01, -2.4035e-01, -1.2380e+00, -4.7481e-01,  2.5771e-01,\n",
      "        -2.3005e+00,  3.0100e-01,  1.0530e+00,  1.4244e+00, -1.6358e+00,\n",
      "         1.5540e+00,  8.2757e-01,  1.2252e+00, -3.5348e-01,  1.1624e+00,\n",
      "         3.1833e-01,  1.0952e+00, -5.9730e-01, -4.4952e-01, -2.6347e-01,\n",
      "         1.1804e+00,  1.1398e+00], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 6.8959e-01,  1.9578e-01, -2.7348e-02, -1.0140e+00, -2.7087e-01,\n",
      "         5.4964e-01,  6.4762e-01,  5.6917e-02, -2.4305e-01,  3.3667e-01,\n",
      "         1.3997e+00, -5.7851e-01,  4.8028e-01,  7.8750e-01, -1.4634e-01,\n",
      "         1.1515e+00,  3.7908e-02,  1.3175e+00,  1.5857e-01,  3.2813e-01,\n",
      "         2.2909e+00, -2.3603e-01, -2.0880e-01,  1.9747e+00,  4.5371e-01,\n",
      "         1.4964e+00, -7.2664e-01, -3.2924e-02, -1.2290e+00, -5.8619e-01,\n",
      "        -1.3075e+00, -9.2281e-01, -2.5965e-01,  8.7289e-01, -7.9056e-01,\n",
      "         1.7694e-01, -1.1409e+00, -7.0447e-01,  3.3018e-01, -1.3882e-01,\n",
      "         6.8301e-01,  9.0442e-01,  1.2863e+00,  3.7828e-01,  4.6970e-01,\n",
      "         3.1867e-01,  1.0424e+00,  6.3944e-01,  8.7179e-01, -6.1918e-01,\n",
      "        -9.3955e-01, -1.5795e-01, -6.6081e-02, -2.1641e-01, -4.0505e-02,\n",
      "        -2.4814e-02,  8.4200e-01,  1.1062e-01,  6.6414e-02, -8.3811e-01,\n",
      "         9.2452e-01, -1.0713e+00,  1.6362e-02, -1.0721e+00,  1.9611e+00,\n",
      "        -2.2817e+00, -1.3223e+00,  1.1526e+00,  9.2941e-01,  1.7352e+00,\n",
      "         1.5129e+00,  5.8977e-02, -3.6364e-01, -5.9913e-01, -6.6114e-01,\n",
      "        -2.7857e-01,  1.1156e+00, -1.8345e+00, -9.0540e-01, -6.8619e-01,\n",
      "         1.2540e+00,  7.2345e-01, -2.9085e-01, -2.9677e-01,  3.0626e+00,\n",
      "         5.7196e-01,  1.1529e-01,  4.1032e-01, -5.8531e-01,  1.4687e-01,\n",
      "         2.4253e-01, -3.7265e-01, -1.4957e+00,  3.1341e-01,  9.7644e-01,\n",
      "         1.2833e-01,  1.1179e+00, -1.3103e-01, -6.7962e-01,  8.4076e-01,\n",
      "        -2.2091e+00, -1.0951e-01,  1.3998e+00, -5.9847e-01, -9.6521e-01,\n",
      "         5.9842e-01,  1.3621e+00, -8.2915e-01,  6.9307e-01,  1.8260e+00,\n",
      "        -2.0677e-01,  1.5691e+00,  1.3443e+00,  5.6282e-01,  1.1590e+00,\n",
      "        -8.2495e-01, -2.9446e-02, -1.6363e+00,  7.1992e-01,  1.1467e+00,\n",
      "         1.3139e+00, -1.0070e+00, -7.9134e-01,  5.4269e-02,  6.0076e-01,\n",
      "         6.3374e-01,  2.4810e-01,  2.5725e-01,  1.3358e+00, -3.8166e-01,\n",
      "        -6.9914e-02, -8.9404e-03, -2.9113e-01, -1.6915e+00, -9.8418e-02,\n",
      "        -1.2081e+00,  3.6249e-01,  9.9006e-01,  1.6060e-01,  7.0385e-01,\n",
      "         1.5001e-01,  1.0924e+00, -6.1860e-01,  4.0496e-01,  1.7699e-01,\n",
      "         1.6225e+00,  6.3249e-02, -1.7781e-01,  1.2013e+00,  1.6996e+00,\n",
      "         1.1363e-01, -1.1313e+00,  1.6454e+00, -3.9534e-01,  7.2792e-01,\n",
      "        -3.5912e-01,  9.2930e-01, -4.4443e-01, -8.3078e-01,  1.3855e+00,\n",
      "        -5.3391e-01,  3.0963e+00, -1.5767e-01, -1.2676e+00, -8.1141e-01,\n",
      "        -1.7722e+00, -2.0941e-01,  5.2635e-01, -6.7627e-01,  8.2310e-01,\n",
      "         1.9325e-01, -1.5507e+00,  3.8287e-01, -3.4627e-01,  8.3732e-02,\n",
      "        -5.0375e-01,  3.2760e-01, -7.8361e-01,  2.2861e-01, -1.0347e+00,\n",
      "        -1.9505e-01, -5.0762e-01, -1.2952e+00, -2.2829e-01,  8.0824e-01,\n",
      "        -4.8287e-01, -7.6719e-01, -1.1979e+00,  1.0106e+00,  7.0537e-02,\n",
      "         1.9508e-01,  1.3228e+00,  1.2068e+00,  2.5613e-01, -1.0229e+00,\n",
      "         5.6795e-01,  1.5514e+00,  9.4147e-01,  2.7394e-01,  1.1641e-01,\n",
      "        -9.9636e-01,  8.6735e-01,  1.6688e-01, -1.4639e+00, -4.0940e-01,\n",
      "        -1.2389e+00,  5.5241e-02,  8.9772e-01,  3.5854e-02,  9.3296e-01,\n",
      "        -3.7601e-01, -1.1234e+00, -1.7732e+00, -4.4943e-01,  2.4546e-01,\n",
      "        -5.4883e-01,  7.3157e-01,  2.8268e-01,  3.9225e-01,  3.0489e+00,\n",
      "         2.6713e+00,  1.0702e+00, -8.8865e-01, -1.3777e+00, -1.4461e+00,\n",
      "        -9.4731e-01,  6.6618e-01, -1.7636e-01, -1.3917e+00, -9.1205e-01,\n",
      "        -1.8485e+00, -7.4824e-02, -1.9752e-01,  9.0524e-01, -4.0007e-01,\n",
      "        -3.1437e-02,  2.0418e+00, -2.9156e+00,  2.9400e-01,  8.0135e-03,\n",
      "        -4.3569e-01,  2.6242e-01, -1.1589e+00,  2.6331e-01,  1.5692e+00,\n",
      "        -1.9539e+00,  1.2078e+00, -1.6457e+00,  7.3462e-01, -1.9357e+00,\n",
      "         6.4377e-01, -2.8388e+00,  5.2163e-01,  4.6839e-01, -7.0089e-01,\n",
      "        -8.9434e-01,  2.0291e-03,  1.4223e+00,  1.0761e-01,  4.3142e-01,\n",
      "        -5.1610e-02,  4.7491e-01, -2.7326e-01, -5.8714e-01,  6.0114e-01,\n",
      "        -2.4824e-01,  4.3042e-02,  7.1157e-01, -1.1419e+00,  4.9362e-01,\n",
      "         1.1753e+00,  6.9426e-01, -1.8828e+00,  1.6005e+00, -1.0271e+00,\n",
      "        -5.8610e-01,  3.6323e-01, -5.1944e-01, -1.2805e+00, -5.3928e-01,\n",
      "         2.8997e-01, -2.4934e-01, -2.3912e-01, -6.5801e-01,  2.2165e+00,\n",
      "         2.6942e-01,  5.5633e-01, -1.6952e+00, -8.2189e-02, -9.9941e-01,\n",
      "         1.1807e+00, -8.3562e-01, -1.5650e+00,  7.4209e-01, -2.9089e-01,\n",
      "        -5.5114e-01, -5.6004e-01,  7.9492e-01, -2.1742e+00, -1.4349e+00,\n",
      "         9.4938e-01,  9.6071e-01, -1.4162e+00, -1.0776e+00,  6.5685e-01,\n",
      "        -1.7579e+00,  1.2082e+00,  1.4852e+00,  1.1027e+00, -2.1240e-01,\n",
      "         9.1257e-01,  7.7422e-01, -4.2610e-01,  8.6209e-01,  1.2364e+00,\n",
      "        -5.4831e-01,  1.5830e+00, -8.1045e-01, -9.3045e-01,  1.0953e+00,\n",
      "        -5.5514e-01, -2.1822e+00,  3.7085e-02, -8.0933e-01, -8.7608e-01,\n",
      "         9.5839e-01, -9.7323e-01,  4.4357e-01,  2.0998e-01,  8.4564e-01,\n",
      "        -1.1228e-01, -1.2183e-01,  7.3444e-01,  6.9224e-02, -1.8260e-01,\n",
      "         2.2683e+00,  3.3947e-02, -3.0931e-01, -1.5742e+00, -2.8988e-01,\n",
      "         2.3535e+00, -1.2900e+00,  8.7987e-01,  2.9074e-01, -1.0320e-01,\n",
      "         6.3080e-01,  6.1236e-01, -9.3849e-01, -5.2639e-01, -4.3571e-02,\n",
      "        -2.4483e-01,  1.2576e+00, -3.3036e-01, -1.4637e+00, -1.8021e+00,\n",
      "        -2.3595e-01, -2.4871e+00, -4.2259e-01, -1.0910e+00, -4.9351e-01,\n",
      "         1.7933e+00, -2.4389e-01, -3.6292e-01,  8.9720e-01, -1.7324e+00,\n",
      "        -8.9076e-02, -5.2670e-01, -1.2729e-01, -8.1000e-01, -4.8999e-01,\n",
      "         8.8614e-01,  2.2695e-01,  2.8627e-02, -1.2875e+00,  4.3302e-01,\n",
      "         1.1309e+00,  8.1072e-01,  4.9472e-01,  1.9056e+00,  8.3826e-01,\n",
      "         1.2243e-01,  2.2297e-01,  5.8859e-01, -1.0834e+00, -7.3375e-03,\n",
      "        -5.4179e-01,  1.8360e+00,  7.4176e-01, -8.3887e-01,  1.2348e+00,\n",
      "        -1.0221e+00,  9.7006e-01, -1.3325e-01,  3.5118e-01,  1.1261e-01,\n",
      "         2.4538e+00, -2.8221e-01,  7.9512e-01,  6.1134e-01, -3.2783e-01,\n",
      "        -2.7133e-01,  1.7692e+00,  2.2080e-01, -1.6375e+00, -1.5998e+00,\n",
      "         4.7948e-01, -3.6392e-01,  7.0572e-02, -1.0655e+00,  2.9926e-01,\n",
      "         1.1933e+00, -4.8968e-01, -1.6400e-02, -1.6562e+00, -1.7258e+00,\n",
      "        -1.6327e+00, -5.2549e-02, -1.3954e-03, -9.2572e-01, -8.4890e-01,\n",
      "         1.1737e+00, -8.6506e-03,  2.5049e-01,  2.3216e-01, -1.7140e-01,\n",
      "         1.4050e+00, -3.3479e-01, -2.7174e-02, -1.4063e+00, -3.5870e-01,\n",
      "         1.4133e+00,  1.0158e+00,  4.7641e-01, -2.0241e+00,  1.4922e+00,\n",
      "         1.5014e+00,  9.2783e-01,  9.9409e-01,  1.1670e-01,  6.0830e-01,\n",
      "        -1.8123e-01,  7.2458e-01,  1.5259e+00, -6.8250e-01, -6.3551e-02,\n",
      "        -1.3010e-01,  8.7836e-01, -1.5129e+00,  2.1785e+00, -1.5566e+00,\n",
      "        -7.9806e-01, -1.2679e+00, -2.7267e+00, -1.7204e-01, -3.4798e-02,\n",
      "        -1.5537e-01, -1.4328e+00,  2.9090e-01,  1.5268e+00, -1.5308e+00,\n",
      "         1.3139e-01, -3.6066e-02,  1.1716e+00, -1.6313e+00, -9.9574e-01,\n",
      "         9.2461e-01,  5.0857e-01,  1.4311e+00,  1.8388e-01,  2.8582e-01,\n",
      "        -1.7209e+00, -1.1425e+00, -1.3228e+00, -2.5200e+00, -2.0980e-01,\n",
      "         1.5647e+00,  5.9821e-01,  8.5884e-01, -8.6424e-01, -1.5175e+00,\n",
      "         4.2683e-01,  6.4841e-01, -4.6104e-01,  6.0117e-01, -1.2615e+00,\n",
      "        -1.2289e+00,  8.9144e-01, -3.3520e-01,  6.7347e-01, -9.7040e-01,\n",
      "        -3.1997e-01,  5.5413e-01, -1.7189e+00, -2.0284e+00, -8.5971e-01,\n",
      "        -1.7601e+00, -7.6058e-01, -8.5098e-02, -1.0292e+00, -1.7046e+00,\n",
      "         2.2797e+00,  2.3535e-01, -8.3762e-01,  9.3960e-01, -1.4121e+00,\n",
      "         1.7506e+00, -3.6442e-01, -7.7617e-02, -3.3592e-01, -1.5553e+00,\n",
      "         4.3025e-01, -1.2178e+00], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 1.3378e+00, -1.7574e+00,  7.7895e-01,  1.3577e+00,  4.5171e-01,\n",
      "         1.1284e+00, -2.7932e-01,  1.2496e+00,  4.3491e-01, -2.5349e+00,\n",
      "         1.0216e+00, -1.4387e+00, -1.5672e+00,  2.3250e-02, -1.6154e+00,\n",
      "        -6.6138e-01, -3.8621e+00,  6.8692e-03, -1.5035e+00,  3.1686e-01,\n",
      "        -9.5652e-01,  1.0628e+00,  2.2072e-01,  1.5761e+00,  3.6322e-01,\n",
      "         5.0772e-01,  2.5195e+00,  4.8471e-01, -1.7560e+00, -2.2407e+00,\n",
      "        -4.2652e-01, -5.3035e-01,  6.3301e-01,  1.7405e-01,  1.2252e+00,\n",
      "         1.0494e+00,  5.6955e-01,  5.0624e-01,  2.6796e-01,  6.0135e-02,\n",
      "         3.2632e-01, -1.1963e+00,  1.0301e-01,  1.1652e+00, -1.6620e+00,\n",
      "        -7.0642e-02,  1.0514e-01, -9.0798e-01, -7.8326e-01,  6.7686e-01,\n",
      "         1.8613e-01,  4.1161e-02, -5.0892e-01, -1.8839e-01,  6.6431e-01,\n",
      "         4.6446e-02,  3.7530e-01, -6.1265e-01,  1.6858e+00, -1.4189e+00,\n",
      "         2.2138e+00,  1.1727e+00,  1.0900e+00, -2.5804e-01, -8.6108e-01,\n",
      "         6.9648e-01,  1.4779e+00, -1.5208e+00, -3.7577e-01,  1.4037e-01,\n",
      "        -1.1886e+00, -3.5453e-01,  1.1596e+00, -4.4908e-01,  2.4077e-02,\n",
      "        -4.7661e-01, -7.0983e-01,  2.1009e+00, -8.5975e-01, -3.3839e-01,\n",
      "        -6.0363e-01, -5.1800e-01, -2.8580e-01,  2.0152e+00,  7.9156e-01,\n",
      "         6.3754e-01,  8.5429e-01, -2.4498e-01,  1.6545e+00, -1.5117e-01,\n",
      "         1.4007e-01, -2.6312e+00, -6.5414e-01, -1.8427e+00, -3.1251e-01,\n",
      "        -1.0768e-01,  6.6724e-01, -1.1217e+00, -2.5941e-01, -8.1249e-01,\n",
      "         9.5356e-02,  1.4450e-01,  5.5018e-01, -3.6192e-01,  1.1870e-02,\n",
      "        -1.1086e+00,  1.2545e+00, -8.4202e-01, -4.3636e-01, -4.5583e-01,\n",
      "        -2.0012e+00, -2.8281e-01, -1.1568e+00,  9.8183e-01,  7.8300e-01,\n",
      "        -1.1552e+00,  1.4923e-01,  2.8632e-01,  2.3063e-01,  1.2845e+00,\n",
      "         6.1095e-01, -7.8545e-01, -1.2078e-01, -9.8488e-02,  2.1548e-01,\n",
      "        -9.6518e-01,  7.1351e-01,  3.3677e-01,  1.7538e-01,  6.9063e-02,\n",
      "         4.4733e-01,  6.0638e-01,  9.8120e-01, -1.3219e+00, -5.2896e-01,\n",
      "         9.2822e-01,  5.8993e-01,  3.1405e-02,  1.3448e+00, -7.8238e-01,\n",
      "        -1.4276e+00,  1.9365e+00, -3.5776e-01, -6.6423e-01, -7.4555e-01,\n",
      "         6.9599e-03, -3.1355e-01, -1.9865e-01,  1.7057e+00, -3.2092e-02,\n",
      "        -6.3207e-01,  5.4329e-01, -2.2011e+00, -2.9281e-01, -6.2251e-01,\n",
      "        -4.5056e-01,  2.0766e-01, -1.7941e-01, -8.9957e-01, -1.5458e+00,\n",
      "         7.7318e-01, -1.5648e+00, -1.5364e+00,  1.3754e+00,  1.2520e+00,\n",
      "        -2.1418e+00, -7.1237e-01,  6.0374e-02,  6.0233e-01, -5.2959e-01,\n",
      "        -3.4130e-01,  9.4965e-01,  1.9413e-01,  8.3097e-01,  8.1046e-01,\n",
      "         5.5241e-01,  7.0747e-01,  2.3037e+00, -8.6772e-01, -2.3979e-01,\n",
      "        -8.1892e-01,  5.6773e-01,  2.0453e+00, -1.0734e+00, -4.8652e-01,\n",
      "        -8.9261e-01,  2.4075e-01, -2.4669e-01, -1.2215e+00,  5.6063e-01,\n",
      "        -3.6845e-01,  3.3333e-02, -3.1855e-01, -1.9889e+00, -6.4225e-01,\n",
      "        -1.2166e-01, -1.8008e-01,  1.2227e+00,  7.6009e-01, -3.3177e-01,\n",
      "         7.3803e-01,  5.9317e-02,  4.4425e-01,  1.5398e-01, -3.8847e-01,\n",
      "        -1.6201e+00,  8.6881e-01, -5.8047e-01,  1.8975e-01,  7.4270e-01,\n",
      "         9.4042e-01,  4.6618e-01, -1.1321e+00,  8.0418e-01,  1.8335e-01,\n",
      "         2.3918e+00, -1.7638e+00,  5.6224e-02,  1.5096e-01, -6.9073e-01,\n",
      "        -1.1218e+00, -7.8060e-01,  1.1894e+00,  1.9596e+00,  2.4884e-01,\n",
      "         1.6411e-01,  1.1601e+00,  1.2505e-01,  7.7287e-01, -4.1172e-01,\n",
      "        -1.3936e+00, -4.3792e-01, -4.6844e-01,  1.5951e+00,  2.1082e+00,\n",
      "        -2.0321e+00,  7.5155e-02,  2.2223e-02,  2.5685e-01,  1.7453e-01,\n",
      "         1.9502e+00,  1.6271e-01, -6.2299e-01, -4.2443e-01,  3.9486e-01,\n",
      "         1.3730e-01,  2.6352e-01,  9.1788e-01,  6.2602e-02,  5.0478e-01,\n",
      "         2.6247e-01, -1.5821e-01,  1.0857e+00, -1.3168e+00,  1.2502e+00,\n",
      "        -5.6213e-01,  1.0366e-01,  1.4524e+00,  6.5711e-01, -7.0969e-01,\n",
      "        -1.1807e+00, -6.9832e-01, -1.2348e+00, -9.7450e-01, -9.8426e-01,\n",
      "        -1.3555e+00, -1.0456e+00, -6.9710e-01,  3.7179e-01, -5.9176e-01,\n",
      "        -3.7158e-01,  3.8953e-01,  1.5409e+00,  2.7630e-01,  1.6572e+00,\n",
      "        -1.3497e+00,  8.3813e-02,  1.3991e+00,  6.0334e-01, -1.7363e+00,\n",
      "         1.3401e+00,  8.1319e-01, -7.1918e-01,  1.5897e-01, -4.9626e-01,\n",
      "        -1.4756e+00,  1.8016e+00, -5.7496e-01, -2.4098e-01, -1.0227e-01,\n",
      "         4.9541e-01, -5.2977e-01, -1.0464e+00, -1.1109e+00, -1.1866e-01,\n",
      "        -1.5160e+00,  6.9261e-01,  7.8567e-01,  9.2497e-01, -1.8673e+00,\n",
      "        -1.7981e-01, -7.8807e-01,  1.0675e+00, -5.4632e-01, -1.3145e+00,\n",
      "         1.5859e-01,  9.9035e-01, -2.8716e-01,  1.3887e+00,  2.7852e+00,\n",
      "         1.4667e+00, -2.1630e-03,  1.3122e-01, -4.4082e-01,  1.4388e+00,\n",
      "         2.7012e-01,  1.8311e-01,  8.7286e-02,  7.0655e-01,  8.5583e-02,\n",
      "        -8.0453e-01,  4.9520e-01, -4.5858e-02,  1.4293e-01,  1.3324e-01,\n",
      "        -7.6789e-01,  1.2833e+00, -1.5717e+00,  3.7064e-01, -6.9137e-02,\n",
      "        -2.3351e-01, -1.0496e+00, -7.1519e-01, -3.1503e-01,  2.4134e-01,\n",
      "        -2.1327e+00, -7.0920e-02, -8.5889e-01, -2.1502e-01, -3.9418e-01,\n",
      "        -1.7573e+00,  5.0271e-01, -1.8717e+00, -2.8780e-01,  1.0373e+00,\n",
      "        -1.9540e+00, -2.8975e+00, -3.7805e-02,  5.9749e-01,  1.8649e+00,\n",
      "        -1.8234e-01,  8.9876e-02,  1.0113e+00, -1.0590e+00, -2.5694e+00,\n",
      "        -3.6618e-01,  1.1363e+00,  2.9621e+00, -6.4946e-01,  5.2534e-01,\n",
      "         8.5458e-01,  1.1530e-01,  7.4480e-01, -9.1495e-01, -3.4917e-01,\n",
      "         8.2525e-01, -4.6126e-01, -6.1585e-01,  5.0931e-01, -1.4049e-01,\n",
      "         4.4019e-02,  1.9994e+00,  1.2511e+00,  9.2711e-01, -9.3070e-01,\n",
      "         1.2189e+00, -1.4664e+00,  2.0946e-01,  8.3740e-01, -1.1316e+00,\n",
      "         2.1325e+00,  3.0934e-01,  2.4597e-01,  1.5155e+00, -5.9255e-01,\n",
      "        -7.1502e-01,  5.6260e-01,  1.3257e+00,  3.0931e-02,  1.9564e+00,\n",
      "         2.6448e+00, -9.7250e-01,  2.9212e-01, -6.0533e-01,  2.0877e+00,\n",
      "        -2.0522e-01, -3.7066e-01,  4.1269e-01, -1.5873e+00, -3.8223e-01,\n",
      "         4.5748e-01,  1.7029e+00, -1.8429e+00,  9.2457e-01,  5.1284e-01,\n",
      "         6.6726e-01,  1.1963e+00, -5.0064e-01, -5.3246e-01,  6.9767e-01,\n",
      "        -4.8854e-01,  3.4013e-01,  2.7424e-01, -7.0709e-02,  1.1260e+00,\n",
      "        -1.4537e-01, -1.4229e+00, -1.7384e+00,  2.6901e-01, -6.3280e-02,\n",
      "         1.5646e-01,  8.9145e-01, -2.0361e+00, -1.2101e+00,  5.3662e-01,\n",
      "        -2.0959e+00, -5.4110e-01,  8.2315e-01, -4.3355e-02,  2.1027e-01,\n",
      "        -7.0236e-01,  3.1297e-01,  2.1490e+00, -3.8548e-01, -9.6717e-01,\n",
      "        -5.9997e-01, -3.0140e-01, -7.4357e-01,  1.5301e+00, -3.1532e-01,\n",
      "        -1.1947e+00,  1.4834e+00, -9.0908e-01, -1.1689e+00, -6.1742e-01,\n",
      "         4.5516e-01, -1.5063e+00, -3.1754e-01,  5.9486e-01,  5.6021e-01,\n",
      "         2.5182e-01, -6.8701e-01, -1.1398e+00, -9.4239e-01,  6.2022e-01,\n",
      "        -1.7724e-01, -5.4568e-01,  5.6724e-01, -3.2044e-01,  7.9431e-01,\n",
      "        -8.1198e-01,  1.9527e+00, -1.5011e+00, -1.1080e+00, -1.4306e+00,\n",
      "         3.5481e-02, -2.3049e-02, -1.6953e-01,  2.3860e+00,  1.0630e+00,\n",
      "        -1.4932e+00,  2.5329e-01, -5.7798e-01,  1.5582e+00,  6.9588e-01,\n",
      "        -8.9027e-02,  1.6316e+00, -1.0228e+00,  1.8693e-01,  1.2849e+00,\n",
      "        -9.6505e-02,  8.0098e-01, -1.3400e+00,  9.5497e-01,  1.7876e+00,\n",
      "         2.4873e-02,  7.3946e-01, -1.8697e-02,  4.0401e-01, -9.1567e-01,\n",
      "         8.5603e-01, -3.4786e-01,  3.7784e-02, -1.7795e-01, -7.3329e-01,\n",
      "        -3.4399e-02, -4.4117e-01,  9.1771e-01,  1.8784e+00,  4.8392e-01,\n",
      "        -4.4497e-01, -7.7221e-01,  2.7877e-01, -7.6384e-01,  1.5674e+00,\n",
      "         7.4855e-01, -7.2604e-01,  5.0055e-01,  5.9569e-01,  4.2833e-01,\n",
      "         7.1239e-01, -6.6702e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 8.5893e-01, -6.6307e-01,  1.4327e+00,  6.2499e-01,  7.5477e-01,\n",
      "         2.3523e-01, -1.1165e-01,  1.1192e+00, -1.8997e+00,  2.1488e+00,\n",
      "         1.0158e-02, -1.3138e+00,  6.3099e-01,  1.8190e+00,  2.3372e+00,\n",
      "         7.5857e-01, -6.8859e-01, -2.3978e-01,  1.6898e+00,  2.3014e+00,\n",
      "        -2.4741e-02,  3.4922e-01, -1.1879e+00, -6.9010e-01,  1.6543e-01,\n",
      "        -4.4854e-01, -1.3306e+00, -1.4979e+00,  3.8609e-01, -2.4282e+00,\n",
      "         1.4832e+00, -1.5316e+00, -1.2414e+00,  1.1190e+00, -3.1155e-01,\n",
      "        -9.1828e-01,  1.2676e-01,  5.0565e-01, -1.3248e+00,  9.1813e-04,\n",
      "         1.4551e+00,  5.9795e-01,  1.5750e+00,  2.8976e-01, -2.6176e-01,\n",
      "        -9.9451e-01,  1.8912e-01,  8.7030e-01, -2.0705e+00, -3.4099e-01,\n",
      "        -1.4938e+00, -9.2713e-01, -1.2240e-01,  1.1803e+00, -1.7325e+00,\n",
      "        -8.0019e-01, -5.6946e-01,  2.9255e-01, -2.9072e-01, -1.3932e-01,\n",
      "         9.7213e-01, -1.6820e+00,  5.6624e-01,  1.5700e+00,  4.2331e-01,\n",
      "         3.8784e-01,  7.7976e-01,  4.9155e-01, -1.8209e+00,  1.8066e-01,\n",
      "         1.8018e+00, -5.7387e-02,  1.5920e+00, -8.6131e-01,  4.8063e-01,\n",
      "        -1.7005e+00,  5.5833e-01, -4.2245e-01, -4.7229e-01, -1.5675e-01,\n",
      "         1.0425e+00, -1.2413e+00,  2.0553e-01,  6.3675e-01, -2.8079e-01,\n",
      "        -1.1332e+00, -5.1788e-01,  1.1611e+00, -9.5528e-01,  1.1145e-01,\n",
      "        -2.6877e-01, -9.6476e-01,  1.2807e-01, -6.2625e-01,  2.1321e+00,\n",
      "         5.9350e-01,  8.6484e-01,  9.0861e-01,  3.9021e-01,  9.7475e-01,\n",
      "        -2.7938e-01,  4.3994e-01, -1.0507e+00,  4.0245e-01, -1.5155e-01,\n",
      "        -7.7878e-01, -9.0321e-01, -3.7718e-02, -6.2987e-01, -1.6148e+00,\n",
      "        -1.5339e+00,  1.2112e+00,  2.5697e-01,  2.1045e-01,  9.3085e-02,\n",
      "        -6.4937e-01,  1.8931e+00,  1.1691e+00,  2.9373e-01,  8.2596e-01,\n",
      "        -1.8421e+00,  6.4771e-01,  6.8112e-01, -3.7936e-02,  1.1006e-01,\n",
      "        -8.9752e-01,  2.0648e-01, -4.1486e-01,  6.7390e-01, -4.5273e-01,\n",
      "         6.6224e-01,  1.3032e-01,  2.5158e-01,  4.0502e-01, -3.7230e-01,\n",
      "        -1.0804e+00,  4.1281e-02,  1.1146e+00,  2.0146e+00,  3.0294e-01,\n",
      "         2.4657e-01, -5.8857e-01,  2.4879e-01,  9.8144e-01,  8.1118e-01,\n",
      "         4.8648e-01, -1.5817e+00, -8.0902e-01, -2.5132e+00,  1.0065e+00,\n",
      "         2.7482e+00, -2.6825e+00,  9.3281e-01,  5.8174e-02,  8.2012e-02,\n",
      "        -7.9963e-01,  9.8319e-01,  5.7695e-01,  2.8355e-01, -1.4843e+00,\n",
      "         2.7745e-01,  1.4460e+00, -2.4749e+00, -7.6354e-02, -2.5684e-01,\n",
      "         1.2991e+00,  6.8607e-01, -6.9136e-01,  7.1692e-01,  2.0935e+00,\n",
      "        -1.0352e-01, -1.1104e+00,  9.1220e-01, -4.5907e-01,  3.3780e-01,\n",
      "         5.4660e-01, -6.6961e-02, -1.0751e+00, -5.6621e-01,  2.6256e-02,\n",
      "         1.8064e+00,  1.4629e+00,  1.2410e+00,  1.3087e+00, -2.4769e-01,\n",
      "         2.3899e-01,  1.8423e+00,  5.1154e-01,  1.8630e-01, -2.1793e+00,\n",
      "         2.2871e-01,  2.0845e-01,  1.7594e-01,  1.3217e+00, -1.0888e-01,\n",
      "         1.0166e+00, -5.2717e-01, -1.8260e+00, -5.4954e-01, -1.4432e+00,\n",
      "        -6.9290e-01,  1.8308e+00,  1.3860e+00, -1.1575e+00, -1.3247e+00,\n",
      "        -5.7283e-01, -5.1396e-01,  1.0665e+00, -1.8964e+00,  5.2968e-01,\n",
      "         2.0568e+00, -3.5922e-01,  7.1103e-02,  1.3636e+00, -1.3977e+00,\n",
      "        -4.0137e-01, -3.1420e-01, -1.7758e-01, -7.9314e-01, -4.5657e-01,\n",
      "        -2.5189e-01, -1.0842e-01, -1.0946e+00, -4.1769e-01,  3.0716e-01,\n",
      "        -7.9982e-01, -1.4691e+00, -1.8556e-03,  3.7741e-01,  1.9406e+00,\n",
      "        -2.4803e-01,  2.1914e+00,  5.3903e-01,  1.0143e-01, -8.0035e-02,\n",
      "        -9.5852e-01,  7.6658e-01, -5.2400e-01,  1.7801e-02, -4.2901e-01,\n",
      "         5.5022e-01,  2.8316e-01,  4.2839e-01, -2.6227e-01,  5.2284e-01,\n",
      "        -2.0432e+00, -1.3803e+00,  3.0736e-01,  8.1601e-01,  8.1097e-01,\n",
      "        -1.9665e+00,  1.0071e+00,  9.7760e-01, -3.2409e-01, -6.9007e-01,\n",
      "        -9.0631e-01,  1.5365e-01, -5.4061e-01,  2.6242e-01,  2.9899e-01,\n",
      "        -1.6617e+00, -4.8990e-01, -1.2497e-01, -4.0032e-01,  2.2100e+00,\n",
      "         3.5872e-02,  6.0101e-01, -2.9638e-01, -1.1316e+00,  6.8365e-01,\n",
      "         2.8005e-01, -1.0582e+00, -1.5054e+00,  1.5830e+00, -1.1038e+00,\n",
      "         1.3664e+00, -8.3212e-01,  1.4831e+00, -5.5071e-01,  1.0322e+00,\n",
      "         1.5022e+00,  2.9502e-01, -7.4190e-01, -7.3907e-01, -1.1670e+00,\n",
      "         9.7942e-02,  1.0178e+00,  8.0222e-01,  1.1473e+00, -2.0413e+00,\n",
      "        -2.7907e-01, -8.4081e-01, -1.0805e+00, -8.9744e-01,  1.0874e+00,\n",
      "        -6.5321e-01, -2.1454e-01, -1.9291e+00,  8.6693e-01, -2.0619e+00,\n",
      "         4.1638e-01,  3.8644e-01,  5.1181e-01, -1.3798e+00,  9.9644e-02,\n",
      "         1.2902e+00, -1.2817e+00, -6.0255e-01,  2.9612e-01, -7.0157e-01,\n",
      "        -1.0015e+00, -8.7340e-01,  4.3516e-01,  7.2042e-01, -7.5187e-02,\n",
      "         9.5138e-01,  5.3696e-02, -1.3181e+00,  2.5098e+00, -2.1889e-02,\n",
      "         3.6832e-01, -4.3695e-01, -1.7553e-01, -4.9621e-01, -1.3058e+00,\n",
      "         4.9914e-01,  5.0799e-02,  5.2535e-01, -1.3362e+00,  2.8677e+00,\n",
      "        -5.1927e-01,  6.9326e-01,  4.4631e-01, -6.0006e-01,  8.2783e-01,\n",
      "        -7.2294e-01, -2.6363e-01,  9.8493e-01,  1.4405e+00, -2.2593e+00,\n",
      "         5.7358e-01, -6.4564e-01, -3.2883e-01,  6.5439e-02,  8.3685e-01,\n",
      "        -1.5707e-01,  1.1123e+00, -1.7445e-01,  1.9577e+00,  2.2722e-01,\n",
      "         4.6306e-01, -2.1316e+00, -8.8598e-01, -2.7260e-01,  1.1925e+00,\n",
      "        -3.6699e-01,  8.2618e-01, -3.9646e-01, -4.3128e-01, -1.0738e+00,\n",
      "         1.0141e+00, -9.7214e-01,  2.0366e+00, -4.3801e-01, -5.6359e-01,\n",
      "         8.6640e-01, -5.5710e-01, -1.1414e+00,  9.6971e-01, -8.1398e-01,\n",
      "         1.4113e+00,  5.5510e-02,  1.0644e+00, -7.4032e-01, -2.2015e-01,\n",
      "         1.7221e+00,  7.9320e-01, -6.6917e-01, -6.3390e-01, -9.2966e-01,\n",
      "        -7.8798e-02,  3.6975e-01, -2.1426e+00,  1.8271e-01, -9.5851e-01,\n",
      "         7.7748e-01,  7.5330e-01,  1.3840e-01,  2.6568e-01, -1.6023e+00,\n",
      "         5.2706e-01, -9.0875e-01,  1.1563e+00,  1.4540e+00,  1.7252e+00,\n",
      "         2.2496e+00,  1.1169e+00, -5.1447e-01,  4.0154e-01, -1.1063e+00,\n",
      "        -2.0280e+00, -9.9139e-01, -1.2995e+00, -9.1548e-01,  8.9668e-01,\n",
      "        -9.4588e-02, -1.5725e+00, -4.6694e-01,  8.8330e-01, -8.5061e-01,\n",
      "         1.8339e-01,  1.4676e+00,  1.2809e+00,  9.3023e-01, -5.0369e-01,\n",
      "        -4.2456e-01, -3.3072e-01,  2.6112e-01,  7.9442e-01, -1.2999e+00,\n",
      "        -2.5998e+00, -1.3821e-01,  1.3719e+00,  8.2557e-01,  1.1624e+00,\n",
      "        -1.5725e+00, -4.9760e-01,  1.5447e+00,  5.6006e-01,  5.0887e-01,\n",
      "        -8.1638e-01, -5.3788e-01, -4.3908e-01,  9.4841e-02, -8.8941e-01,\n",
      "        -2.0941e+00, -1.2748e-01, -5.0414e-01,  4.4538e-01,  3.7384e-01,\n",
      "         1.9979e-01,  2.0204e+00, -1.2960e+00,  7.1043e-02,  6.6822e-01,\n",
      "         3.7340e-01,  2.9493e-01, -5.3430e-01, -1.6864e+00,  2.0208e+00,\n",
      "        -2.2748e-01,  8.3193e-01,  1.1077e-02, -3.2379e-01,  5.5850e-01,\n",
      "        -2.3221e-01, -6.1739e-01, -6.9482e-01, -7.7192e-02,  1.0872e+00,\n",
      "         6.4847e-02,  6.4346e-01, -1.2386e-01,  3.7494e-01,  2.0958e+00,\n",
      "        -1.3731e+00, -8.8479e-01, -6.6426e-01,  1.1964e+00, -6.3720e-01,\n",
      "        -8.4755e-01, -8.6142e-01,  1.0166e+00,  1.7640e+00, -6.6794e-01,\n",
      "        -1.6616e+00,  1.5877e+00,  2.0993e+00, -4.2710e-01,  1.6143e+00,\n",
      "        -6.0696e-01, -7.8119e-02, -1.5606e+00,  5.3673e-02,  8.2225e-01,\n",
      "        -2.8771e+00, -6.8000e-01, -1.2994e+00, -2.2611e+00, -5.7376e-01,\n",
      "         1.2683e+00, -7.2756e-01,  7.1561e-01, -4.8745e-01,  4.5082e-02,\n",
      "        -1.3765e+00,  1.6972e+00, -1.6767e+00, -5.8955e-01,  4.6094e-02,\n",
      "        -5.0827e-01,  1.4540e+00,  7.5746e-01,  1.5265e+00,  5.7766e-01,\n",
      "        -1.2300e+00, -1.4478e+00, -6.9850e-02,  1.1436e-01, -1.0784e+00,\n",
      "        -1.0616e+00, -7.9951e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-7.6177e-01,  1.3674e+00, -6.8602e-01,  1.9918e-01,  5.8263e-01,\n",
      "         1.2359e+00,  1.8734e-01, -8.2844e-01, -8.4177e-01,  1.2564e+00,\n",
      "        -1.2608e-01, -7.4056e-01, -8.3481e-01, -1.1347e+00,  1.1383e-01,\n",
      "        -6.3899e-01, -5.2712e-02,  1.4074e-01, -1.2227e-01,  3.4323e-01,\n",
      "         4.2129e-01,  1.5553e+00,  5.1451e-01, -1.0015e-01, -3.0600e-01,\n",
      "        -1.1749e+00, -5.3331e-01,  5.8290e-01, -6.8400e-01, -1.1577e+00,\n",
      "        -3.9424e-01,  5.8831e-01,  3.0565e-01,  5.7431e-01,  1.4157e+00,\n",
      "        -7.4823e-01,  2.1093e-01,  1.3552e+00,  1.7092e+00,  5.0471e-01,\n",
      "         1.0011e+00, -2.7488e-01, -1.6058e+00,  1.5753e+00, -2.2280e+00,\n",
      "         1.4303e+00,  5.1191e-01,  8.7291e-01,  6.7008e-01, -6.3168e-01,\n",
      "         3.8122e-01, -2.4411e-01, -2.7463e-01,  8.6733e-02,  2.8165e-01,\n",
      "        -7.9925e-01, -1.1007e-01,  2.7414e-01, -6.8833e-02,  6.6219e-01,\n",
      "        -6.9311e-01, -3.2954e-01,  1.1884e+00, -1.3773e-01, -3.1309e-01,\n",
      "         9.3321e-01, -7.6189e-01, -4.6748e-01,  1.4583e-01, -7.7059e-01,\n",
      "         2.0915e+00, -4.7608e-01, -5.6923e-01, -1.9956e-01, -2.1408e+00,\n",
      "         8.3986e-01, -4.9170e-03, -1.0126e+00,  5.1157e-01,  4.7371e-01,\n",
      "         4.7444e-01, -4.7182e-01, -9.2607e-01,  3.8782e-01, -3.1782e-03,\n",
      "         3.0520e-01, -2.1760e-01,  8.0874e-01, -8.7470e-01,  4.7706e-01,\n",
      "        -5.2168e-01, -1.4474e+00,  1.0340e+00, -6.6817e-02, -1.3182e+00,\n",
      "        -8.9684e-01,  1.0217e+00, -1.1298e-01, -1.2046e+00, -1.9356e+00,\n",
      "         5.5633e-01,  7.2070e-01, -2.3717e+00,  1.9017e-04, -6.4905e-01,\n",
      "        -1.7694e+00, -3.4698e-01,  8.5942e-02, -6.9841e-01,  1.1973e+00,\n",
      "        -8.8916e-02,  9.1808e-01, -2.0102e+00, -4.9413e-01,  1.8440e+00,\n",
      "        -4.9054e-01, -1.3695e+00, -4.4845e-01,  4.2983e-01, -3.1179e-01,\n",
      "         3.7674e-01,  1.8179e+00,  1.8581e+00, -1.0099e+00,  5.8385e-01,\n",
      "         6.3333e-01,  1.0261e+00, -5.7236e-02,  1.0130e+00, -2.1114e-01,\n",
      "        -7.4316e-01,  3.5970e-01, -1.6492e+00,  1.3405e+00, -7.7996e-01,\n",
      "         1.0200e+00, -9.0561e-01, -5.1236e-01,  8.1664e-01, -6.1609e-01,\n",
      "        -1.0015e+00, -1.8866e-01, -9.2270e-01,  1.6825e+00, -1.6654e+00,\n",
      "         1.0409e-02,  1.5207e+00, -1.1824e-02,  6.7447e-01,  3.7820e-01,\n",
      "         1.6918e+00, -2.5829e-01,  8.0643e-01,  8.7559e-01, -7.5604e-01,\n",
      "         1.5809e+00, -2.3993e-01, -7.2455e-01, -2.2676e-01, -7.2801e-01,\n",
      "         8.4120e-01,  2.2293e-01, -1.8507e-01, -1.2650e-01, -9.1604e-01,\n",
      "         1.4243e+00,  1.3515e+00,  8.1138e-02,  5.4142e-02, -1.2421e-01,\n",
      "        -2.2948e-01, -3.1923e-01,  2.8134e-01, -7.9073e-01, -1.1599e-01,\n",
      "         5.4611e-02, -2.4492e+00, -5.7096e-01,  8.9551e-01, -3.7435e-01,\n",
      "        -1.1534e+00, -1.1458e+00, -3.9581e-01,  6.7133e-01,  2.1129e-01,\n",
      "         7.2083e-02,  2.9927e-02, -5.6767e-01,  2.1500e+00, -3.4121e-01,\n",
      "         7.1722e-01, -1.1482e+00, -1.0575e+00, -7.5848e-01,  1.0081e+00,\n",
      "        -5.1337e-01,  4.6088e-01, -6.2782e-02,  1.1713e-01,  1.5239e+00,\n",
      "         4.6787e-01,  4.3642e-01,  8.8860e-01,  5.0816e-01,  6.7017e-01,\n",
      "         6.3685e-01,  1.5885e+00,  1.9076e-01, -1.2359e+00, -1.6231e+00,\n",
      "         6.1387e-01,  1.7721e+00, -1.5521e+00, -1.8892e-01,  2.4454e-01,\n",
      "         1.1941e+00, -6.9550e-03,  3.4324e+00, -1.1320e+00, -3.4986e-01,\n",
      "        -1.0075e+00,  5.6611e-01,  1.2677e+00, -2.7775e+00,  4.4631e-01,\n",
      "        -5.0398e-01,  1.3485e+00,  8.4371e-01, -7.1576e-01, -7.4508e-01,\n",
      "        -2.5617e-01, -2.1006e-01,  5.7214e-01,  6.1765e-01,  1.4635e+00,\n",
      "        -1.7997e+00,  2.0983e-01,  7.7415e-01,  3.6950e-01, -5.3736e-01,\n",
      "         1.9678e+00, -8.1338e-01, -7.0822e-01,  6.4507e-01,  5.0754e-01,\n",
      "        -4.4391e-01,  6.5932e-01, -2.5958e-01, -2.6725e-01, -2.1606e-01,\n",
      "        -1.1711e+00,  8.5766e-01, -1.7346e+00,  9.9414e-02, -1.1339e+00,\n",
      "         6.5333e-01,  2.2702e-01,  1.4453e+00, -7.4170e-01,  1.1069e+00,\n",
      "        -7.3058e-01,  8.0137e-01, -1.8932e+00,  9.4820e-02,  1.9177e-01,\n",
      "         8.5215e-02, -6.7578e-03, -4.6792e-01, -1.0052e+00,  5.1998e-01,\n",
      "         5.0097e-01,  6.4100e-02, -5.4298e-01, -1.1215e+00,  1.4765e+00,\n",
      "        -3.3911e+00, -1.1978e+00, -1.5211e+00, -8.1433e-01,  2.5916e-01,\n",
      "         4.0411e-01,  6.8105e-01, -6.9490e-01, -4.9967e-01, -2.3143e+00,\n",
      "         7.5413e-01,  2.8220e-01,  5.8932e-01,  7.2380e-01,  4.3212e-01,\n",
      "         1.0906e-02,  1.2939e+00,  8.4194e-01, -7.2512e-01, -9.6339e-01,\n",
      "        -3.9472e-01,  1.2180e+00,  1.5058e+00,  1.0679e+00, -9.6880e-01,\n",
      "        -8.1279e-01, -1.7903e-01, -1.4808e+00,  9.3006e-02, -2.4609e-02,\n",
      "         4.1062e-01, -2.2094e+00, -2.1413e+00, -4.7554e-01, -7.5923e-01,\n",
      "         7.3031e-02, -9.5376e-01,  2.5830e-01, -1.0716e+00,  8.9984e-01,\n",
      "        -8.1949e-01, -3.3640e-01, -2.2448e+00, -5.2399e-01,  7.2377e-01,\n",
      "        -1.8524e+00,  7.7007e-01,  3.8479e-01,  5.3228e-01,  1.8966e+00,\n",
      "         1.2767e+00, -1.2836e+00, -6.0892e-01, -5.8598e-01,  3.4242e-01,\n",
      "         1.8644e-01, -5.3140e-02, -8.2161e-01, -4.9264e-01,  6.4290e-01,\n",
      "        -5.3832e-01,  4.2723e-01, -1.6948e+00,  1.6949e-01,  5.7345e-01,\n",
      "         5.4304e-01,  1.0503e+00, -1.8370e+00, -1.2243e+00,  6.2093e-01,\n",
      "        -2.1173e+00, -1.3852e+00,  2.0011e-01,  5.3131e-01, -2.7619e-01,\n",
      "        -2.5620e-01,  8.3902e-02,  1.5768e+00, -4.8703e-02, -8.3048e-01,\n",
      "        -4.6693e-01, -6.3284e-01,  1.7672e+00, -1.4515e+00,  2.4986e-01,\n",
      "        -1.2104e+00,  1.3452e+00,  1.2996e-01,  4.6122e-01,  6.4494e-01,\n",
      "        -1.4897e+00,  7.1854e-01,  1.7319e+00,  9.9451e-01, -6.9406e-02,\n",
      "         1.6229e-01, -6.8992e-01,  9.1297e-01, -2.0586e+00, -1.4450e+00,\n",
      "        -1.0871e+00, -9.8979e-01,  6.0721e-04,  6.8388e-01,  3.7741e-01,\n",
      "        -7.4146e-01, -1.5143e-01,  1.0517e+00,  1.2993e+00, -8.8076e-01,\n",
      "        -1.4663e+00, -1.8183e+00, -5.5754e-01, -2.2369e+00,  1.3435e-01,\n",
      "         2.5162e-01,  2.5043e-01, -1.1669e+00, -1.4929e-01, -7.4592e-01,\n",
      "         4.0340e-01,  2.8140e-01, -8.2615e-01, -1.4127e+00, -1.3650e+00,\n",
      "         2.6487e-01, -2.3243e+00,  7.5126e-02, -5.6270e-01, -8.7069e-01,\n",
      "         9.0418e-02,  3.8805e-01,  3.3913e-01, -1.6132e+00, -1.8910e-01,\n",
      "        -1.4734e+00, -1.7430e+00,  1.0705e-01,  3.4868e-01,  7.8221e-01,\n",
      "         3.1484e-01, -6.8640e-01, -1.2770e+00,  7.1895e-03, -4.4179e-01,\n",
      "        -1.9208e+00,  6.6361e-01, -3.4298e-01,  1.4805e-01, -2.2935e-01,\n",
      "         3.3240e-01,  4.1915e-01,  2.5571e+00, -7.1840e-01,  3.3006e-01,\n",
      "        -6.1656e-01,  1.2180e+00,  9.3761e-01,  1.5197e-01,  1.1935e-01,\n",
      "         2.1842e-01, -9.4911e-01, -1.3474e+00,  2.3237e-01, -1.8593e-01,\n",
      "        -1.0113e-01,  1.2006e+00, -1.2938e+00,  9.4625e-04, -9.8819e-01,\n",
      "        -1.6406e+00,  8.4581e-01,  8.6870e-01, -4.5826e-01, -4.1646e-01,\n",
      "         6.8354e-01,  2.2460e+00, -1.9262e+00,  9.2299e-01,  8.9166e-01,\n",
      "        -5.2959e-01,  4.7555e-01, -9.9432e-02,  7.2470e-01, -2.8928e-01,\n",
      "        -1.0400e+00, -3.4675e-01, -1.4293e+00,  6.7989e-02,  1.2749e+00,\n",
      "         1.0440e+00, -1.2043e+00,  4.9172e-02, -1.1441e+00, -2.6703e-01,\n",
      "         1.0223e-01,  6.1446e-01,  2.3715e+00,  1.1349e+00,  1.0298e+00,\n",
      "         5.0673e-01, -4.5558e-01, -4.0302e-01,  1.0080e-01, -5.2568e-01,\n",
      "        -9.5729e-01, -1.2922e+00,  1.5112e+00,  1.3886e+00,  7.3935e-01,\n",
      "        -1.1460e+00,  6.5772e-01,  7.4466e-01, -5.2974e-02, -4.0577e-01,\n",
      "        -1.9393e-01,  1.0393e+00,  2.7364e-01,  1.2229e+00, -6.8689e-01,\n",
      "        -1.4451e+00,  2.3121e-01,  1.7566e+00, -1.1306e+00, -9.5419e-01,\n",
      "        -1.6360e-02,  1.0855e-02,  3.7081e-01, -8.3029e-01, -1.7768e+00,\n",
      "        -1.0176e+00,  7.7290e-01, -4.0987e-01, -8.7646e-01, -7.2025e-01,\n",
      "        -8.6121e-01,  6.0919e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "start: 73, end: 76\n",
      "start embedding: tensor([-8.2587e-01, -8.2022e-01, -6.0081e-01,  1.5697e+00, -6.0212e-01,\n",
      "        -8.6783e-01, -9.7513e-01,  1.2477e+00, -1.6718e+00, -7.6757e-01,\n",
      "        -2.4951e+00,  1.5847e+00, -1.2018e+00,  2.8679e-01, -1.7152e+00,\n",
      "        -1.1170e+00, -1.1451e+00, -4.7059e-01,  1.6934e+00,  1.0483e+00,\n",
      "         2.7828e+00, -2.0520e+00,  3.1031e-01,  1.2576e+00,  9.3845e-01,\n",
      "        -1.9284e+00,  2.3695e-02, -1.4099e+00,  6.7581e-01,  2.1581e-01,\n",
      "        -1.7183e+00, -3.1066e-01, -6.2229e-01,  2.3328e+00, -1.0088e+00,\n",
      "         1.8482e+00,  1.5533e+00, -1.4943e+00, -1.2811e+00,  2.9724e-01,\n",
      "         1.6593e+00,  1.4469e+00, -1.1549e-01,  5.3555e-02, -5.6337e-01,\n",
      "        -4.9110e-01,  9.1031e-01,  1.4650e+00, -6.8014e-01, -2.0108e-01,\n",
      "        -3.7118e-02, -3.4003e-01,  1.2364e+00,  3.5305e-01, -1.0401e+00,\n",
      "        -1.6767e+00,  2.9864e-01,  1.5091e+00,  4.3660e-01,  2.4950e-01,\n",
      "        -1.5881e+00, -4.7179e-01,  1.0202e+00,  5.7268e-01,  1.3469e+00,\n",
      "         5.3407e-01,  4.1128e-01,  1.1066e+00, -3.8968e-01,  7.4766e-02,\n",
      "        -3.3794e-01, -6.7144e-02,  1.4543e+00,  1.8616e-01, -2.7404e-02,\n",
      "        -5.8948e-01,  5.8817e-02,  9.2429e-01, -2.1199e+00, -1.9959e+00,\n",
      "         1.8312e+00,  1.1087e+00, -3.8218e-01, -3.3100e-01, -3.4432e-01,\n",
      "        -6.9998e-01,  6.1172e-01, -7.1132e-01,  9.2656e-01,  8.2877e-01,\n",
      "        -1.8410e+00, -8.6965e-01, -1.2402e+00, -1.0774e-01,  9.1419e-01,\n",
      "        -1.9558e-01,  3.4196e-01,  7.8618e-01,  1.7883e+00,  3.2422e-01,\n",
      "         2.6208e-01,  4.0818e-01,  1.2974e+00, -6.8388e-01, -4.7253e-01,\n",
      "        -1.0327e+00, -1.5435e+00,  1.3077e+00, -9.1104e-01,  8.7051e-01,\n",
      "        -2.3600e-01,  3.5692e-01, -1.5974e+00, -1.4500e+00,  1.9979e+00,\n",
      "        -8.1126e-01,  1.1582e+00, -1.6189e+00,  4.2191e-01,  3.2396e-01,\n",
      "        -9.9112e-01,  1.5182e+00,  1.2381e+00, -6.1478e-01, -1.2140e+00,\n",
      "        -4.9659e-01,  3.5609e-01, -9.4474e-01, -1.9997e-01, -1.1139e+00,\n",
      "         5.2603e-01, -3.4522e-01, -8.4870e-01, -2.7671e-01,  1.1275e+00,\n",
      "         1.5912e+00, -8.6825e-01, -1.0942e-01,  1.6009e-01, -6.5217e-01,\n",
      "        -1.0879e-01,  2.6607e+00,  3.5913e-01, -1.0394e+00,  1.1128e-01,\n",
      "        -7.7120e-01,  1.2573e-01, -1.3687e-01, -8.9914e-01, -1.9952e+00,\n",
      "         7.8433e-01, -8.6320e-01,  1.3480e-01, -4.7164e-01, -1.6796e-01,\n",
      "        -9.8630e-01, -1.2575e-01, -8.2946e-01, -3.7137e-01,  1.7977e+00,\n",
      "        -3.8375e+00, -1.1539e+00, -1.7210e-01,  1.9722e+00, -4.2705e-01,\n",
      "         1.4537e+00,  1.3665e+00,  1.8088e+00,  3.9968e-01, -2.4635e-01,\n",
      "         3.6410e-01, -2.8261e-01, -1.0077e+00, -1.5239e+00, -1.4971e+00,\n",
      "         5.3170e-01,  8.6167e-01, -6.1309e-01,  1.2161e+00,  1.1534e+00,\n",
      "         1.0538e+00,  1.1911e+00,  5.6176e-02, -4.7045e-01,  1.2788e+00,\n",
      "        -1.4400e+00, -1.1067e-01,  3.6997e-01, -1.8359e+00,  3.8647e-01,\n",
      "         4.8900e-01, -2.3803e-01,  2.2858e+00,  4.6649e-01, -2.6957e-01,\n",
      "        -3.6152e-01,  1.8965e-01, -1.5611e+00,  1.9827e+00,  5.9932e-01,\n",
      "         1.5769e+00,  3.9974e-01, -1.9213e+00,  1.2303e-01, -1.5575e-01,\n",
      "        -8.9852e-01,  2.5605e-01, -1.0915e+00,  5.7445e-01, -1.2359e-01,\n",
      "        -5.0486e-02, -1.4509e+00, -6.3553e-01, -2.0148e+00,  6.0167e-01,\n",
      "        -4.5798e-01, -2.2795e+00,  1.2285e-01, -1.6143e-03,  5.2294e-01,\n",
      "        -3.2315e-01, -1.3481e+00, -6.3913e-01,  2.0024e-01, -2.8982e+00,\n",
      "         5.0958e-01, -8.5462e-01, -1.0776e+00, -6.4004e-01, -7.9151e-01,\n",
      "         6.4726e-01,  8.2272e-02,  6.7953e-01,  2.5621e-01, -4.8070e-01,\n",
      "         1.3818e+00, -1.9198e+00, -1.6979e+00,  6.4160e-01, -1.0353e+00,\n",
      "         6.2744e-01,  1.1796e+00,  5.0284e-01,  2.1215e+00,  8.2374e-01,\n",
      "        -1.0506e+00, -4.4760e-01, -3.6401e-01,  1.9015e+00, -2.2221e-01,\n",
      "        -8.4920e-01, -1.8416e+00, -3.9822e-01,  3.0388e-01, -1.8563e-01,\n",
      "        -1.1949e+00, -6.5453e-01, -4.7992e-01,  8.0722e-01,  2.2785e-01,\n",
      "        -1.6948e+00, -3.0419e-01, -3.7520e-01, -5.9476e-01, -1.4735e-02,\n",
      "        -9.4344e-01,  1.2071e+00, -1.1717e+00, -3.5071e-01,  4.6812e-01,\n",
      "        -4.0579e-01,  5.8734e-01,  2.1137e+00,  1.2434e+00,  3.8822e-02,\n",
      "         7.5566e-01, -2.4402e-01, -4.8540e-02,  2.1021e+00,  2.0518e+00,\n",
      "         7.8785e-01,  4.5851e-01, -1.4956e-01, -1.3933e-01,  4.1735e-01,\n",
      "         1.3104e-01,  9.2199e-01, -1.5672e+00, -4.6051e-02,  5.1116e-01,\n",
      "         5.9312e-01, -1.6784e+00,  2.4422e+00, -5.3517e-01, -1.1532e-01,\n",
      "        -1.7461e+00,  1.5352e+00, -4.9744e-01,  2.4428e-02, -8.9612e-01,\n",
      "        -4.1628e-01,  3.2925e-01,  8.5169e-01, -7.4785e-01,  1.4295e+00,\n",
      "        -2.1813e-01,  1.1455e-01,  1.8660e-01, -5.9998e-01,  6.6764e-01,\n",
      "         2.6966e+00, -3.7412e-01, -7.6739e-01,  4.4479e-01,  5.5238e-03,\n",
      "        -2.4750e-01,  5.2970e-01, -1.0584e+00,  1.4425e+00,  1.1129e+00,\n",
      "         1.3474e+00,  2.4074e-01,  6.8221e-01, -8.5913e-01, -9.0771e-01,\n",
      "         5.8867e-01, -4.4244e-01, -1.7951e+00,  1.2756e-01, -1.0268e+00,\n",
      "        -4.1808e-01,  7.4593e-01, -4.4798e-01, -1.0148e-01,  1.7096e-02,\n",
      "        -2.1950e+00, -1.6492e+00, -4.0459e-02,  1.2264e+00, -4.8012e-01,\n",
      "        -5.9331e-01, -1.7806e+00, -1.5605e+00,  8.7383e-01, -3.9547e-01,\n",
      "         1.6042e+00,  1.2005e+00,  2.0023e+00,  1.0324e+00, -9.1528e-01,\n",
      "        -1.7641e-01,  3.3008e-01,  8.8024e-01, -1.1604e+00,  6.8562e-01,\n",
      "         1.1362e+00,  5.4695e-01, -7.7128e-01,  8.1732e-01,  3.8594e-02,\n",
      "        -2.5032e-01, -2.1038e-01, -3.0138e-01, -4.4422e-01,  7.2975e-01,\n",
      "         5.1364e-02, -1.3066e-01, -4.0859e-01,  5.4368e-01,  1.5642e+00,\n",
      "         4.7331e-01, -9.0748e-01, -2.6490e-01, -4.7362e-01,  1.3523e+00,\n",
      "         2.2740e+00, -4.9080e-01,  8.9092e-02,  1.3470e+00, -2.1514e+00,\n",
      "        -1.3883e-01,  6.6451e-01, -2.1480e-01, -2.5029e-01,  8.5837e-01,\n",
      "         1.9394e+00,  9.4430e-01, -2.7959e-01,  5.5423e-01, -1.3327e-01,\n",
      "        -3.3413e-01, -1.4212e+00, -2.4690e-01, -1.1007e+00,  8.5747e-01,\n",
      "         1.4330e-03,  4.5513e-01, -6.8460e-01,  4.9337e-01,  2.4265e-01,\n",
      "        -9.6244e-01, -5.3460e-01, -9.1000e-01,  2.9413e-01, -1.5594e+00,\n",
      "         4.6178e-01,  1.3083e+00, -8.5275e-01, -1.9035e+00,  5.8732e-01,\n",
      "         1.6421e+00, -1.4197e+00,  2.5959e-01, -4.2743e-01, -1.8748e+00,\n",
      "        -1.0383e+00, -1.2156e+00, -1.0448e-01, -3.8413e-01, -6.0470e-01,\n",
      "        -1.1528e+00,  6.1125e-01,  4.6377e-01,  3.8623e-01,  2.7657e-01,\n",
      "        -4.4639e-01, -9.7987e-01,  6.4538e-01,  8.6198e-01,  1.7287e+00,\n",
      "         1.2765e+00,  5.9996e-01, -1.2964e+00,  1.1623e+00, -6.0241e-01,\n",
      "         3.2243e-01,  7.9883e-01, -7.2408e-01, -2.6684e-01,  5.9825e-01,\n",
      "         8.1046e-02,  1.8266e-01, -3.1386e-01,  1.0349e+00, -4.2257e-02,\n",
      "        -1.1204e+00, -1.0335e+00, -5.0289e-01, -2.5188e-01,  5.4075e-01,\n",
      "         6.9686e-01,  6.8728e-01,  4.0801e-01,  1.8593e+00,  2.5812e-01,\n",
      "        -6.0113e-01, -3.1173e-01,  9.4391e-01,  3.0710e-01, -1.5994e+00,\n",
      "         1.1647e+00, -7.1327e-01, -1.1705e+00,  6.7534e-01,  1.0820e+00,\n",
      "         1.9233e-01,  2.1530e+00, -5.2076e-01,  7.7097e-01,  5.0210e-01,\n",
      "         8.1536e-02,  4.0441e-01, -7.4768e-01,  1.2397e+00,  3.8619e-02,\n",
      "         1.7516e+00, -1.3484e-01,  2.6480e+00,  1.5883e-01,  1.1140e-01,\n",
      "        -6.6371e-01, -6.0238e-01,  1.0684e+00,  2.3833e-01,  1.7568e-02,\n",
      "        -6.4210e-01,  1.5215e+00,  4.7636e-02, -9.7329e-01,  2.5710e-01,\n",
      "         7.0649e-01,  1.8400e+00, -9.9198e-02, -1.2114e+00,  1.3559e-01,\n",
      "        -1.5025e+00,  2.2793e-01,  3.4526e-01, -8.1631e-01, -1.2948e+00,\n",
      "         1.3492e+00,  3.6807e-01, -1.1941e+00, -1.6720e-01, -1.2553e+00,\n",
      "        -2.5647e-01,  7.3231e-01, -1.3918e-01,  1.2280e-01, -2.6747e-01,\n",
      "        -1.1468e-01,  1.3908e+00]), end embedding: tensor([-6.1049e-03, -3.0342e-01, -1.2317e+00,  8.9403e-01, -1.0901e+00,\n",
      "         1.1996e+00,  1.5214e-01, -2.2333e-01,  1.7117e-01,  5.4250e-01,\n",
      "        -5.4564e-01,  4.1279e-02, -1.1190e+00, -1.3981e-01, -1.3444e+00,\n",
      "        -2.7716e-01, -4.2835e-01,  7.4365e-01,  2.9223e+00, -4.5738e-01,\n",
      "         5.4278e-01, -5.7014e-01,  7.1328e-02,  8.9647e-02, -9.2141e-01,\n",
      "        -6.2913e-01,  1.2057e+00, -3.9178e-01, -1.9416e-01, -4.5161e-02,\n",
      "        -6.1623e-01,  8.6702e-01,  2.2011e-02, -1.2333e-01, -6.3390e-01,\n",
      "        -3.3709e-03, -8.1178e-01,  9.2035e-04, -7.8603e-01, -7.9457e-01,\n",
      "        -5.9934e-01, -1.3205e+00,  4.9306e-01,  9.3224e-01,  1.6458e+00,\n",
      "        -7.4206e-01,  2.5990e+00,  1.1172e+00,  2.8851e-01, -8.7960e-01,\n",
      "         1.3629e+00, -1.9656e+00,  2.5617e-01,  8.4054e-02, -1.0363e+00,\n",
      "         1.0632e+00, -7.0672e-01,  3.4878e-02, -3.1775e-01, -3.6903e-01,\n",
      "        -5.2527e-01,  1.9225e+00,  5.5079e-01, -5.4324e-01, -4.0322e-02,\n",
      "        -5.2350e-01, -3.4843e-02,  1.5493e-01,  3.4754e-01,  2.9376e-01,\n",
      "        -9.7488e-01,  4.5223e-01, -6.3757e-01,  5.8201e-01,  6.8934e-01,\n",
      "        -8.1416e-01,  6.3956e-02,  7.2946e-01, -4.3085e-01,  1.8658e-01,\n",
      "         1.6555e+00, -4.3401e-01,  6.1256e-01, -6.0991e-01,  4.1184e-01,\n",
      "         3.7935e-01, -2.2613e+00,  4.1359e-01, -1.2959e-01, -7.5342e-02,\n",
      "         1.1310e+00, -2.1675e-01, -7.4416e-01, -1.0831e+00,  3.2367e-01,\n",
      "         2.6574e+00,  5.0494e-01, -1.0228e-02, -9.2577e-02, -5.2511e-01,\n",
      "         1.8168e-01, -5.0644e-01,  3.2748e-01,  1.7039e+00, -2.7271e-01,\n",
      "        -4.4200e-01,  1.9144e-01, -8.8518e-01, -8.2624e-01, -1.9479e-01,\n",
      "         1.8991e+00, -1.6181e+00,  3.3354e-01, -1.3319e-01, -1.1006e+00,\n",
      "        -1.7106e+00, -8.6754e-01, -1.3984e+00,  1.5390e+00, -1.9382e+00,\n",
      "         1.5896e+00, -7.5260e-01,  2.5393e+00, -3.0394e-01, -1.1364e+00,\n",
      "         8.0678e-01,  1.8708e+00,  9.8046e-01, -1.1970e-01,  2.7167e-01,\n",
      "        -5.1530e-01,  1.2693e+00,  1.4076e-01, -2.0054e-01,  2.0143e-03,\n",
      "         1.9858e+00,  5.6385e-01, -9.2208e-02, -1.1737e+00,  6.0142e-02,\n",
      "         4.4104e-01,  6.7966e-01, -1.3927e+00, -3.1879e-01,  4.5396e-02,\n",
      "         1.1022e+00,  6.9202e-01,  2.5356e-01, -6.0935e-01,  6.5251e-01,\n",
      "         1.8234e+00, -2.0303e+00,  8.5154e-01, -1.6643e+00,  7.0373e-01,\n",
      "         2.4005e-01, -8.1441e-01, -6.6965e-01, -1.7196e+00, -3.6776e-01,\n",
      "        -2.7308e-01,  1.3408e+00, -1.2724e+00,  5.2704e-01,  1.6128e+00,\n",
      "        -3.6281e-01, -1.1905e+00,  1.1060e+00,  8.6715e-01, -1.1314e+00,\n",
      "        -7.5841e-01,  7.6244e-01,  7.3123e-01, -1.4249e+00, -4.1573e-01,\n",
      "        -1.0325e+00, -8.9507e-01, -9.0136e-01, -1.6726e-01,  9.3483e-01,\n",
      "        -2.1547e+00, -1.5732e+00, -3.4471e-01,  1.7268e+00,  8.0088e-01,\n",
      "         1.3355e+00, -5.5765e-01, -3.9640e-01,  2.5994e+00,  1.1797e-01,\n",
      "        -4.0343e-01, -4.4644e-02,  2.9297e-01, -3.6917e-01,  6.7537e-01,\n",
      "        -3.9989e-01, -1.2825e+00, -5.5281e-01, -1.4855e+00, -3.4809e-01,\n",
      "        -2.3615e-01, -5.7473e-01, -7.0779e-01,  8.6640e-02,  1.7038e+00,\n",
      "         1.5262e+00, -1.0350e+00,  9.0777e-01, -1.2630e+00, -1.8308e+00,\n",
      "        -9.1376e-01,  1.0081e+00,  1.3042e+00,  2.6587e-01, -2.7469e+00,\n",
      "         1.6079e+00,  9.4090e-01, -2.5426e-01,  6.0803e-01, -9.7208e-01,\n",
      "         2.0326e-01, -1.1749e+00, -1.0172e+00, -5.6559e-01,  4.6678e-01,\n",
      "        -2.5536e+00,  1.2424e-01,  9.0652e-01, -5.8356e-01,  9.9364e-01,\n",
      "         9.1377e-01, -6.6734e-01,  4.2957e-01,  1.9691e-01,  7.2254e-01,\n",
      "        -3.5616e-02, -3.4406e-01,  1.1517e+00, -3.7665e-01, -7.5363e-01,\n",
      "        -6.6287e-01,  1.2925e+00, -1.3070e-01, -5.7267e-01, -7.2522e-01,\n",
      "        -7.7650e-02, -4.1551e-01,  4.6619e-01, -1.0945e+00,  1.2272e+00,\n",
      "         1.0224e+00, -5.9379e-01,  1.2127e+00,  2.8996e-01,  1.3671e+00,\n",
      "        -1.4205e+00, -7.3495e-01,  1.1943e+00,  4.0114e-01, -4.6573e-01,\n",
      "        -1.2383e+00, -7.7904e-01, -6.9075e-03,  6.5462e-01,  6.8300e-01,\n",
      "         1.0939e+00, -6.3060e-01, -1.0879e+00, -2.0927e+00, -8.2494e-01,\n",
      "        -1.3108e-01, -4.2872e-01,  1.3897e+00,  9.0079e-01, -6.0812e-01,\n",
      "         3.0732e-01, -2.7198e-03, -6.6347e-02,  1.5462e+00, -9.1503e-01,\n",
      "        -1.2471e+00, -7.3715e-01,  1.9529e-01, -1.6806e+00,  4.8216e-02,\n",
      "         1.0336e+00,  7.5914e-02, -2.0273e+00,  7.8878e-01, -6.3272e-01,\n",
      "        -5.8375e-01, -6.4758e-01,  7.8724e-01,  1.0826e+00, -2.8404e-01,\n",
      "         2.6229e-01, -1.0404e+00,  9.5264e-01,  5.5354e-01,  1.3993e-01,\n",
      "        -1.2291e+00,  5.4386e-01,  1.1611e+00, -4.6418e-01,  4.8104e-01,\n",
      "        -1.9429e+00,  6.4798e-01, -2.0719e+00,  8.7743e-01,  5.0119e-01,\n",
      "        -1.2414e+00, -1.0663e+00,  1.2621e+00, -4.3747e-01, -3.0905e-01,\n",
      "        -8.8574e-01, -1.4226e+00,  8.9434e-01, -2.0971e-01, -4.9521e-01,\n",
      "        -5.9181e-01,  1.0361e+00, -1.3326e+00, -8.6198e-01,  2.2239e+00,\n",
      "         5.7154e-01,  6.0220e-01, -4.5682e-01,  1.2435e+00,  2.6136e+00,\n",
      "        -4.2771e-01,  6.9748e-01,  3.6784e-01,  8.6371e-02,  4.6615e-01,\n",
      "         9.4209e-01, -2.0541e+00, -3.8440e-02,  1.0027e+00,  8.9743e-02,\n",
      "         4.6163e-01, -6.0263e-01, -5.8338e-02, -1.4386e+00,  1.3128e+00,\n",
      "         7.4674e-01,  4.6973e-01,  1.9083e-01, -6.2578e-01,  2.3973e-01,\n",
      "         1.8889e+00,  8.5144e-01,  4.6531e-02,  2.0274e+00, -2.2741e+00,\n",
      "         7.9797e-01, -7.8016e-01,  8.2531e-01, -7.6545e-01, -6.7248e-01,\n",
      "         2.9990e-01, -7.6820e-01,  6.1055e-01, -1.6320e+00, -3.8189e-01,\n",
      "         1.2143e+00, -6.8004e-01,  1.0887e+00, -1.5331e-01,  2.5624e+00,\n",
      "         8.7466e-01,  9.4987e-01, -6.6716e-01, -1.0366e+00, -1.1186e+00,\n",
      "         9.6666e-01, -1.5016e+00,  1.7656e+00,  1.2098e-01,  7.1731e-01,\n",
      "         1.0504e+00, -1.6932e-03, -1.0766e-01,  7.2868e-01,  5.7044e-01,\n",
      "        -2.1938e-01, -4.0228e-01,  9.9575e-01,  3.7803e-01, -2.5943e-01,\n",
      "        -4.5628e-01,  1.6184e-01, -2.3731e+00,  8.4397e-02,  5.1150e-01,\n",
      "        -1.5300e+00,  5.4968e-01,  3.6047e-01,  5.1280e-01, -1.2257e+00,\n",
      "        -2.0224e+00, -5.2695e-01,  6.3768e-01, -5.6875e-02, -1.5801e+00,\n",
      "        -1.3318e+00,  1.9213e+00, -2.1507e-01, -8.9387e-01,  5.0843e-01,\n",
      "         2.8631e-01, -8.6693e-01,  1.5268e+00, -2.4710e-01,  5.3634e-01,\n",
      "         2.9096e-01, -1.9699e+00,  3.2761e-01,  2.8163e-01,  5.0453e-01,\n",
      "        -7.2097e-01, -6.1230e-01,  2.9704e-01, -2.7295e-01,  2.7158e-02,\n",
      "         7.0859e-01,  1.5206e-01,  1.4713e+00, -1.3316e+00,  1.3795e+00,\n",
      "         1.9506e+00, -1.1009e+00,  7.0691e-01,  6.0001e-01, -1.3092e+00,\n",
      "        -1.2417e+00,  3.7510e-01,  6.0581e-01,  1.1512e-01, -4.4732e-01,\n",
      "         1.2392e+00, -3.9607e-01, -1.4162e+00, -9.5584e-01, -8.2484e-01,\n",
      "        -5.2944e-01,  1.7402e+00,  6.4705e-01, -5.2779e-01, -5.5571e-01,\n",
      "        -4.1478e-01,  4.0932e-01, -1.6654e-01, -1.9314e+00,  9.8119e-01,\n",
      "        -4.9792e-01,  2.6543e-01,  1.4341e-01,  4.3637e-01,  6.2585e-01,\n",
      "         3.2907e-01,  7.4511e-01, -4.9345e-01,  6.9612e-01,  7.1460e-01,\n",
      "        -1.8775e+00, -5.1788e-01, -2.1937e-02, -1.2420e+00,  6.7708e-01,\n",
      "        -1.1313e+00, -7.1972e-01, -7.8077e-01, -4.2611e-01,  1.3073e+00,\n",
      "        -2.1121e+00,  1.5393e-01,  1.1377e+00,  6.4986e-02,  1.3290e+00,\n",
      "        -2.7053e-01,  9.6093e-01, -1.0525e+00,  1.6742e+00,  3.2030e-01,\n",
      "         6.6861e-01,  1.1105e+00,  1.4996e+00, -9.1968e-01, -3.0627e-02,\n",
      "         1.6959e+00, -9.3388e-01, -6.0709e-01, -1.6573e-01, -1.1438e+00,\n",
      "         1.1289e+00, -5.0477e-01,  9.1511e-01,  1.4575e+00, -1.5958e+00,\n",
      "        -1.4094e+00,  5.5654e-01, -5.3559e-01,  1.1265e+00, -2.9638e-01,\n",
      "        -2.3865e+00, -1.3946e+00,  2.0377e-01, -1.6409e-01,  1.6587e-01,\n",
      "        -4.6841e-01,  3.7158e-01])\n",
      "span length: 2\n",
      "span position embedding: tensor([[ 0.2646, -0.2359,  0.4529,  ..., -0.5603,  0.3245,  0.3620],\n",
      "        [-0.0196, -0.8800,  1.0720,  ...,  1.2667, -0.2152, -0.3769]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "span position embedding shape: torch.Size([2, 512])\n",
      "p_h: tensor([ 2.6463e-01, -2.3591e-01,  4.5285e-01, -1.1136e-01,  3.0407e-01,\n",
      "        -2.3966e-01, -2.7644e-02,  1.2563e+00,  3.6182e-01,  1.9652e-01,\n",
      "        -8.6246e-01, -7.1119e-01, -1.1506e+00, -8.6195e-01,  1.2013e+00,\n",
      "         1.3645e+00, -4.7164e-01, -1.0417e-02,  5.2249e-01,  1.8408e-01,\n",
      "        -1.4745e-01,  1.5400e+00, -1.0897e+00,  1.2691e+00, -1.9417e+00,\n",
      "        -2.5694e-01,  5.3591e-01,  4.6418e-01, -1.1935e+00,  1.5731e+00,\n",
      "         4.0055e-01,  1.6647e+00,  3.1474e-01, -5.1079e-01, -4.6470e-01,\n",
      "        -1.6623e+00, -1.9396e-02, -1.8199e+00, -4.0583e-01,  8.2175e-02,\n",
      "        -5.3666e-02, -6.3857e-01,  2.9397e-01,  5.2579e-01, -2.1096e+00,\n",
      "         1.7281e+00,  3.8924e-01,  3.7421e-01,  8.1201e-01,  6.8693e-01,\n",
      "        -1.9785e+00,  2.4820e-01,  6.1537e-01, -2.1311e+00,  1.0837e+00,\n",
      "         5.3762e-01,  4.5211e-01,  1.4208e+00,  1.8105e+00,  9.5980e-01,\n",
      "         6.4874e-01,  1.0742e+00,  1.9713e-01, -6.1546e-01, -3.3916e-01,\n",
      "        -3.3302e-02, -1.1120e+00,  1.2290e+00,  3.2036e-01,  4.7312e-01,\n",
      "        -1.0821e-01, -1.0119e+00,  7.7355e-01, -7.3499e-01, -1.4620e+00,\n",
      "         6.8714e-01, -1.4982e+00,  3.4491e-01, -1.1672e+00,  4.2549e-01,\n",
      "         1.1212e+00, -1.4065e+00,  2.5087e-01,  3.4171e-01,  3.1139e-01,\n",
      "         8.3637e-01,  1.2320e+00,  1.0655e-01,  8.9789e-01,  2.3202e-01,\n",
      "        -1.8274e+00,  3.1027e-01,  2.1902e-01, -2.4660e-01,  9.7873e-01,\n",
      "         3.6632e-01,  5.2638e-01,  4.3381e-01, -5.1404e-02,  9.4305e-02,\n",
      "         5.2549e-01, -5.7886e-01,  9.5275e-01, -9.3557e-01,  4.2693e-01,\n",
      "         1.2856e+00,  1.7819e-01,  1.1278e+00, -6.1495e-01,  1.0691e-01,\n",
      "         1.4019e+00, -1.9541e-01, -2.7272e-01, -5.9999e-01,  1.3753e+00,\n",
      "         4.8390e-01, -5.9446e-01,  6.2681e-01,  1.0675e-01,  2.6720e+00,\n",
      "        -4.6258e-01,  1.1697e+00,  1.0102e-01,  5.9059e-01, -1.1562e-01,\n",
      "         1.8833e+00, -1.9221e+00,  8.4052e-01,  1.2141e+00, -1.5262e+00,\n",
      "         1.3867e+00,  5.7718e-01,  7.7591e-01,  1.4728e+00,  2.4874e+00,\n",
      "        -5.0059e-01,  9.5103e-03,  3.5364e-01,  1.4312e+00, -4.0655e-01,\n",
      "         1.3028e+00, -2.3050e-01,  4.9509e-01, -1.8871e-03,  6.7407e-01,\n",
      "         1.6877e+00,  7.6270e-01, -1.0258e+00, -1.0028e+00, -7.8825e-01,\n",
      "         2.5775e-01, -7.2426e-01,  2.5744e-03, -2.3219e+00,  6.9216e-01,\n",
      "         2.6199e-01, -6.8344e-01,  1.6513e+00,  8.0119e-01, -9.5820e-01,\n",
      "         1.4848e-01,  4.2119e-01,  5.4669e-01, -5.4224e-01,  1.3896e+00,\n",
      "         5.5137e-01, -2.9887e+00, -8.5112e-01, -8.3678e-01,  4.3097e-01,\n",
      "        -8.2797e-01,  1.8303e-01, -8.1399e-01,  3.0334e-01,  4.3765e-01,\n",
      "        -1.6117e+00,  4.6604e-01, -1.1909e+00, -1.7815e-01,  4.5396e-01,\n",
      "         1.3874e+00,  1.3422e+00, -7.1142e-02, -5.3129e-01,  4.9093e-01,\n",
      "         8.8818e-01,  6.9741e-01, -4.1026e-01, -4.8009e-01,  7.1111e-01,\n",
      "        -3.7213e-01, -4.3906e-01,  1.4767e+00,  7.1079e-02, -1.7537e-01,\n",
      "        -1.1809e+00,  5.6096e-01, -6.4618e-01,  1.1893e+00,  1.5120e+00,\n",
      "         1.3990e+00, -6.8395e-01,  1.5880e-01, -5.5990e-01, -2.6268e-01,\n",
      "         5.4497e-01, -1.2274e+00,  2.7820e-01, -3.6112e-01,  9.7976e-01,\n",
      "         2.9502e-01,  5.4370e-01,  8.3105e-01,  1.8538e+00, -5.3877e-01,\n",
      "        -9.5267e-01, -9.1673e-01,  1.2531e-03, -2.0213e+00,  9.8051e-01,\n",
      "        -8.8374e-01, -4.2150e-02, -1.6528e+00,  1.9307e-01,  1.5692e+00,\n",
      "        -1.4780e+00, -9.2722e-01,  6.9250e-01, -1.8756e+00,  5.8865e-01,\n",
      "         4.9594e-01,  1.3061e+00, -7.3392e-01,  7.4737e-01,  5.5305e-01,\n",
      "        -1.4458e+00,  6.7631e-01, -2.8349e-01, -4.1311e-02,  9.9215e-01,\n",
      "        -7.9370e-01, -1.3216e+00, -3.7143e-01, -1.9428e-01,  1.7150e+00,\n",
      "        -8.5702e-01,  7.9772e-01,  8.0723e-01,  5.9285e-01, -1.7337e+00,\n",
      "        -3.6545e-01, -3.0930e-02,  9.5934e-02,  7.5442e-01,  2.2453e+00,\n",
      "         6.7726e-01, -1.8739e+00,  3.4552e-01,  1.1640e+00, -3.9320e-01,\n",
      "         5.5008e-01, -6.4734e-01,  2.0954e-01, -1.1305e+00, -7.5992e-01,\n",
      "         8.4470e-01,  1.9466e+00, -1.0329e+00,  1.2538e+00, -1.1546e-01,\n",
      "         1.4509e-01,  1.6514e+00, -1.4655e+00, -7.7295e-01,  1.8134e-01,\n",
      "        -1.8199e-01, -2.2637e-01, -1.4556e+00,  4.7327e-01,  5.7220e-01,\n",
      "         1.1069e+00,  5.3194e-01, -1.1256e+00, -3.2274e+00,  6.3759e-01,\n",
      "         4.2993e-03,  1.2920e-01, -3.1513e-03,  8.9170e-01,  5.2861e-01,\n",
      "        -2.7012e-01, -9.0175e-01, -1.6887e+00, -9.3186e-01,  3.1375e-01,\n",
      "        -1.5741e-01, -1.2657e+00, -2.7680e-03, -6.1508e-01,  1.6279e+00,\n",
      "         1.0891e-01, -1.2797e-01, -1.7622e+00, -1.5778e+00, -4.4926e-01,\n",
      "        -2.8947e-01, -2.0997e-01, -1.2714e+00, -3.0723e-01, -1.7475e+00,\n",
      "        -4.5016e-01, -2.0889e+00, -5.9639e-02, -1.2555e-01,  2.8605e-01,\n",
      "        -1.1658e+00,  1.7329e-02, -1.2733e+00,  6.8152e-01, -7.8875e-01,\n",
      "        -3.6547e-01, -2.8417e-01, -7.3583e-01, -6.6815e-01, -2.2105e-01,\n",
      "        -2.5366e-01, -6.1688e-01,  1.3577e+00, -4.7580e-03, -4.3801e-01,\n",
      "         1.0144e+00,  9.6206e-02,  1.1831e+00, -1.0204e+00, -7.2906e-01,\n",
      "         1.1042e+00,  1.0556e+00, -3.3137e-01, -5.8628e-02,  1.6092e+00,\n",
      "         6.9107e-01,  9.4272e-01, -4.0911e-01,  4.8866e-01, -9.8013e-01,\n",
      "        -5.3689e-01,  1.5416e-01, -4.8419e-01, -1.2030e+00, -1.8621e-01,\n",
      "         1.4200e+00, -5.6757e-01, -1.2296e+00, -8.0300e-01,  8.2033e-01,\n",
      "         9.9433e-01,  3.8412e-01, -2.9066e-01,  1.2961e+00, -5.4361e-01,\n",
      "        -1.3810e-01,  2.6702e-01,  3.3126e-01, -3.1704e-01, -9.3242e-01,\n",
      "         3.7303e-01, -3.5497e-01, -6.0568e-01,  6.2027e-01,  2.3453e-01,\n",
      "        -4.7209e-01,  3.3481e-02,  2.1820e-02, -5.8500e-01, -5.3081e-01,\n",
      "        -6.4882e-01,  2.2216e+00, -7.2217e-01, -2.9424e-01, -1.1246e+00,\n",
      "        -9.9307e-01, -8.4144e-01, -1.7093e+00,  7.5401e-01,  2.0645e-01,\n",
      "        -4.3273e-01, -1.7653e+00, -2.1502e-01,  4.2585e-01, -6.9993e-01,\n",
      "        -1.1024e+00,  9.1361e-01, -1.4485e-01, -1.9265e-01, -1.3256e+00,\n",
      "        -2.3604e-02, -1.9355e+00, -1.0227e+00,  1.1890e+00,  5.9773e-01,\n",
      "        -8.6292e-01, -3.0950e-03, -8.2854e-01,  5.9784e-01, -6.1528e-01,\n",
      "        -1.2698e+00,  5.7545e-01, -8.4002e-01,  1.3896e-01, -9.3209e-02,\n",
      "         7.3866e-01,  7.1812e-01, -6.1141e-01, -3.4375e-02, -1.0954e+00,\n",
      "         1.8022e-01,  3.2163e-01,  7.7503e-02, -1.0133e+00,  1.1984e+00,\n",
      "         9.1484e-01, -4.9774e-01,  2.1523e+00, -1.2008e-01,  3.3075e-02,\n",
      "        -4.0801e-01,  9.1579e-01, -6.9246e-01,  1.2818e+00, -1.7857e+00,\n",
      "         1.8785e+00,  7.0748e-02,  1.3929e+00,  2.0655e-01, -1.2619e+00,\n",
      "        -2.3901e-01,  1.2071e+00,  1.6173e+00, -1.3642e+00,  2.3291e+00,\n",
      "        -6.8836e-01,  8.9147e-01,  1.5207e+00, -1.8084e-01, -1.9412e-01,\n",
      "         7.5915e-01, -1.8645e+00,  5.3172e-01, -8.7955e-01, -2.4235e+00,\n",
      "        -1.0345e+00, -5.3043e-01, -1.7635e+00,  4.9432e-01, -1.3330e+00,\n",
      "         1.0709e+00,  9.4012e-02,  6.9564e-02, -5.0142e-01,  4.6696e-01,\n",
      "        -9.9967e-01,  9.0375e-01,  5.6307e-01, -1.6594e+00, -1.1686e-01,\n",
      "         2.4648e+00,  1.8703e+00,  1.4332e+00,  7.1619e-01,  2.5616e+00,\n",
      "        -2.2084e+00,  1.5308e+00, -1.2692e+00,  1.3647e-01,  1.0541e+00,\n",
      "         3.5369e-01,  1.0998e+00, -1.7216e-01,  1.3324e+00,  4.7375e-01,\n",
      "        -1.0231e+00,  7.9570e-01,  1.3606e+00,  2.0566e-02,  8.9172e-01,\n",
      "        -1.8407e+00,  1.8103e-01,  8.0128e-01,  9.9860e-01,  7.4569e-02,\n",
      "        -6.2979e-01, -1.1183e+00,  7.5391e-01,  2.5534e-01, -1.0144e+00,\n",
      "        -4.8885e-01, -1.3235e-01, -5.8060e-01,  5.4132e-02, -1.5560e+00,\n",
      "        -2.2478e+00,  9.4176e-01, -1.2558e+00,  4.1022e-01, -8.7279e-01,\n",
      "         8.9475e-02,  5.2558e-01, -1.1772e+00, -9.8584e-01, -5.6031e-01,\n",
      "         3.2450e-01,  3.6195e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.9598e-02, -8.8004e-01,  1.0720e+00, -2.7167e-01, -1.1181e-01,\n",
      "         1.2305e+00, -7.0031e-01, -4.4509e-01, -1.0202e+00,  1.7274e+00,\n",
      "         2.6604e-01, -2.7644e+00, -2.9702e-01,  7.5236e-01, -5.5668e-01,\n",
      "        -5.4757e-01,  1.4329e+00,  3.3933e-01, -2.2905e+00, -6.3927e-02,\n",
      "        -3.9277e-01, -1.3286e+00, -1.0442e+00,  6.3118e-01, -3.9864e-01,\n",
      "         1.1672e+00,  4.9961e-01, -2.4401e+00,  2.0224e+00,  1.4115e-01,\n",
      "         2.9880e-01, -1.7060e-01, -1.0577e+00,  7.1500e-01,  2.9370e-01,\n",
      "        -4.2851e-02, -3.0085e-01, -1.7421e-03, -4.0230e-01,  5.1137e-01,\n",
      "         7.4943e-01, -1.8208e-01,  2.6125e-01, -5.7877e-01,  2.7831e+00,\n",
      "         2.1889e+00, -1.2854e+00,  1.0939e+00,  2.9090e+00, -1.5365e+00,\n",
      "        -1.7057e+00,  1.0591e+00,  2.0244e+00,  2.2355e+00, -1.9716e+00,\n",
      "         1.3339e+00, -1.1843e+00, -1.5504e+00,  3.8147e-01, -1.5133e-01,\n",
      "         2.9308e-01,  9.4728e-01,  5.1063e-01, -9.4425e-01,  4.7430e-01,\n",
      "         3.3420e-01,  4.3306e-01, -1.4448e+00,  1.1767e-01,  2.6016e+00,\n",
      "        -1.0885e+00,  7.2074e-01, -8.0917e-01,  6.9210e-01, -5.1269e-01,\n",
      "         5.4817e-01, -3.4270e-02,  7.2508e-01,  4.0123e-01,  6.3323e-01,\n",
      "         1.3014e+00, -2.5752e-01, -3.7336e-01,  2.4239e-01, -7.1877e-01,\n",
      "        -1.3336e-01,  8.0229e-01,  1.1414e+00,  3.2048e-01, -1.1728e+00,\n",
      "         5.7086e-01, -1.9970e-01, -9.0181e-01, -7.4187e-01, -1.1517e+00,\n",
      "        -4.8143e-01,  3.5825e-02,  8.8615e-01, -8.7241e-01,  7.4572e-01,\n",
      "        -1.0059e+00, -1.2884e+00, -1.4603e+00, -8.2570e-01, -1.4340e-01,\n",
      "        -6.6732e-01, -5.6294e-01,  1.2165e+00,  1.0110e+00, -2.2715e+00,\n",
      "         5.6288e-01, -2.4479e-01,  1.4545e+00,  4.1549e-01, -1.3575e+00,\n",
      "        -7.9776e-02,  1.3199e+00,  5.7921e-01, -7.9095e-01,  9.1039e-01,\n",
      "         2.1433e+00, -1.6521e+00, -1.1074e+00, -5.2481e-01, -2.3083e-01,\n",
      "         1.4427e+00,  6.8813e-01,  9.2377e-01, -4.3607e-01, -6.7831e-01,\n",
      "         1.6607e+00, -6.0901e-01, -1.2238e+00, -1.2792e+00,  7.7615e-01,\n",
      "         1.7335e+00, -3.0826e-01, -1.6324e+00, -2.2841e-02,  7.7872e-01,\n",
      "        -2.3813e-01,  1.7590e+00, -2.6300e+00, -2.2589e+00, -5.7844e-01,\n",
      "        -1.0014e+00, -4.4668e-01, -1.0133e+00,  2.3634e-01, -5.3267e-01,\n",
      "        -9.9985e-01, -2.1989e+00, -3.7624e-01,  6.5364e-01,  7.5254e-01,\n",
      "        -1.3376e+00,  9.7770e-01,  1.1336e+00,  4.7673e-01,  2.9082e-01,\n",
      "        -1.3255e-01,  1.1891e+00, -1.3592e+00,  1.4276e+00,  1.0099e+00,\n",
      "        -2.0686e-01,  4.7024e-01,  6.6699e-01, -1.2182e+00,  4.1511e-01,\n",
      "         3.4016e-01, -1.3129e+00,  6.7744e-01, -9.9545e-01, -1.2289e+00,\n",
      "         1.6814e+00,  1.7367e-01,  4.4566e-01, -3.4744e-01,  7.7216e-01,\n",
      "        -7.9999e-01,  1.0696e+00, -1.9791e+00,  7.5679e-01, -6.2594e-01,\n",
      "         3.3649e-01,  3.2236e-01,  9.3129e-01, -2.6896e-01, -1.1185e+00,\n",
      "         1.2515e+00, -1.4685e-01, -7.1486e-02, -4.7896e-01,  2.8939e-02,\n",
      "        -1.6243e-01,  2.5263e-01,  7.6768e-01,  6.1950e-01, -9.7351e-01,\n",
      "        -8.4524e-01,  1.6915e+00, -7.3563e-01, -3.6067e-02, -1.9589e+00,\n",
      "        -8.4760e-02, -1.7551e-01,  2.5339e+00,  1.2955e+00, -2.5083e+00,\n",
      "         1.0164e+00, -2.3493e+00,  4.3328e-01, -4.7192e-01,  3.8348e-02,\n",
      "         2.2390e-01, -6.9014e-02, -1.4051e-01,  7.9474e-01, -1.8916e-01,\n",
      "         1.6112e-01, -1.3122e+00,  1.0782e+00, -8.3441e-01,  4.5891e-01,\n",
      "        -9.0378e-01,  1.0776e+00,  3.5492e-01,  6.7974e-01,  8.5984e-01,\n",
      "         6.2570e-02,  4.7049e-01,  4.9977e-02, -5.9910e-02,  5.8082e-01,\n",
      "         7.0209e-01,  1.8570e+00,  3.3905e-01, -3.4004e-01,  9.5000e-02,\n",
      "        -7.0462e-01, -1.1546e+00,  2.6067e+00,  2.8814e-01,  9.5239e-01,\n",
      "        -6.3638e-01, -2.4426e-01, -1.0868e+00,  4.2619e-01,  1.0016e-01,\n",
      "        -7.8702e-01, -5.4084e-01, -1.4274e-01, -1.9805e-02, -7.1918e-01,\n",
      "         1.7290e-01, -1.2436e+00,  3.1620e-01, -1.0714e+00,  6.6434e-02,\n",
      "        -4.5941e-01,  7.2912e-02,  6.2007e-01,  5.5581e-01,  1.1954e+00,\n",
      "         2.0939e-01, -5.0785e-01,  2.0959e+00, -8.1876e-02,  4.2700e-01,\n",
      "         5.0943e-01,  1.4900e+00,  4.3161e-01,  1.8884e+00,  6.2704e-01,\n",
      "        -1.4820e+00,  2.1680e-01,  8.0652e-01, -2.0691e-01,  6.6663e-02,\n",
      "        -4.1691e-01,  1.7703e+00,  6.1042e-01,  1.5419e+00, -3.6541e-01,\n",
      "         1.2856e+00, -8.3941e-01, -3.8372e-02,  7.4279e-01, -2.1912e-01,\n",
      "         1.5360e+00,  4.8248e-01,  8.2361e-01,  1.0086e+00, -8.2352e-01,\n",
      "         4.2431e-01,  8.4797e-01, -1.1859e+00, -4.4374e-01,  1.7759e+00,\n",
      "         2.6485e+00, -1.6682e+00,  1.4951e+00,  1.2841e-01,  9.0137e-01,\n",
      "        -5.5399e-01, -5.4908e-01, -1.6300e-01,  5.8974e-02,  7.7423e-01,\n",
      "        -1.1408e+00, -2.3258e+00,  1.7219e+00,  1.4725e+00,  4.4545e-01,\n",
      "         1.3608e-01, -3.4079e-01,  8.4047e-01, -1.5302e+00, -1.3600e+00,\n",
      "        -1.1235e+00, -1.1894e+00, -3.1683e-01, -8.8800e-01, -1.8915e+00,\n",
      "        -2.5639e-01, -2.3428e+00,  4.5652e-01, -4.4602e-01,  5.0303e-01,\n",
      "         7.9082e-01, -5.1529e-01, -7.5383e-01,  1.2808e+00, -1.0749e+00,\n",
      "        -6.3119e-01, -5.7263e-01,  2.3266e-01,  1.6130e+00, -2.6413e-01,\n",
      "        -1.5035e+00,  6.3873e-01,  3.8395e-01, -3.2821e-01, -9.4901e-01,\n",
      "         8.1626e-01,  1.2318e+00, -5.8183e-01,  7.6981e-01,  1.2267e+00,\n",
      "         2.7440e-01,  6.3441e-01, -1.2575e+00, -8.4964e-01, -1.4209e+00,\n",
      "        -2.0525e+00,  8.5586e-01, -2.0060e+00,  5.1493e-01,  4.4926e-02,\n",
      "        -1.1243e+00,  1.6439e+00,  3.8856e-02, -2.6801e-01,  3.7889e-01,\n",
      "        -1.6657e+00,  2.1121e+00,  4.7003e-01,  1.6673e+00,  1.4359e+00,\n",
      "         3.1666e-01, -1.8693e-01,  4.3260e-01, -7.3865e-01, -1.6888e-01,\n",
      "        -8.2745e-01,  4.4106e-01, -9.3589e-01, -6.0546e-01, -1.1373e+00,\n",
      "        -6.7438e-01,  6.9004e-01, -1.2898e+00, -8.5722e-01,  1.2332e+00,\n",
      "        -2.8805e-01, -5.1052e-01,  7.3412e-01,  6.2072e-01, -1.3678e-01,\n",
      "        -1.4201e-01, -7.5883e-03, -2.6767e+00, -7.6234e-01,  8.5236e-01,\n",
      "         5.6856e-02, -7.2773e-01,  1.2267e-01, -9.7834e-01,  5.1376e-01,\n",
      "         3.3411e-01,  1.3300e+00, -4.7372e-01, -1.1496e+00,  1.8684e+00,\n",
      "         7.2719e-01, -6.1977e-02, -1.3151e+00, -6.8870e-01,  8.6271e-01,\n",
      "         3.0699e-01,  5.7380e-01, -9.4069e-02,  4.6136e-01,  8.2800e-01,\n",
      "         3.8674e-01,  1.2559e-01, -4.6637e-01, -6.6718e-01,  7.6186e-01,\n",
      "         5.8211e-01,  1.2183e+00,  1.0905e-01,  3.3896e-01,  1.3243e+00,\n",
      "         2.9844e-01,  1.4861e+00,  4.9099e-01, -1.4104e+00,  1.1438e+00,\n",
      "        -1.6922e+00, -9.0433e-01, -7.5813e-01, -8.7738e-01, -3.2076e-01,\n",
      "        -4.6825e-01, -7.2635e-01,  1.1144e-03, -7.2225e-01, -3.4616e-01,\n",
      "         6.9479e-01,  1.1173e+00,  1.8688e+00,  2.0539e-01, -1.7454e-01,\n",
      "         6.0237e-01, -5.1255e-01, -7.0896e-01,  7.4415e-01,  6.1457e-01,\n",
      "        -1.3599e+00, -1.3151e+00, -9.6092e-01,  2.3501e-01,  4.3561e-01,\n",
      "        -5.8040e-01,  4.6350e-01,  1.0027e+00,  5.3332e-01,  6.2659e-01,\n",
      "         4.7085e-01, -2.4516e+00,  2.2334e-01, -7.2773e-01, -1.5475e-01,\n",
      "        -3.6478e-01, -5.8729e-01, -1.0755e+00,  8.3631e-01,  4.4258e-01,\n",
      "        -4.9116e-01, -1.7064e+00,  6.5128e-01, -1.7775e-01,  5.9177e-01,\n",
      "        -1.7584e+00,  2.9596e-01,  5.9606e-01, -1.0755e+00, -1.2221e+00,\n",
      "         1.5103e+00, -1.7211e+00, -3.5132e-01,  1.9871e+00,  8.4459e-01,\n",
      "         9.5885e-01,  2.2156e-01,  1.2679e+00, -2.6715e-02, -1.1446e-01,\n",
      "        -1.8737e+00, -3.3209e-01, -1.2168e+00, -1.2257e+00,  2.2572e-01,\n",
      "         1.2483e+00, -3.1807e-01,  9.7262e-01,  2.4968e-01,  6.2445e-01,\n",
      "         8.6025e-01,  5.9226e-01, -7.8353e-01, -1.0757e+00,  1.5338e+00,\n",
      "         1.4497e+00,  2.9066e-01,  1.6366e+00, -8.5775e-01,  1.2667e+00,\n",
      "        -2.1525e-01, -3.7695e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "start: 86, end: 90\n",
      "start embedding: tensor([-3.4511e-01, -2.0091e-01,  6.9464e-01, -7.4464e-01, -5.1197e-01,\n",
      "        -9.5332e-01,  2.0528e+00,  3.8576e-01,  7.1037e-01, -4.7012e-01,\n",
      "        -2.9593e-01, -5.2949e-01,  1.9064e+00,  9.5638e-01, -1.7220e+00,\n",
      "         4.6686e-01, -1.1432e+00,  6.6270e-01, -2.1959e-02,  1.2368e+00,\n",
      "        -1.0521e+00,  1.3459e+00,  9.8767e-01,  1.4633e+00,  1.7832e+00,\n",
      "        -1.0088e+00, -1.2780e+00,  9.2065e-01, -1.1337e-01, -2.9273e-01,\n",
      "        -2.7375e-01, -4.9944e-01, -1.9772e-01, -7.3081e-01, -1.8570e+00,\n",
      "         1.7371e-01, -3.0073e-01,  1.0585e+00, -1.3660e+00,  3.5104e-02,\n",
      "         1.0355e+00, -2.3213e-03,  2.1560e+00,  6.8416e-02,  6.9720e-01,\n",
      "        -3.0251e-01, -1.1654e+00,  1.4144e+00, -8.9484e-01, -9.7127e-01,\n",
      "         9.7935e-01, -1.4250e+00,  2.1722e-01,  1.7234e-01, -2.7987e-01,\n",
      "        -4.6934e-01,  5.1056e-01, -3.7873e-01,  7.8122e-01,  2.3563e+00,\n",
      "         1.3342e+00,  1.1210e+00, -1.6007e+00,  9.6448e-01, -9.5923e-01,\n",
      "        -5.6628e-02, -1.7513e-01, -1.1350e+00,  1.0143e+00,  4.4145e-01,\n",
      "         1.0127e+00, -5.1447e-01, -1.6657e-03,  8.6285e-01, -8.6617e-01,\n",
      "        -9.1683e-01,  9.6117e-01,  6.8294e-01, -5.5932e-02,  1.4260e+00,\n",
      "         7.2130e-01, -1.5678e+00, -1.5187e+00, -1.7223e+00, -1.0936e+00,\n",
      "        -1.2300e+00,  4.8216e-01,  1.1044e+00,  1.1699e+00,  4.7833e-01,\n",
      "         3.5415e-01, -1.6256e+00, -1.6654e-01,  3.4291e-01,  1.4177e-01,\n",
      "        -1.1303e+00,  1.7687e+00,  1.3811e+00, -6.2232e-01, -8.4714e-01,\n",
      "        -4.1556e-01, -4.0950e-02,  1.2789e+00, -7.6195e-01, -2.2298e+00,\n",
      "        -7.5127e-01,  5.4504e-01, -2.3416e-02, -6.7093e-01, -2.2883e+00,\n",
      "        -1.2139e+00,  6.8799e-02, -1.3759e+00,  9.0909e-01,  3.9626e-02,\n",
      "        -6.0401e-01,  1.3051e+00, -7.6252e-01,  1.4729e+00,  3.4468e+00,\n",
      "         1.5596e+00, -1.1967e-01, -1.2614e-01,  2.1036e-01, -2.6328e-02,\n",
      "         2.0465e-01, -3.2238e-02,  1.8580e+00,  2.5073e-01, -6.1396e-01,\n",
      "        -1.0154e-01, -3.8537e-01,  3.0753e-01,  2.9193e-02, -4.0421e-01,\n",
      "         2.4624e-01, -1.1665e+00,  2.4298e+00,  1.0416e+00,  3.4379e-01,\n",
      "         8.7025e-01, -1.6247e+00,  7.1706e-01,  2.9835e-01,  1.8737e+00,\n",
      "         1.6373e+00,  5.5823e-01, -3.5258e-01, -5.7512e-01, -6.2157e-02,\n",
      "        -1.1356e+00,  5.6184e-01, -1.6662e+00, -7.1966e-01, -1.9913e+00,\n",
      "         2.6273e-01,  9.1375e-02,  3.8643e-02, -2.1116e-01,  1.7440e+00,\n",
      "         8.3913e-01,  1.7618e-01,  2.9602e-01, -1.9259e+00,  2.6461e+00,\n",
      "        -6.9497e-01,  7.8173e-01, -5.5145e-01,  1.0428e+00, -8.5984e-02,\n",
      "        -5.5125e-01,  1.0936e-01,  1.2232e+00,  3.6245e-01,  8.5056e-01,\n",
      "         1.6344e-01,  7.5024e-01, -1.2497e+00,  5.4698e-01,  5.4900e-01,\n",
      "         1.2733e+00, -1.0765e+00,  5.0590e-01, -4.1840e-01, -2.6331e-01,\n",
      "         1.4300e+00, -4.0607e-01, -9.3933e-01, -5.8094e-01,  8.8791e-01,\n",
      "         1.7236e+00,  1.5438e+00, -3.1542e-01,  2.5315e-01, -9.7068e-01,\n",
      "        -2.3972e-02, -5.7260e-01,  1.1258e+00, -4.2333e-01, -8.7346e-01,\n",
      "        -1.6513e+00, -8.5117e-01, -1.5721e+00,  2.6718e-01,  2.2265e-01,\n",
      "         1.1676e-01, -1.3452e+00,  2.0584e-01, -1.1032e-01,  7.4715e-01,\n",
      "         5.9694e-01,  5.9009e-01, -1.5073e+00,  5.7651e-01,  3.7867e-01,\n",
      "         1.0616e-01, -1.0473e-01, -5.7844e-01,  1.4020e+00, -2.3105e-01,\n",
      "        -6.0064e-02, -2.3190e+00, -2.4896e-01,  8.7269e-01, -2.3015e-02,\n",
      "        -2.3483e-01,  3.8652e-01, -1.2916e+00,  1.8955e+00,  2.4593e-01,\n",
      "         8.3331e-01,  1.1295e+00, -1.4556e+00,  1.2057e+00, -1.4956e-02,\n",
      "         1.4021e-01, -9.5062e-01,  1.8124e-01, -3.6936e-01,  7.6422e-01,\n",
      "        -6.3401e-01, -5.0110e-01, -1.9463e+00,  8.2641e-01, -2.1121e-01,\n",
      "        -1.1780e+00,  2.7402e-01, -3.0051e-01, -2.1249e-01,  1.7620e+00,\n",
      "        -1.3403e+00, -2.0041e-02,  8.5770e-01, -1.6354e-01,  1.1619e+00,\n",
      "        -3.2488e-02, -4.2473e-01, -1.7043e-02, -1.1708e+00,  1.0481e+00,\n",
      "         7.3856e-01,  1.8194e-01, -9.7077e-01,  1.0332e+00, -6.3078e-01,\n",
      "        -8.0633e-02,  7.6681e-01,  1.8609e+00,  1.2126e+00, -1.7995e+00,\n",
      "         1.0934e+00, -1.9464e+00, -3.0860e-01, -9.4653e-01, -1.6307e+00,\n",
      "        -1.0631e+00,  3.2439e-01,  3.2126e-02, -8.5076e-01,  1.6938e-01,\n",
      "        -8.7071e-01, -1.0098e+00,  1.0492e+00, -2.8663e-01,  5.0946e-01,\n",
      "        -1.5702e+00, -3.3211e-01, -1.2602e-02,  6.2837e-01,  1.5127e+00,\n",
      "        -6.2004e-01,  5.9337e-01,  3.8524e-01,  3.6407e-01,  1.2484e+00,\n",
      "        -2.2653e+00,  7.2044e-01,  9.7247e-02,  2.2890e-01,  1.8158e-01,\n",
      "         2.8596e-01,  1.5406e+00,  6.9893e-02, -9.4071e-01, -1.1812e+00,\n",
      "         5.2264e-02,  1.2168e+00,  1.4084e-01,  9.7588e-01,  9.7962e-01,\n",
      "        -5.8703e-01,  2.3024e-01,  3.0344e-01,  7.0195e-01,  5.8683e-01,\n",
      "        -1.9571e-01, -2.4648e-01,  1.3599e+00, -9.8965e-01,  4.5254e-01,\n",
      "         2.8346e-01,  1.1554e+00,  2.7040e-01, -1.4812e+00,  5.2909e-01,\n",
      "         2.3175e-02,  6.8967e-02, -1.4822e+00, -2.0547e-02,  4.0742e-01,\n",
      "        -1.5539e+00,  1.0416e-02,  1.2138e-02, -3.8501e-01,  1.6805e+00,\n",
      "         8.4092e-01,  2.7533e-02,  3.3488e-01, -1.7148e+00, -1.6663e-01,\n",
      "         8.4041e-01,  8.4967e-01,  6.1599e-01,  2.0856e+00,  1.3566e-01,\n",
      "         5.7435e-01,  4.3997e-01,  8.9767e-01,  6.2209e-01,  1.3824e+00,\n",
      "         1.1779e+00, -1.4041e+00,  6.5252e-01,  1.2490e-03, -5.6114e-01,\n",
      "         2.9251e+00, -3.1274e-01, -3.3313e-01, -9.8542e-02,  1.8858e+00,\n",
      "        -4.1546e-01, -7.5793e-01,  4.7334e-01,  1.7908e+00,  1.1836e+00,\n",
      "        -8.1993e-01,  1.4741e+00, -1.0733e+00, -2.1084e-01,  1.3253e-01,\n",
      "         1.0511e+00,  1.6024e+00,  1.2599e+00, -5.6212e-01,  1.6049e+00,\n",
      "        -6.4853e-01,  7.7913e-01,  1.3219e+00, -2.0508e+00, -1.5185e+00,\n",
      "         1.7457e+00, -9.8392e-01, -5.1788e-01, -1.1643e+00, -3.1677e-02,\n",
      "         7.9083e-01, -1.1113e+00, -6.7988e-01,  4.0368e-01,  1.6329e+00,\n",
      "        -1.5678e-01, -3.5682e-01,  7.6504e-01, -7.2362e-02, -4.0409e-01,\n",
      "        -1.3091e+00, -1.9171e+00, -8.8454e-01, -6.9791e-01, -4.8949e-02,\n",
      "        -1.2364e+00, -5.8972e-01,  5.3023e-01, -5.4051e-01,  4.8836e-01,\n",
      "         1.0158e+00, -2.9912e-01, -1.1335e+00, -1.4569e-02,  1.5716e+00,\n",
      "        -1.0888e+00,  1.9649e-01,  6.1375e-01, -3.7111e-01,  6.0801e-01,\n",
      "        -1.4278e-01,  8.9581e-01, -1.3674e+00,  4.2151e-01,  4.8915e-01,\n",
      "         6.9244e-01,  4.9356e-01, -3.1384e-01, -6.4025e-02,  8.9959e-02,\n",
      "        -9.9882e-01,  1.4564e+00,  1.1139e-01, -2.6828e+00,  2.0765e-01,\n",
      "        -4.2546e-01,  2.0103e-01,  1.1026e+00,  1.8033e-01, -1.7265e+00,\n",
      "         2.7187e-01,  2.7921e-01, -1.4234e+00,  4.8271e-01, -1.0663e+00,\n",
      "        -7.7872e-01, -9.4414e-01,  1.0043e+00, -4.3148e-01,  1.1852e-01,\n",
      "        -9.4428e-01,  1.2928e+00,  6.4811e-02,  5.5117e-01,  3.1600e-01,\n",
      "         1.5238e-02, -1.7392e+00, -6.2959e-01,  1.5711e+00,  5.5393e-01,\n",
      "        -6.8733e-01,  8.8314e-01,  1.4884e-01, -1.7547e-01, -3.4808e-01,\n",
      "         6.8426e-01,  8.3109e-01, -2.9050e-01, -6.5980e-01, -1.5511e+00,\n",
      "         9.5983e-01,  4.4307e-01, -9.8224e-01, -8.9855e-01,  1.3564e+00,\n",
      "        -5.7587e-01, -3.9331e-01, -2.0686e-01, -2.0225e+00,  4.7464e-01,\n",
      "        -1.1344e+00, -1.4254e+00,  8.8874e-01,  4.0018e-02,  5.8922e-01,\n",
      "        -3.9605e-01,  1.0123e-01, -5.0925e-01, -1.1579e+00, -1.7957e-01,\n",
      "         1.8418e-01,  5.1194e-02, -2.1907e+00, -2.9630e-01, -9.7842e-02,\n",
      "        -5.7971e-01,  7.2162e-01,  1.6668e+00, -4.3489e-01, -4.2843e-01,\n",
      "         1.4506e+00,  1.2357e+00,  7.0838e-01,  2.6942e+00,  5.7159e-01,\n",
      "        -3.5205e-01,  2.9561e-01, -1.2290e+00,  2.4692e-01, -8.7250e-01,\n",
      "        -1.6024e-01, -3.3940e-01,  1.9052e+00, -4.7042e-01, -5.6858e-01,\n",
      "        -1.4414e+00, -3.0130e-01]), end embedding: tensor([-9.8986e-01, -1.8046e-01,  5.4521e-01,  7.9054e-01,  3.0929e-01,\n",
      "         1.4342e+00,  6.1102e-01,  8.8463e-01,  8.7495e-01,  1.7557e+00,\n",
      "         8.8940e-01, -3.5024e-01,  1.9800e-01,  2.0143e-01,  5.1783e-01,\n",
      "         8.5017e-01, -1.5833e+00, -1.0519e+00,  1.3370e+00,  2.0458e-01,\n",
      "         3.0766e-01, -6.7757e-01, -7.4541e-01, -1.2959e+00,  5.6616e-01,\n",
      "         1.9009e+00, -1.4511e+00,  5.0723e-01,  1.2210e-01, -1.3869e+00,\n",
      "         1.9081e+00,  1.8194e-01, -3.7724e-02, -1.1464e+00,  1.9453e-01,\n",
      "         3.9629e-01,  1.2576e+00,  9.4360e-01,  2.9288e-01, -7.9000e-01,\n",
      "        -6.6180e-01,  2.8134e-01, -5.3730e-01,  1.2863e+00,  1.4980e-01,\n",
      "        -6.2491e-01, -4.5890e-01,  7.9975e-01,  1.0988e+00,  9.0893e-01,\n",
      "        -4.1694e-01,  2.5493e-01,  1.2425e+00, -1.6249e+00,  1.5574e-01,\n",
      "        -1.1252e-01,  1.0331e+00,  1.0807e+00, -2.7507e-01, -1.2897e-01,\n",
      "        -1.2066e+00,  3.2826e-01, -6.6398e-01,  1.5853e+00, -1.8367e-01,\n",
      "         1.4892e+00, -2.0354e+00,  3.9076e-01, -6.7785e-01,  1.8159e-01,\n",
      "        -9.1253e-01, -1.3537e-01,  9.7132e-01,  1.3227e+00,  5.2622e-01,\n",
      "        -1.5731e+00,  1.2469e+00,  2.0948e+00,  4.8361e-02, -1.4976e-01,\n",
      "         7.7358e-01,  5.5731e-01,  1.5268e+00, -4.0217e-01, -3.5570e-01,\n",
      "        -2.6978e-01, -2.4251e+00,  6.4631e-01, -2.1033e-01,  1.5166e+00,\n",
      "        -8.4601e-01, -6.6744e-01, -2.8562e-02,  1.7073e-01, -1.0999e-03,\n",
      "        -1.5655e-03,  8.2208e-01, -9.9911e-01,  3.7652e-01, -9.1090e-01,\n",
      "        -7.8976e-01, -6.1060e-01, -1.1599e+00, -8.2837e-01, -6.4355e-02,\n",
      "        -8.7997e-01, -5.6471e-01, -9.1516e-01, -8.2619e-01,  4.0023e-01,\n",
      "        -1.2417e+00, -8.5801e-01,  1.0589e+00, -2.1761e-01,  2.5568e-01,\n",
      "         5.8360e-01,  1.4469e+00, -5.6708e-01,  1.3116e+00,  1.2085e-02,\n",
      "        -5.8275e-01,  1.5718e+00,  6.2001e-01,  1.7634e+00,  3.9923e-01,\n",
      "        -6.3764e-01, -1.3547e-01,  4.5599e-01,  4.2970e-01,  1.5051e+00,\n",
      "        -3.1835e-01,  7.0843e-01,  2.7296e-01,  7.8147e-02,  1.5636e-01,\n",
      "        -1.5046e+00, -3.2629e-01,  4.3886e-01, -1.9106e-01, -8.9949e-01,\n",
      "        -4.7299e-01, -8.1979e-02, -8.6577e-01, -7.2858e-01,  6.3750e-01,\n",
      "        -6.2956e-01, -8.7120e-01, -9.1281e-01,  5.0525e-01, -9.6068e-01,\n",
      "         6.9778e-01, -3.9654e-01, -9.0381e-02, -6.0389e-01, -1.0797e+00,\n",
      "         1.8438e-01, -7.5837e-01,  1.3279e+00, -2.2019e-01,  1.6914e+00,\n",
      "         5.3764e-01, -9.0603e-01,  1.0307e+00,  6.4060e-02,  1.0488e+00,\n",
      "        -1.7081e+00,  2.6472e-01,  3.4861e-01,  1.6942e-02, -6.2993e-01,\n",
      "         1.2753e+00,  1.2548e+00, -2.7071e-01,  9.0442e-01, -2.2714e+00,\n",
      "        -3.2403e-01,  3.0155e-01,  3.2093e-01, -4.7863e-01, -3.0350e-02,\n",
      "        -8.7040e-01,  1.0893e+00,  1.3883e+00,  1.1400e+00,  7.6975e-01,\n",
      "         6.4702e-01, -6.2688e-01, -1.5452e+00,  6.1429e-01, -1.0327e-01,\n",
      "         2.6480e+00, -1.2972e+00,  1.8746e-01,  2.3466e+00, -3.7419e-01,\n",
      "        -1.1872e+00,  4.0909e-01,  4.0376e-01, -9.8173e-01,  8.9514e-01,\n",
      "        -1.4095e+00, -5.9984e-01, -7.9057e-01,  1.4128e+00,  2.4606e-01,\n",
      "         1.3927e+00, -1.0786e+00,  1.6454e+00,  1.1125e+00,  2.8200e-01,\n",
      "        -6.2562e-01, -1.7236e+00, -2.0923e-01, -3.1247e-01, -6.3965e-01,\n",
      "         4.3256e-01,  7.6671e-02,  1.4702e-01,  2.9542e-01, -4.1828e-01,\n",
      "        -3.9475e-01, -1.0607e+00,  1.9776e-01, -1.3466e+00, -5.0508e-02,\n",
      "        -4.9135e-01,  1.0309e-01,  1.5619e+00,  5.4126e-01, -1.7342e+00,\n",
      "        -6.1830e-01, -2.1211e+00,  5.1592e-01,  4.0028e-02, -6.8762e-02,\n",
      "         1.5943e-01, -1.4475e+00, -9.5222e-01,  4.2511e-01,  3.0836e-01,\n",
      "        -1.3491e+00, -6.3112e-01,  1.5669e+00, -4.1462e-01, -2.0730e+00,\n",
      "        -7.4333e-02, -1.4274e-01, -2.6556e-01,  7.0127e-01,  3.1720e-01,\n",
      "        -1.1975e+00, -4.5552e-01, -1.0137e+00, -1.1097e+00,  7.1652e-01,\n",
      "        -1.2610e+00, -4.1677e-01, -6.6667e-01,  7.4375e-01,  8.2091e-01,\n",
      "         3.2985e-01, -9.6264e-01, -2.4895e-01,  1.7645e+00, -4.6028e-01,\n",
      "        -9.5241e-03,  1.5339e-01, -6.2931e-01,  2.2281e+00,  1.2678e+00,\n",
      "        -2.7558e-01, -1.2878e+00,  7.8929e-01,  1.0532e+00, -1.6618e+00,\n",
      "         1.3168e+00, -1.1554e+00,  5.3732e-01, -1.9226e+00, -6.4095e-01,\n",
      "        -8.6654e-01,  3.2195e-01, -4.4672e-01,  9.3896e-01,  1.2257e-01,\n",
      "        -6.3405e-01, -4.8081e-01,  7.3621e-01,  2.3152e-01, -1.1860e+00,\n",
      "        -9.7367e-01,  1.8457e-01,  1.9303e-01, -1.4835e+00,  6.8850e-01,\n",
      "         8.5529e-01,  1.9714e-01,  1.3331e+00,  2.6684e-01, -8.2664e-01,\n",
      "        -1.8086e+00, -3.9728e-01,  1.4149e+00, -7.7333e-01,  8.2466e-01,\n",
      "        -9.4964e-01,  6.8218e-01, -3.8262e-01,  6.2778e-01, -1.0678e+00,\n",
      "         1.3990e-01, -4.7095e-01, -8.3105e-01,  7.4161e-01, -2.0403e+00,\n",
      "        -1.2471e+00,  5.4031e-01, -9.9935e-01,  1.4378e+00, -2.1267e+00,\n",
      "        -5.1058e-01,  1.5957e+00, -1.6405e+00, -6.3529e-01,  7.4637e-01,\n",
      "        -6.2634e-01, -1.0367e+00, -6.9674e-01, -3.1169e-01,  2.3229e-01,\n",
      "         5.8107e-01, -3.5936e-01,  2.5855e-01,  4.3172e-01, -7.8796e-01,\n",
      "        -2.4968e+00, -1.2575e+00, -2.2388e-01,  3.2516e-01,  8.9945e-01,\n",
      "         2.2608e-01,  8.3859e-01, -9.0043e-01,  1.4450e+00, -1.8264e-01,\n",
      "         2.2926e+00, -6.1515e-01,  5.8324e-01, -8.5470e-01,  9.6077e-01,\n",
      "         1.5726e-01, -3.4879e-02,  1.1338e-01, -3.3124e-01, -1.0896e-01,\n",
      "         1.1141e-01, -2.5034e-01,  7.5621e-01,  2.4888e-01,  7.7201e-01,\n",
      "        -1.1491e-01,  1.2109e+00,  3.2538e-01, -8.3059e-01, -1.3309e+00,\n",
      "        -1.4287e+00,  8.5633e-01, -2.9140e-02, -9.9648e-01,  1.4776e-02,\n",
      "         4.5106e-01, -2.0755e+00,  3.4201e-01,  4.9234e-01, -1.1095e-01,\n",
      "        -4.3966e-01, -3.2249e-01,  8.8142e-01, -1.3527e+00, -3.8373e-01,\n",
      "        -1.8939e+00,  2.2753e+00, -1.1222e-01, -2.6822e-01, -7.4008e-01,\n",
      "         1.8624e+00, -5.8345e-01,  2.8232e-01, -1.6919e+00, -1.4711e+00,\n",
      "         1.6420e-01, -9.2272e-01, -1.6220e-01,  1.2279e+00,  4.5097e-02,\n",
      "        -5.7021e-01, -1.5043e+00,  4.2501e-01,  5.1453e-01,  3.1777e-01,\n",
      "        -1.7832e+00,  5.1557e-02,  1.5332e-01,  9.8458e-01,  1.4886e+00,\n",
      "        -6.0698e-01,  8.5199e-01,  1.5943e-01,  1.4919e-01,  9.4473e-01,\n",
      "         1.2702e+00,  1.1382e+00, -2.0903e+00,  7.4874e-01,  5.0818e-01,\n",
      "        -1.4309e+00,  7.1948e-01, -5.5566e-01, -9.4216e-01, -1.9828e+00,\n",
      "        -1.2809e-01, -1.5535e+00,  3.0889e-01, -1.2722e+00, -9.5856e-01,\n",
      "         1.1230e+00, -5.2518e-02,  1.0242e+00,  9.4004e-01, -1.2286e+00,\n",
      "        -3.6235e-01, -3.0560e-01, -5.5872e-01, -1.0023e+00,  7.7375e-01,\n",
      "         1.2401e-01, -4.8133e-01, -1.7903e-01,  5.7483e-01, -2.7723e-01,\n",
      "        -3.7525e-01,  2.3712e-01,  1.0492e-01,  1.3329e-01,  4.1647e-01,\n",
      "         5.3793e-01,  1.1313e+00,  4.5784e-01,  1.7339e+00, -1.7568e-01,\n",
      "        -1.6905e-01, -3.4362e-02,  1.3627e+00, -7.3377e-01,  7.1669e-01,\n",
      "         2.3517e-01,  2.2355e+00, -2.0672e+00,  7.2219e-01, -5.2361e-02,\n",
      "        -4.6260e-02, -8.4782e-01, -1.1286e+00, -9.0396e-01, -1.3652e+00,\n",
      "         7.7529e-02,  8.0761e-02, -4.9308e-02,  1.3795e+00,  1.2476e+00,\n",
      "         1.0303e+00,  2.3895e+00, -9.1600e-01, -1.3609e+00, -3.1732e-01,\n",
      "        -1.4618e+00,  9.7295e-01, -5.3667e-01,  8.0061e-01, -9.4056e-01,\n",
      "         9.3383e-01, -3.3780e-02,  2.9835e-01,  6.1802e-01,  3.8083e-01,\n",
      "        -1.6730e+00,  9.6721e-01, -8.9698e-01, -1.3906e-01,  1.3828e+00,\n",
      "         2.2738e+00,  1.4648e-01,  2.2567e-02,  6.6828e-01, -1.4315e-01,\n",
      "        -8.4800e-01,  1.0410e+00,  7.5086e-01, -2.6166e-01,  1.3139e+00,\n",
      "         1.1378e+00,  2.1063e+00,  1.4490e-01, -6.7740e-01, -4.5959e-01,\n",
      "        -4.2959e-01, -2.0851e-02, -1.8301e-01, -7.6961e-02, -1.9468e+00,\n",
      "         9.5633e-01,  3.4709e-01])\n",
      "span length: 3\n",
      "span position embedding: tensor([[ 0.2646, -0.2359,  0.4529,  ..., -0.5603,  0.3245,  0.3620],\n",
      "        [-0.0196, -0.8800,  1.0720,  ...,  1.2667, -0.2152, -0.3769],\n",
      "        [-0.7504,  0.3307,  1.1889,  ...,  0.4162, -0.3113,  0.6106]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "span position embedding shape: torch.Size([3, 512])\n",
      "p_h: tensor([ 2.6463e-01, -2.3591e-01,  4.5285e-01, -1.1136e-01,  3.0407e-01,\n",
      "        -2.3966e-01, -2.7644e-02,  1.2563e+00,  3.6182e-01,  1.9652e-01,\n",
      "        -8.6246e-01, -7.1119e-01, -1.1506e+00, -8.6195e-01,  1.2013e+00,\n",
      "         1.3645e+00, -4.7164e-01, -1.0417e-02,  5.2249e-01,  1.8408e-01,\n",
      "        -1.4745e-01,  1.5400e+00, -1.0897e+00,  1.2691e+00, -1.9417e+00,\n",
      "        -2.5694e-01,  5.3591e-01,  4.6418e-01, -1.1935e+00,  1.5731e+00,\n",
      "         4.0055e-01,  1.6647e+00,  3.1474e-01, -5.1079e-01, -4.6470e-01,\n",
      "        -1.6623e+00, -1.9396e-02, -1.8199e+00, -4.0583e-01,  8.2175e-02,\n",
      "        -5.3666e-02, -6.3857e-01,  2.9397e-01,  5.2579e-01, -2.1096e+00,\n",
      "         1.7281e+00,  3.8924e-01,  3.7421e-01,  8.1201e-01,  6.8693e-01,\n",
      "        -1.9785e+00,  2.4820e-01,  6.1537e-01, -2.1311e+00,  1.0837e+00,\n",
      "         5.3762e-01,  4.5211e-01,  1.4208e+00,  1.8105e+00,  9.5980e-01,\n",
      "         6.4874e-01,  1.0742e+00,  1.9713e-01, -6.1546e-01, -3.3916e-01,\n",
      "        -3.3302e-02, -1.1120e+00,  1.2290e+00,  3.2036e-01,  4.7312e-01,\n",
      "        -1.0821e-01, -1.0119e+00,  7.7355e-01, -7.3499e-01, -1.4620e+00,\n",
      "         6.8714e-01, -1.4982e+00,  3.4491e-01, -1.1672e+00,  4.2549e-01,\n",
      "         1.1212e+00, -1.4065e+00,  2.5087e-01,  3.4171e-01,  3.1139e-01,\n",
      "         8.3637e-01,  1.2320e+00,  1.0655e-01,  8.9789e-01,  2.3202e-01,\n",
      "        -1.8274e+00,  3.1027e-01,  2.1902e-01, -2.4660e-01,  9.7873e-01,\n",
      "         3.6632e-01,  5.2638e-01,  4.3381e-01, -5.1404e-02,  9.4305e-02,\n",
      "         5.2549e-01, -5.7886e-01,  9.5275e-01, -9.3557e-01,  4.2693e-01,\n",
      "         1.2856e+00,  1.7819e-01,  1.1278e+00, -6.1495e-01,  1.0691e-01,\n",
      "         1.4019e+00, -1.9541e-01, -2.7272e-01, -5.9999e-01,  1.3753e+00,\n",
      "         4.8390e-01, -5.9446e-01,  6.2681e-01,  1.0675e-01,  2.6720e+00,\n",
      "        -4.6258e-01,  1.1697e+00,  1.0102e-01,  5.9059e-01, -1.1562e-01,\n",
      "         1.8833e+00, -1.9221e+00,  8.4052e-01,  1.2141e+00, -1.5262e+00,\n",
      "         1.3867e+00,  5.7718e-01,  7.7591e-01,  1.4728e+00,  2.4874e+00,\n",
      "        -5.0059e-01,  9.5103e-03,  3.5364e-01,  1.4312e+00, -4.0655e-01,\n",
      "         1.3028e+00, -2.3050e-01,  4.9509e-01, -1.8871e-03,  6.7407e-01,\n",
      "         1.6877e+00,  7.6270e-01, -1.0258e+00, -1.0028e+00, -7.8825e-01,\n",
      "         2.5775e-01, -7.2426e-01,  2.5744e-03, -2.3219e+00,  6.9216e-01,\n",
      "         2.6199e-01, -6.8344e-01,  1.6513e+00,  8.0119e-01, -9.5820e-01,\n",
      "         1.4848e-01,  4.2119e-01,  5.4669e-01, -5.4224e-01,  1.3896e+00,\n",
      "         5.5137e-01, -2.9887e+00, -8.5112e-01, -8.3678e-01,  4.3097e-01,\n",
      "        -8.2797e-01,  1.8303e-01, -8.1399e-01,  3.0334e-01,  4.3765e-01,\n",
      "        -1.6117e+00,  4.6604e-01, -1.1909e+00, -1.7815e-01,  4.5396e-01,\n",
      "         1.3874e+00,  1.3422e+00, -7.1142e-02, -5.3129e-01,  4.9093e-01,\n",
      "         8.8818e-01,  6.9741e-01, -4.1026e-01, -4.8009e-01,  7.1111e-01,\n",
      "        -3.7213e-01, -4.3906e-01,  1.4767e+00,  7.1079e-02, -1.7537e-01,\n",
      "        -1.1809e+00,  5.6096e-01, -6.4618e-01,  1.1893e+00,  1.5120e+00,\n",
      "         1.3990e+00, -6.8395e-01,  1.5880e-01, -5.5990e-01, -2.6268e-01,\n",
      "         5.4497e-01, -1.2274e+00,  2.7820e-01, -3.6112e-01,  9.7976e-01,\n",
      "         2.9502e-01,  5.4370e-01,  8.3105e-01,  1.8538e+00, -5.3877e-01,\n",
      "        -9.5267e-01, -9.1673e-01,  1.2531e-03, -2.0213e+00,  9.8051e-01,\n",
      "        -8.8374e-01, -4.2150e-02, -1.6528e+00,  1.9307e-01,  1.5692e+00,\n",
      "        -1.4780e+00, -9.2722e-01,  6.9250e-01, -1.8756e+00,  5.8865e-01,\n",
      "         4.9594e-01,  1.3061e+00, -7.3392e-01,  7.4737e-01,  5.5305e-01,\n",
      "        -1.4458e+00,  6.7631e-01, -2.8349e-01, -4.1311e-02,  9.9215e-01,\n",
      "        -7.9370e-01, -1.3216e+00, -3.7143e-01, -1.9428e-01,  1.7150e+00,\n",
      "        -8.5702e-01,  7.9772e-01,  8.0723e-01,  5.9285e-01, -1.7337e+00,\n",
      "        -3.6545e-01, -3.0930e-02,  9.5934e-02,  7.5442e-01,  2.2453e+00,\n",
      "         6.7726e-01, -1.8739e+00,  3.4552e-01,  1.1640e+00, -3.9320e-01,\n",
      "         5.5008e-01, -6.4734e-01,  2.0954e-01, -1.1305e+00, -7.5992e-01,\n",
      "         8.4470e-01,  1.9466e+00, -1.0329e+00,  1.2538e+00, -1.1546e-01,\n",
      "         1.4509e-01,  1.6514e+00, -1.4655e+00, -7.7295e-01,  1.8134e-01,\n",
      "        -1.8199e-01, -2.2637e-01, -1.4556e+00,  4.7327e-01,  5.7220e-01,\n",
      "         1.1069e+00,  5.3194e-01, -1.1256e+00, -3.2274e+00,  6.3759e-01,\n",
      "         4.2993e-03,  1.2920e-01, -3.1513e-03,  8.9170e-01,  5.2861e-01,\n",
      "        -2.7012e-01, -9.0175e-01, -1.6887e+00, -9.3186e-01,  3.1375e-01,\n",
      "        -1.5741e-01, -1.2657e+00, -2.7680e-03, -6.1508e-01,  1.6279e+00,\n",
      "         1.0891e-01, -1.2797e-01, -1.7622e+00, -1.5778e+00, -4.4926e-01,\n",
      "        -2.8947e-01, -2.0997e-01, -1.2714e+00, -3.0723e-01, -1.7475e+00,\n",
      "        -4.5016e-01, -2.0889e+00, -5.9639e-02, -1.2555e-01,  2.8605e-01,\n",
      "        -1.1658e+00,  1.7329e-02, -1.2733e+00,  6.8152e-01, -7.8875e-01,\n",
      "        -3.6547e-01, -2.8417e-01, -7.3583e-01, -6.6815e-01, -2.2105e-01,\n",
      "        -2.5366e-01, -6.1688e-01,  1.3577e+00, -4.7580e-03, -4.3801e-01,\n",
      "         1.0144e+00,  9.6206e-02,  1.1831e+00, -1.0204e+00, -7.2906e-01,\n",
      "         1.1042e+00,  1.0556e+00, -3.3137e-01, -5.8628e-02,  1.6092e+00,\n",
      "         6.9107e-01,  9.4272e-01, -4.0911e-01,  4.8866e-01, -9.8013e-01,\n",
      "        -5.3689e-01,  1.5416e-01, -4.8419e-01, -1.2030e+00, -1.8621e-01,\n",
      "         1.4200e+00, -5.6757e-01, -1.2296e+00, -8.0300e-01,  8.2033e-01,\n",
      "         9.9433e-01,  3.8412e-01, -2.9066e-01,  1.2961e+00, -5.4361e-01,\n",
      "        -1.3810e-01,  2.6702e-01,  3.3126e-01, -3.1704e-01, -9.3242e-01,\n",
      "         3.7303e-01, -3.5497e-01, -6.0568e-01,  6.2027e-01,  2.3453e-01,\n",
      "        -4.7209e-01,  3.3481e-02,  2.1820e-02, -5.8500e-01, -5.3081e-01,\n",
      "        -6.4882e-01,  2.2216e+00, -7.2217e-01, -2.9424e-01, -1.1246e+00,\n",
      "        -9.9307e-01, -8.4144e-01, -1.7093e+00,  7.5401e-01,  2.0645e-01,\n",
      "        -4.3273e-01, -1.7653e+00, -2.1502e-01,  4.2585e-01, -6.9993e-01,\n",
      "        -1.1024e+00,  9.1361e-01, -1.4485e-01, -1.9265e-01, -1.3256e+00,\n",
      "        -2.3604e-02, -1.9355e+00, -1.0227e+00,  1.1890e+00,  5.9773e-01,\n",
      "        -8.6292e-01, -3.0950e-03, -8.2854e-01,  5.9784e-01, -6.1528e-01,\n",
      "        -1.2698e+00,  5.7545e-01, -8.4002e-01,  1.3896e-01, -9.3209e-02,\n",
      "         7.3866e-01,  7.1812e-01, -6.1141e-01, -3.4375e-02, -1.0954e+00,\n",
      "         1.8022e-01,  3.2163e-01,  7.7503e-02, -1.0133e+00,  1.1984e+00,\n",
      "         9.1484e-01, -4.9774e-01,  2.1523e+00, -1.2008e-01,  3.3075e-02,\n",
      "        -4.0801e-01,  9.1579e-01, -6.9246e-01,  1.2818e+00, -1.7857e+00,\n",
      "         1.8785e+00,  7.0748e-02,  1.3929e+00,  2.0655e-01, -1.2619e+00,\n",
      "        -2.3901e-01,  1.2071e+00,  1.6173e+00, -1.3642e+00,  2.3291e+00,\n",
      "        -6.8836e-01,  8.9147e-01,  1.5207e+00, -1.8084e-01, -1.9412e-01,\n",
      "         7.5915e-01, -1.8645e+00,  5.3172e-01, -8.7955e-01, -2.4235e+00,\n",
      "        -1.0345e+00, -5.3043e-01, -1.7635e+00,  4.9432e-01, -1.3330e+00,\n",
      "         1.0709e+00,  9.4012e-02,  6.9564e-02, -5.0142e-01,  4.6696e-01,\n",
      "        -9.9967e-01,  9.0375e-01,  5.6307e-01, -1.6594e+00, -1.1686e-01,\n",
      "         2.4648e+00,  1.8703e+00,  1.4332e+00,  7.1619e-01,  2.5616e+00,\n",
      "        -2.2084e+00,  1.5308e+00, -1.2692e+00,  1.3647e-01,  1.0541e+00,\n",
      "         3.5369e-01,  1.0998e+00, -1.7216e-01,  1.3324e+00,  4.7375e-01,\n",
      "        -1.0231e+00,  7.9570e-01,  1.3606e+00,  2.0566e-02,  8.9172e-01,\n",
      "        -1.8407e+00,  1.8103e-01,  8.0128e-01,  9.9860e-01,  7.4569e-02,\n",
      "        -6.2979e-01, -1.1183e+00,  7.5391e-01,  2.5534e-01, -1.0144e+00,\n",
      "        -4.8885e-01, -1.3235e-01, -5.8060e-01,  5.4132e-02, -1.5560e+00,\n",
      "        -2.2478e+00,  9.4176e-01, -1.2558e+00,  4.1022e-01, -8.7279e-01,\n",
      "         8.9475e-02,  5.2558e-01, -1.1772e+00, -9.8584e-01, -5.6031e-01,\n",
      "         3.2450e-01,  3.6195e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.9598e-02, -8.8004e-01,  1.0720e+00, -2.7167e-01, -1.1181e-01,\n",
      "         1.2305e+00, -7.0031e-01, -4.4509e-01, -1.0202e+00,  1.7274e+00,\n",
      "         2.6604e-01, -2.7644e+00, -2.9702e-01,  7.5236e-01, -5.5668e-01,\n",
      "        -5.4757e-01,  1.4329e+00,  3.3933e-01, -2.2905e+00, -6.3927e-02,\n",
      "        -3.9277e-01, -1.3286e+00, -1.0442e+00,  6.3118e-01, -3.9864e-01,\n",
      "         1.1672e+00,  4.9961e-01, -2.4401e+00,  2.0224e+00,  1.4115e-01,\n",
      "         2.9880e-01, -1.7060e-01, -1.0577e+00,  7.1500e-01,  2.9370e-01,\n",
      "        -4.2851e-02, -3.0085e-01, -1.7421e-03, -4.0230e-01,  5.1137e-01,\n",
      "         7.4943e-01, -1.8208e-01,  2.6125e-01, -5.7877e-01,  2.7831e+00,\n",
      "         2.1889e+00, -1.2854e+00,  1.0939e+00,  2.9090e+00, -1.5365e+00,\n",
      "        -1.7057e+00,  1.0591e+00,  2.0244e+00,  2.2355e+00, -1.9716e+00,\n",
      "         1.3339e+00, -1.1843e+00, -1.5504e+00,  3.8147e-01, -1.5133e-01,\n",
      "         2.9308e-01,  9.4728e-01,  5.1063e-01, -9.4425e-01,  4.7430e-01,\n",
      "         3.3420e-01,  4.3306e-01, -1.4448e+00,  1.1767e-01,  2.6016e+00,\n",
      "        -1.0885e+00,  7.2074e-01, -8.0917e-01,  6.9210e-01, -5.1269e-01,\n",
      "         5.4817e-01, -3.4270e-02,  7.2508e-01,  4.0123e-01,  6.3323e-01,\n",
      "         1.3014e+00, -2.5752e-01, -3.7336e-01,  2.4239e-01, -7.1877e-01,\n",
      "        -1.3336e-01,  8.0229e-01,  1.1414e+00,  3.2048e-01, -1.1728e+00,\n",
      "         5.7086e-01, -1.9970e-01, -9.0181e-01, -7.4187e-01, -1.1517e+00,\n",
      "        -4.8143e-01,  3.5825e-02,  8.8615e-01, -8.7241e-01,  7.4572e-01,\n",
      "        -1.0059e+00, -1.2884e+00, -1.4603e+00, -8.2570e-01, -1.4340e-01,\n",
      "        -6.6732e-01, -5.6294e-01,  1.2165e+00,  1.0110e+00, -2.2715e+00,\n",
      "         5.6288e-01, -2.4479e-01,  1.4545e+00,  4.1549e-01, -1.3575e+00,\n",
      "        -7.9776e-02,  1.3199e+00,  5.7921e-01, -7.9095e-01,  9.1039e-01,\n",
      "         2.1433e+00, -1.6521e+00, -1.1074e+00, -5.2481e-01, -2.3083e-01,\n",
      "         1.4427e+00,  6.8813e-01,  9.2377e-01, -4.3607e-01, -6.7831e-01,\n",
      "         1.6607e+00, -6.0901e-01, -1.2238e+00, -1.2792e+00,  7.7615e-01,\n",
      "         1.7335e+00, -3.0826e-01, -1.6324e+00, -2.2841e-02,  7.7872e-01,\n",
      "        -2.3813e-01,  1.7590e+00, -2.6300e+00, -2.2589e+00, -5.7844e-01,\n",
      "        -1.0014e+00, -4.4668e-01, -1.0133e+00,  2.3634e-01, -5.3267e-01,\n",
      "        -9.9985e-01, -2.1989e+00, -3.7624e-01,  6.5364e-01,  7.5254e-01,\n",
      "        -1.3376e+00,  9.7770e-01,  1.1336e+00,  4.7673e-01,  2.9082e-01,\n",
      "        -1.3255e-01,  1.1891e+00, -1.3592e+00,  1.4276e+00,  1.0099e+00,\n",
      "        -2.0686e-01,  4.7024e-01,  6.6699e-01, -1.2182e+00,  4.1511e-01,\n",
      "         3.4016e-01, -1.3129e+00,  6.7744e-01, -9.9545e-01, -1.2289e+00,\n",
      "         1.6814e+00,  1.7367e-01,  4.4566e-01, -3.4744e-01,  7.7216e-01,\n",
      "        -7.9999e-01,  1.0696e+00, -1.9791e+00,  7.5679e-01, -6.2594e-01,\n",
      "         3.3649e-01,  3.2236e-01,  9.3129e-01, -2.6896e-01, -1.1185e+00,\n",
      "         1.2515e+00, -1.4685e-01, -7.1486e-02, -4.7896e-01,  2.8939e-02,\n",
      "        -1.6243e-01,  2.5263e-01,  7.6768e-01,  6.1950e-01, -9.7351e-01,\n",
      "        -8.4524e-01,  1.6915e+00, -7.3563e-01, -3.6067e-02, -1.9589e+00,\n",
      "        -8.4760e-02, -1.7551e-01,  2.5339e+00,  1.2955e+00, -2.5083e+00,\n",
      "         1.0164e+00, -2.3493e+00,  4.3328e-01, -4.7192e-01,  3.8348e-02,\n",
      "         2.2390e-01, -6.9014e-02, -1.4051e-01,  7.9474e-01, -1.8916e-01,\n",
      "         1.6112e-01, -1.3122e+00,  1.0782e+00, -8.3441e-01,  4.5891e-01,\n",
      "        -9.0378e-01,  1.0776e+00,  3.5492e-01,  6.7974e-01,  8.5984e-01,\n",
      "         6.2570e-02,  4.7049e-01,  4.9977e-02, -5.9910e-02,  5.8082e-01,\n",
      "         7.0209e-01,  1.8570e+00,  3.3905e-01, -3.4004e-01,  9.5000e-02,\n",
      "        -7.0462e-01, -1.1546e+00,  2.6067e+00,  2.8814e-01,  9.5239e-01,\n",
      "        -6.3638e-01, -2.4426e-01, -1.0868e+00,  4.2619e-01,  1.0016e-01,\n",
      "        -7.8702e-01, -5.4084e-01, -1.4274e-01, -1.9805e-02, -7.1918e-01,\n",
      "         1.7290e-01, -1.2436e+00,  3.1620e-01, -1.0714e+00,  6.6434e-02,\n",
      "        -4.5941e-01,  7.2912e-02,  6.2007e-01,  5.5581e-01,  1.1954e+00,\n",
      "         2.0939e-01, -5.0785e-01,  2.0959e+00, -8.1876e-02,  4.2700e-01,\n",
      "         5.0943e-01,  1.4900e+00,  4.3161e-01,  1.8884e+00,  6.2704e-01,\n",
      "        -1.4820e+00,  2.1680e-01,  8.0652e-01, -2.0691e-01,  6.6663e-02,\n",
      "        -4.1691e-01,  1.7703e+00,  6.1042e-01,  1.5419e+00, -3.6541e-01,\n",
      "         1.2856e+00, -8.3941e-01, -3.8372e-02,  7.4279e-01, -2.1912e-01,\n",
      "         1.5360e+00,  4.8248e-01,  8.2361e-01,  1.0086e+00, -8.2352e-01,\n",
      "         4.2431e-01,  8.4797e-01, -1.1859e+00, -4.4374e-01,  1.7759e+00,\n",
      "         2.6485e+00, -1.6682e+00,  1.4951e+00,  1.2841e-01,  9.0137e-01,\n",
      "        -5.5399e-01, -5.4908e-01, -1.6300e-01,  5.8974e-02,  7.7423e-01,\n",
      "        -1.1408e+00, -2.3258e+00,  1.7219e+00,  1.4725e+00,  4.4545e-01,\n",
      "         1.3608e-01, -3.4079e-01,  8.4047e-01, -1.5302e+00, -1.3600e+00,\n",
      "        -1.1235e+00, -1.1894e+00, -3.1683e-01, -8.8800e-01, -1.8915e+00,\n",
      "        -2.5639e-01, -2.3428e+00,  4.5652e-01, -4.4602e-01,  5.0303e-01,\n",
      "         7.9082e-01, -5.1529e-01, -7.5383e-01,  1.2808e+00, -1.0749e+00,\n",
      "        -6.3119e-01, -5.7263e-01,  2.3266e-01,  1.6130e+00, -2.6413e-01,\n",
      "        -1.5035e+00,  6.3873e-01,  3.8395e-01, -3.2821e-01, -9.4901e-01,\n",
      "         8.1626e-01,  1.2318e+00, -5.8183e-01,  7.6981e-01,  1.2267e+00,\n",
      "         2.7440e-01,  6.3441e-01, -1.2575e+00, -8.4964e-01, -1.4209e+00,\n",
      "        -2.0525e+00,  8.5586e-01, -2.0060e+00,  5.1493e-01,  4.4926e-02,\n",
      "        -1.1243e+00,  1.6439e+00,  3.8856e-02, -2.6801e-01,  3.7889e-01,\n",
      "        -1.6657e+00,  2.1121e+00,  4.7003e-01,  1.6673e+00,  1.4359e+00,\n",
      "         3.1666e-01, -1.8693e-01,  4.3260e-01, -7.3865e-01, -1.6888e-01,\n",
      "        -8.2745e-01,  4.4106e-01, -9.3589e-01, -6.0546e-01, -1.1373e+00,\n",
      "        -6.7438e-01,  6.9004e-01, -1.2898e+00, -8.5722e-01,  1.2332e+00,\n",
      "        -2.8805e-01, -5.1052e-01,  7.3412e-01,  6.2072e-01, -1.3678e-01,\n",
      "        -1.4201e-01, -7.5883e-03, -2.6767e+00, -7.6234e-01,  8.5236e-01,\n",
      "         5.6856e-02, -7.2773e-01,  1.2267e-01, -9.7834e-01,  5.1376e-01,\n",
      "         3.3411e-01,  1.3300e+00, -4.7372e-01, -1.1496e+00,  1.8684e+00,\n",
      "         7.2719e-01, -6.1977e-02, -1.3151e+00, -6.8870e-01,  8.6271e-01,\n",
      "         3.0699e-01,  5.7380e-01, -9.4069e-02,  4.6136e-01,  8.2800e-01,\n",
      "         3.8674e-01,  1.2559e-01, -4.6637e-01, -6.6718e-01,  7.6186e-01,\n",
      "         5.8211e-01,  1.2183e+00,  1.0905e-01,  3.3896e-01,  1.3243e+00,\n",
      "         2.9844e-01,  1.4861e+00,  4.9099e-01, -1.4104e+00,  1.1438e+00,\n",
      "        -1.6922e+00, -9.0433e-01, -7.5813e-01, -8.7738e-01, -3.2076e-01,\n",
      "        -4.6825e-01, -7.2635e-01,  1.1144e-03, -7.2225e-01, -3.4616e-01,\n",
      "         6.9479e-01,  1.1173e+00,  1.8688e+00,  2.0539e-01, -1.7454e-01,\n",
      "         6.0237e-01, -5.1255e-01, -7.0896e-01,  7.4415e-01,  6.1457e-01,\n",
      "        -1.3599e+00, -1.3151e+00, -9.6092e-01,  2.3501e-01,  4.3561e-01,\n",
      "        -5.8040e-01,  4.6350e-01,  1.0027e+00,  5.3332e-01,  6.2659e-01,\n",
      "         4.7085e-01, -2.4516e+00,  2.2334e-01, -7.2773e-01, -1.5475e-01,\n",
      "        -3.6478e-01, -5.8729e-01, -1.0755e+00,  8.3631e-01,  4.4258e-01,\n",
      "        -4.9116e-01, -1.7064e+00,  6.5128e-01, -1.7775e-01,  5.9177e-01,\n",
      "        -1.7584e+00,  2.9596e-01,  5.9606e-01, -1.0755e+00, -1.2221e+00,\n",
      "         1.5103e+00, -1.7211e+00, -3.5132e-01,  1.9871e+00,  8.4459e-01,\n",
      "         9.5885e-01,  2.2156e-01,  1.2679e+00, -2.6715e-02, -1.1446e-01,\n",
      "        -1.8737e+00, -3.3209e-01, -1.2168e+00, -1.2257e+00,  2.2572e-01,\n",
      "         1.2483e+00, -3.1807e-01,  9.7262e-01,  2.4968e-01,  6.2445e-01,\n",
      "         8.6025e-01,  5.9226e-01, -7.8353e-01, -1.0757e+00,  1.5338e+00,\n",
      "         1.4497e+00,  2.9066e-01,  1.6366e+00, -8.5775e-01,  1.2667e+00,\n",
      "        -2.1525e-01, -3.7695e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-0.7504,  0.3307,  1.1889, -0.1797,  0.4551, -0.2385,  0.3020,  0.3964,\n",
      "        -0.5703, -1.2782, -0.0379, -1.4034,  0.9590,  0.0099,  0.9522,  1.4344,\n",
      "        -1.1014, -1.8471,  0.1693, -0.9546,  1.4319,  0.8903,  0.8522, -1.3764,\n",
      "         0.2885, -0.0727, -1.9786, -1.7993,  0.1210,  0.5786, -0.8996, -0.2015,\n",
      "        -0.2142,  1.3566, -1.0467, -0.2777,  0.9662, -0.9339, -0.8660,  0.5690,\n",
      "        -1.6367, -1.2919, -0.3426, -0.9690,  0.4440, -0.9708,  0.5877, -0.9867,\n",
      "         1.0085,  0.6473,  0.8648,  0.0203, -1.8394,  1.0840,  1.4080,  0.6950,\n",
      "        -0.8276,  0.1367,  1.5239, -0.0234,  1.5090, -0.9798,  0.1744,  0.2268,\n",
      "        -1.1804, -1.1009,  0.1866, -0.2109, -1.2063,  0.4134,  0.6401,  0.8016,\n",
      "        -0.2500,  0.0466, -0.1226,  1.6164,  0.4022, -0.5826, -0.0856,  1.3567,\n",
      "         0.4002, -0.3948,  0.9759,  0.3123,  0.8401, -0.1592,  0.4744,  1.3961,\n",
      "        -0.0657, -0.1925,  0.8939,  0.0873,  1.0628,  1.7551, -0.6340,  0.4578,\n",
      "         0.2988, -0.2587,  0.6627,  1.9613, -1.1302, -0.9525,  0.5244,  0.6685,\n",
      "        -0.7214, -0.2801, -0.5120,  1.4162, -0.5164,  0.8006, -0.6180, -1.2510,\n",
      "        -0.0455, -1.7446,  0.3919,  0.0274, -2.4785,  0.5470, -0.7437, -0.0895,\n",
      "        -0.4452, -0.5428, -0.7256, -0.5121,  0.3895, -0.8705, -1.3791,  0.7412,\n",
      "        -0.4045,  1.1329,  0.5078, -0.6499, -0.9989,  0.3185,  0.8239, -2.3652,\n",
      "         2.0420,  1.1559, -0.2084,  1.9962, -0.9739,  0.9744, -1.1922, -1.8917,\n",
      "         0.9056,  0.1586,  0.7926, -0.6207,  0.8054, -0.1170,  1.2409,  0.6600,\n",
      "         2.1661, -0.1774,  0.1110,  0.4225, -0.0848,  0.3466, -0.7631, -2.1882,\n",
      "         0.2719,  0.1662,  0.2923, -1.0385,  0.4762,  0.7655,  0.4460, -0.2891,\n",
      "        -0.3066, -1.2684,  1.3048, -0.1688, -0.4136,  1.8192, -1.2687,  0.1156,\n",
      "        -0.3577,  0.9496,  0.3266,  0.1149, -1.4874,  1.4921,  0.3631,  0.0513,\n",
      "         0.9077, -0.0278, -0.2975,  0.2053, -0.7905,  1.5896, -1.3326,  1.4535,\n",
      "         1.5136,  0.6979, -0.7753, -0.0797,  0.8933, -1.5865, -2.8705, -0.2598,\n",
      "        -0.5357,  0.9557,  1.5877, -1.3100, -0.8385, -0.4479, -1.5694, -0.5087,\n",
      "         0.9920, -0.0290, -0.4488, -1.1622,  0.7778, -1.0847,  1.1099,  0.3768,\n",
      "        -0.6814,  1.6994,  0.3495,  0.1313, -1.2125, -0.4133,  0.3382, -1.4008,\n",
      "         1.6466,  0.4950, -0.3221,  1.3289,  0.7555,  0.3506, -0.8889, -0.1805,\n",
      "        -0.5240,  0.4309, -0.7121, -0.6457, -0.3073,  0.7066, -1.7207, -2.0986,\n",
      "         0.5175, -0.3444, -0.6635,  0.0468, -1.8558,  0.0919, -0.7158,  0.3148,\n",
      "         1.3764, -0.7770, -0.2787, -0.6062, -0.4592, -0.6404,  1.0975, -1.2084,\n",
      "        -0.0559, -0.7027, -1.0166, -1.8683,  0.3301,  0.7017,  0.4275, -1.1290,\n",
      "         0.1254,  0.9455, -0.4284, -1.2824, -0.2163,  2.0310, -0.5892, -2.6387,\n",
      "         0.2871,  0.9723,  0.8353, -0.0239,  1.5444, -0.7838, -0.6200, -0.2476,\n",
      "        -2.2379,  1.1104, -0.3804,  0.0345,  0.9600, -0.1915,  1.1250,  1.5672,\n",
      "         0.0503, -0.5717,  0.5345, -0.2425,  0.4562, -0.4484, -0.6491,  1.1844,\n",
      "        -1.0267,  1.0339,  0.3380, -0.2015,  0.6605,  0.0422,  0.1583,  1.1028,\n",
      "        -1.3520, -0.3794,  1.2837,  0.6935,  2.4659,  0.0182,  0.6813, -1.8906,\n",
      "         0.5508, -1.3803, -0.5619, -0.5565,  1.9952,  1.2809,  0.3816,  0.3348,\n",
      "         0.7241,  0.2163, -3.2037, -0.0758,  0.0477,  0.9328,  1.1508,  1.6287,\n",
      "        -0.5876, -0.3290, -0.5660,  0.6235,  0.8290,  0.4471,  1.4814, -0.6217,\n",
      "        -1.0007, -0.4594, -1.1678,  0.9717, -1.2264,  1.0469,  0.5557, -0.5625,\n",
      "         0.9440, -0.9814, -0.7207, -0.8293,  0.3572, -0.3558,  0.6082, -0.8350,\n",
      "        -0.1453,  0.9702, -0.2615, -1.0350,  1.1619, -0.9494, -1.1617, -2.2713,\n",
      "        -1.3153,  2.1866, -0.5869,  0.5863,  0.5625,  0.9849, -0.5078, -0.2339,\n",
      "        -1.0275, -0.7601,  0.1333, -0.8738, -0.6843,  1.6700,  1.2572,  0.2745,\n",
      "        -1.6771, -0.1209,  1.0814, -0.3502, -0.8827,  0.3480, -0.2602,  0.6152,\n",
      "         0.1692,  0.6783, -0.6858, -0.1144,  0.1485, -0.9948, -0.1695, -0.6526,\n",
      "         0.4156,  1.9687, -0.5675,  0.2630, -0.6254,  0.7081, -0.9420, -0.8826,\n",
      "        -1.8052,  0.5378,  0.0949, -0.4008,  1.2614,  1.3561, -0.5987, -0.0456,\n",
      "         0.3407,  0.7499,  0.2387, -0.5059, -0.3471, -1.6377, -1.8931, -0.5449,\n",
      "        -0.8162,  0.0195, -2.5477, -0.0890,  1.1402,  2.0917,  1.0522,  1.5690,\n",
      "        -1.3152,  0.0594,  0.6033, -0.8900,  0.8229, -0.7064, -0.4799, -0.1496,\n",
      "         0.1460, -0.6779, -1.1489,  0.7961, -2.4001,  0.4305,  2.0857,  0.4562,\n",
      "        -0.4430, -0.1794, -0.6101, -0.4280,  0.3718,  2.2594, -0.6633, -0.2723,\n",
      "         1.7358, -0.7143, -0.8630, -0.0437, -0.2681, -1.5857,  2.6693,  0.8341,\n",
      "         1.5734,  0.9690, -0.8671,  0.0320, -1.4927,  0.3371, -1.1928,  1.0526,\n",
      "         0.3028,  0.3294,  0.0487,  0.0846,  0.9330,  0.8237, -0.5224, -1.4377,\n",
      "        -2.4455,  0.0306, -1.2102,  0.0402,  0.9468, -0.1233,  1.1659,  0.6326,\n",
      "        -0.2395, -0.4908, -0.0631,  0.6146,  1.2287,  0.9718, -1.3850,  1.0913,\n",
      "        -0.6968, -2.5954,  0.6071,  0.6172,  0.6222,  1.1954, -1.2100, -0.6661,\n",
      "         1.3550,  1.5153, -0.8437, -0.6585, -1.5876,  1.0028,  0.6496, -1.2787,\n",
      "        -1.5123,  0.3077, -2.7209, -0.4437,  2.0181,  0.4162, -0.3113,  0.6106],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "start: 137, end: 148\n",
      "start embedding: tensor([-1.7443e+00, -6.3907e-02, -3.0167e-02, -3.2836e-01, -7.3608e-01,\n",
      "        -6.4470e-01, -1.8913e-01,  2.5115e+00, -2.3432e-01,  1.3946e+00,\n",
      "         1.8161e-01,  7.9627e-01, -8.4531e-01, -4.5129e-01, -9.7228e-02,\n",
      "        -1.0134e-01, -8.0014e-01,  5.7102e-01, -1.4943e-01,  9.1576e-01,\n",
      "        -8.3325e-01,  6.9610e-01,  1.4516e+00, -5.4428e-01, -8.1398e-02,\n",
      "         1.6059e-02, -6.5758e-01,  1.2864e-01,  1.0651e+00,  8.0856e-01,\n",
      "         3.2091e-01,  1.1376e+00,  6.1496e-01,  1.7244e-01,  3.1920e-01,\n",
      "         3.9542e-01, -4.9492e-01, -4.0193e-01, -1.4267e-01, -4.0570e-01,\n",
      "        -6.0638e-01, -6.8782e-01,  5.9159e-01,  6.7655e-01,  1.0687e+00,\n",
      "        -1.0234e+00,  5.0680e-01,  1.2837e+00, -2.0029e-01,  1.3893e+00,\n",
      "         1.5521e+00, -2.4100e-01,  8.4939e-01, -1.0548e+00, -1.8460e-01,\n",
      "         1.9733e-01,  1.9740e+00,  6.5086e-01, -4.5013e-01, -5.6741e-01,\n",
      "         1.9919e-01,  4.1542e-01, -1.7286e+00, -3.0032e-01,  2.9144e-01,\n",
      "         7.6355e-01,  3.8772e-01, -1.0498e+00, -4.7480e-02, -7.8912e-02,\n",
      "         1.4499e+00,  1.0485e+00, -1.9654e+00, -1.3407e+00, -2.4140e-01,\n",
      "        -1.9851e+00, -4.2196e-01,  6.4017e-01,  4.8641e-01, -5.3555e-01,\n",
      "         7.0021e-01, -2.0095e-01,  5.9613e-01,  1.3130e-01, -3.9987e-01,\n",
      "        -8.6122e-01,  1.6513e+00,  8.5432e-01,  3.3853e-01,  1.8241e+00,\n",
      "         1.3777e-01, -5.5136e-01, -4.6325e-01,  3.2445e-02, -5.5964e-01,\n",
      "         1.6885e+00, -1.2398e+00,  1.0196e-01, -2.3214e+00,  6.7145e-02,\n",
      "        -2.2680e-01, -5.4023e-01,  6.1931e-01, -6.1286e-01, -1.7062e-01,\n",
      "         9.7285e-01,  9.9682e-01, -7.9107e-01, -1.1544e+00,  3.9756e-01,\n",
      "        -3.9964e-01, -1.6629e+00,  1.2116e+00, -1.1144e+00,  3.6204e-01,\n",
      "        -6.8831e-01, -1.9874e-01,  9.4270e-01, -8.1534e-01, -5.8619e-02,\n",
      "        -4.4375e-01, -4.1895e-02, -1.5240e+00,  1.4857e+00, -6.1897e-01,\n",
      "        -8.8981e-01,  5.2616e-01,  2.1589e+00,  6.0779e-01,  5.8175e-01,\n",
      "         7.5916e-01,  1.2719e+00,  1.3198e+00,  1.3056e+00,  6.4578e-01,\n",
      "        -1.2278e+00, -8.6670e-01, -3.2811e+00, -1.8584e+00,  7.3487e-01,\n",
      "        -1.1034e+00, -1.7765e-01, -9.1758e-01,  1.0897e-01,  3.8620e-01,\n",
      "        -1.1089e+00,  7.8037e-01,  4.5542e-01,  8.4509e-01, -1.7201e+00,\n",
      "         2.3318e-01, -2.1333e-01, -1.9389e-02, -4.1562e-01,  1.1729e+00,\n",
      "        -9.7175e-01,  1.4845e+00,  1.4674e-01,  7.6112e-01, -1.1746e-01,\n",
      "        -2.5196e-01, -3.9544e+00, -1.1602e+00,  1.5524e+00,  5.0957e-01,\n",
      "         5.6552e-01, -1.2121e-01,  9.6831e-01, -4.7666e-01,  3.7878e-01,\n",
      "        -1.6565e+00,  8.6647e-01, -5.7469e-02,  9.3886e-01,  1.2603e+00,\n",
      "         2.1915e+00,  7.8887e-01, -6.1763e-01,  8.9477e-01, -7.8014e-02,\n",
      "         4.3431e-01,  1.6176e+00,  1.7980e+00,  9.5171e-01,  2.5359e-01,\n",
      "        -7.4826e-01,  1.9528e-01, -6.3142e-01,  1.1042e+00,  1.6785e-01,\n",
      "         1.0880e-01, -6.6211e-01, -2.0342e-01,  1.1230e+00,  2.7705e-01,\n",
      "        -1.8237e-02, -5.4533e-01,  1.1648e+00,  4.5530e-01, -2.8266e-01,\n",
      "        -9.3975e-01, -1.7031e-01, -9.2607e-01,  3.8509e-01,  1.5316e-02,\n",
      "         7.4582e-01, -4.5444e-01, -3.2969e-01, -8.3106e-01,  2.1412e+00,\n",
      "         6.8782e-01,  9.4472e-01,  1.1339e+00, -2.3283e-01,  1.8157e+00,\n",
      "         2.3522e-02, -1.6087e+00, -8.6481e-01,  1.9867e-01,  1.2324e-01,\n",
      "        -1.3807e+00, -1.2577e+00, -5.6710e-01, -7.3636e-01,  1.2297e+00,\n",
      "        -1.0464e-01,  9.7685e-02,  3.7254e-01, -8.8036e-04,  3.9679e-01,\n",
      "         3.3050e-01, -1.5358e-01,  8.5668e-01,  2.1118e-01, -1.3822e+00,\n",
      "         1.6557e+00,  2.4661e-01,  2.4346e+00,  4.1257e-01,  1.1324e+00,\n",
      "        -1.5090e+00, -4.7196e-01,  2.8140e-01,  1.0905e+00,  5.6627e-01,\n",
      "         1.5986e+00,  1.0956e+00,  7.8879e-01,  6.9269e-01, -3.8528e-02,\n",
      "         3.1813e-01, -1.5402e-01,  1.7471e-01,  5.5859e-01, -9.2250e-01,\n",
      "        -4.4692e-01,  7.1193e-01,  8.9530e-01,  3.5015e-01, -8.4095e-01,\n",
      "         7.4135e-01,  2.5670e-01,  7.4926e-02, -1.4339e+00, -4.1362e-01,\n",
      "         8.5187e-01,  1.3974e+00,  4.2385e-01, -1.3671e-01,  3.2040e-02,\n",
      "         2.7465e-01,  2.3707e-01, -7.1487e-01, -1.1993e+00, -2.2591e-02,\n",
      "        -2.1369e-01,  7.8333e-01, -7.2488e-01, -8.5237e-01,  3.9099e-01,\n",
      "         7.9212e-01, -4.7619e-01, -8.7991e-01, -8.0743e-01, -6.5381e-01,\n",
      "         1.3587e+00, -1.5423e+00, -1.4854e+00, -1.3839e-01, -2.5382e+00,\n",
      "        -4.2205e-01,  8.3928e-02,  1.0707e+00,  2.7495e-01,  4.3977e-01,\n",
      "         8.9627e-01,  1.4439e+00,  5.0873e-02,  5.0602e-01,  1.0423e+00,\n",
      "         3.7604e-01, -1.7488e+00, -2.2095e-01,  5.5114e-01,  5.1412e-01,\n",
      "         1.0123e+00,  2.5944e-01,  9.6761e-01, -1.1478e-01, -1.4381e+00,\n",
      "        -7.9574e-01, -1.5290e+00, -2.8385e-01,  8.0880e-01,  5.3163e-01,\n",
      "         1.0705e+00, -4.0684e-02, -4.4681e-02,  9.9161e-02,  6.6867e-01,\n",
      "         1.4762e+00,  1.8748e+00, -7.7215e-02,  1.0114e+00,  7.8063e-01,\n",
      "         1.2023e+00, -1.7122e+00, -2.0489e+00,  5.2770e-01, -3.0446e-01,\n",
      "        -5.6247e-01,  3.8858e-01, -6.5393e-01,  1.3865e+00,  7.2409e-01,\n",
      "         7.5858e-01, -1.2031e+00, -1.2840e+00,  2.6964e-01,  7.1289e-01,\n",
      "        -5.6220e-01,  2.1164e-01, -1.8674e+00,  1.1524e+00, -9.3792e-01,\n",
      "         1.1019e+00,  2.0646e+00,  3.1720e-01, -7.0910e-01, -1.2986e-01,\n",
      "        -5.2107e-01, -3.9573e-01,  4.7066e-01, -1.4771e+00, -3.8919e-02,\n",
      "        -8.8238e-01,  8.6283e-01, -1.0519e+00, -9.1860e-01,  3.6031e-01,\n",
      "        -1.1063e+00, -1.4639e+00,  5.2554e-01,  6.3060e-01, -2.4016e-01,\n",
      "         7.4032e-01, -1.5423e+00, -1.3217e-02, -1.0116e+00, -5.9086e-01,\n",
      "        -7.8196e-02,  1.0227e+00,  1.3497e-01,  1.7322e+00,  3.3533e-01,\n",
      "         1.1410e+00,  4.7158e-01, -1.4027e+00, -6.3698e-01, -7.2276e-01,\n",
      "        -1.2116e+00, -1.4119e+00,  3.0492e-01,  3.3951e-01,  6.9429e-02,\n",
      "        -1.8389e+00, -6.1952e-01,  9.1167e-01,  1.2257e+00, -9.6860e-01,\n",
      "        -1.3737e-01,  7.2008e-01,  3.6462e-01,  1.4809e+00, -1.4594e-01,\n",
      "         9.6389e-01, -1.0409e+00, -1.7215e-01, -1.7952e+00,  5.4020e-01,\n",
      "        -7.6997e-01,  1.0301e+00, -1.5759e-02, -1.5427e+00,  2.2887e-01,\n",
      "        -4.4072e-01, -9.9662e-02, -7.0265e-01,  4.2000e-01, -6.4747e-01,\n",
      "         3.8777e-01,  1.1415e+00,  1.3939e-01, -5.9962e-01,  1.7747e+00,\n",
      "        -4.9357e-01,  4.5424e-01,  3.8528e-01, -1.1406e-01,  5.3714e-01,\n",
      "         9.5760e-01,  1.5632e+00,  1.3318e-01, -1.5861e-01,  8.1220e-01,\n",
      "        -1.7940e-01, -1.6002e+00,  7.2628e-02, -6.0461e-01, -1.7931e-01,\n",
      "         5.5232e-01,  8.5269e-02, -1.4649e-01,  3.5819e-01, -1.3963e+00,\n",
      "        -1.3251e-01, -1.8117e-01, -8.0957e-01, -2.1222e-01,  9.6354e-01,\n",
      "        -9.5916e-02, -5.3033e-01,  1.1112e+00, -2.6913e+00, -2.0313e+00,\n",
      "         1.6150e+00, -1.9441e-01, -7.8106e-02,  7.9640e-01,  1.4128e-01,\n",
      "        -8.6403e-02,  1.0892e+00, -1.8350e-01,  2.8921e-01, -1.0831e-01,\n",
      "         2.8012e+00, -2.1962e-01, -8.3137e-01, -2.9874e-01,  1.1799e+00,\n",
      "        -1.1627e+00,  2.0376e+00, -1.4339e+00,  5.2008e-02,  5.9759e-01,\n",
      "        -1.0997e+00,  2.7154e-01,  1.3021e+00,  7.4968e-01, -1.4037e-01,\n",
      "        -3.9918e-01,  7.0670e-01, -2.0589e+00,  1.7621e+00,  2.4725e+00,\n",
      "         5.4384e-01, -1.9662e-01, -5.8439e-01,  1.0530e+00,  8.6672e-01,\n",
      "         1.6177e+00, -7.9942e-02,  9.3379e-01,  7.2874e-01,  2.4657e-01,\n",
      "        -6.3581e-01, -2.1969e+00,  5.8977e-01,  1.7784e-01, -5.1629e-01,\n",
      "         8.6875e-01,  3.6831e-02, -3.3486e-01, -1.3053e+00, -1.0149e+00,\n",
      "        -1.2671e+00, -1.7613e+00, -6.2356e-01,  9.3946e-01, -9.5774e-01,\n",
      "         1.0184e+00, -9.9915e-01,  2.6331e-01,  1.8725e+00, -7.3043e-01,\n",
      "        -6.3729e-01,  3.9853e-02,  1.6510e+00,  1.4107e+00,  5.8832e-01,\n",
      "        -4.6881e-01, -2.1579e-01]), end embedding: tensor([ 9.4508e-01, -8.4607e-01,  1.0373e+00, -2.3792e-02, -6.7034e-01,\n",
      "         5.2804e-01,  4.5297e-01,  9.8956e-01,  5.7268e-02,  5.5834e-01,\n",
      "         4.9028e-01, -6.2372e-02,  5.8251e-01, -6.0373e-01, -1.8621e-01,\n",
      "         1.0435e-01,  8.4557e-01,  3.9401e-01,  9.1894e-01,  9.9541e-01,\n",
      "        -1.1891e+00, -3.6691e-01, -4.4616e-01, -9.0684e-01,  1.1740e-01,\n",
      "         9.9293e-01,  3.0168e-02, -3.6434e-01, -1.0293e+00,  3.0485e-01,\n",
      "         1.3741e+00, -3.8645e-01, -1.5379e+00, -3.6841e-01,  6.8146e-01,\n",
      "         5.0401e-01, -2.1586e-01, -3.3655e+00,  9.5748e-01,  5.8539e-01,\n",
      "        -2.1018e+00,  2.0876e+00,  1.3806e+00, -6.0346e-01, -9.3879e-01,\n",
      "        -6.5223e-01,  1.8937e+00,  4.1299e-02,  1.4819e+00, -7.5039e-01,\n",
      "        -8.9343e-01, -1.1086e+00, -5.8317e-01,  1.0024e+00,  1.0426e+00,\n",
      "         1.4585e+00,  9.1550e-01, -4.6097e-01, -9.1535e-01,  9.9746e-01,\n",
      "        -2.0671e+00,  1.3723e+00,  7.8197e-01, -7.4568e-01,  3.5591e-01,\n",
      "         4.6703e-01,  2.1524e+00, -2.2392e+00,  3.9477e-01,  4.4661e-01,\n",
      "         1.4906e-01,  1.1935e+00, -8.7571e-01, -2.0736e-01, -1.0383e+00,\n",
      "         1.4438e+00,  3.0756e-02, -7.2836e-02, -8.1645e-01,  5.2649e-01,\n",
      "        -2.0533e+00, -2.6489e-02,  6.7531e-01,  8.3792e-01,  1.5562e+00,\n",
      "        -4.9083e-01,  1.7676e+00, -5.4525e-01,  1.2576e-01,  1.7514e+00,\n",
      "         6.6303e-01, -9.6367e-03, -3.8087e-01,  8.2920e-01,  2.9412e-01,\n",
      "         1.8675e+00, -8.3219e-01,  1.3025e+00,  4.5011e-01, -2.4016e+00,\n",
      "        -6.9291e-01, -5.0267e-01, -8.9035e-01, -1.5169e-01,  4.7752e-01,\n",
      "        -2.3805e-01,  1.2887e+00, -2.0717e+00, -1.5084e-01,  1.9245e+00,\n",
      "        -1.5919e+00,  5.3315e-01, -4.8708e-01, -3.6294e-01, -7.4352e-02,\n",
      "         1.9597e-01, -2.5839e-01, -1.1992e+00, -2.5447e-01, -1.5154e+00,\n",
      "         8.4613e-01,  3.2624e-02,  8.0460e-01, -1.6280e-01,  2.0558e+00,\n",
      "         1.8879e-01, -1.4885e+00,  1.5720e-02, -5.1553e-01,  2.7468e-02,\n",
      "         2.1834e+00, -4.6234e-01, -1.0717e+00, -2.3977e-01,  6.7127e-01,\n",
      "         1.6365e-01,  1.0769e-01,  1.2512e+00,  1.9563e+00,  7.5704e-01,\n",
      "         5.9158e-03, -1.5416e-01, -5.4312e-01, -6.9118e-01,  5.7319e-01,\n",
      "         2.9879e-01,  7.8960e-01, -7.9194e-01,  1.7895e+00,  2.0051e+00,\n",
      "        -1.5120e+00,  8.1539e-03,  1.9315e-01,  4.9572e-01,  5.3672e-01,\n",
      "         7.8992e-01,  1.3302e-01,  2.5822e+00,  4.6047e-01, -5.5363e-01,\n",
      "         1.9109e-01,  1.7028e-01, -8.4220e-01, -7.2416e-01, -8.3591e-01,\n",
      "         1.5401e-01,  9.2270e-01,  9.2314e-02, -5.7189e-01, -8.9820e-01,\n",
      "         1.0682e+00,  3.3584e-01,  2.5604e+00, -1.1018e+00,  1.2654e+00,\n",
      "         8.8215e-02,  5.3768e-01,  1.5875e+00,  1.1619e+00,  2.8832e-01,\n",
      "        -1.0467e+00, -1.3153e+00,  1.5928e+00,  4.9800e-01,  1.6880e+00,\n",
      "         8.3475e-02, -5.1042e-01, -6.3131e-01,  2.6667e-01,  5.8506e-01,\n",
      "        -6.3371e-01, -1.7084e-01, -5.7341e-01, -8.1920e-01, -1.8185e+00,\n",
      "         6.0953e-01, -1.0673e+00,  9.7072e-02, -2.1321e+00,  1.4271e+00,\n",
      "         1.9449e+00,  1.1737e+00,  1.6971e-01,  2.9173e-01, -2.1025e+00,\n",
      "         5.6108e-01, -8.3652e-01,  7.7437e-03,  2.4667e-02, -5.1075e-01,\n",
      "         1.4996e+00,  4.3307e-01,  1.4183e+00,  1.8813e-01,  2.1675e+00,\n",
      "         1.6228e+00,  1.7913e-01,  4.5663e-02,  2.0285e+00,  2.4651e-01,\n",
      "         9.0256e-01, -4.6049e-01,  7.2068e-02,  2.2605e+00,  1.6446e-01,\n",
      "         7.9932e-01, -2.1124e-01, -4.1411e-01,  1.1879e-01,  1.9834e-01,\n",
      "        -1.1108e+00,  4.7168e-01, -6.6680e-01,  4.0253e-01,  3.2981e-01,\n",
      "         2.5516e-01,  1.0341e+00, -6.4394e-01, -1.1131e+00,  1.2196e+00,\n",
      "         2.4281e-01, -1.7888e+00,  2.7351e-01, -1.1417e-01,  4.6750e-01,\n",
      "        -2.0252e-01, -1.6664e+00,  4.1837e-01, -1.1013e+00, -4.6615e-01,\n",
      "         2.6903e-01, -9.2726e-01,  7.1826e-01,  2.3448e-01,  1.7898e+00,\n",
      "         5.1921e-01, -4.8726e-01,  5.2391e-02,  9.6525e-01, -2.3954e+00,\n",
      "         8.3208e-02, -1.6772e-01,  6.7202e-01, -5.8998e-01, -2.6585e-01,\n",
      "        -1.9851e+00, -3.7170e-01, -9.3266e-01, -8.6634e-01, -2.5911e-02,\n",
      "        -5.7427e-01,  1.7883e+00,  1.1326e+00,  8.5158e-01, -6.4994e-01,\n",
      "         1.2992e-02,  1.3392e+00, -1.0120e+00, -7.9567e-01,  4.4133e-01,\n",
      "         1.1522e+00,  1.5985e+00,  7.2850e-01, -5.7359e-01,  5.7955e-01,\n",
      "         3.1839e-04, -1.8407e+00,  5.4319e-02,  6.8987e-02, -2.0911e+00,\n",
      "         2.5903e-01, -2.4320e-01,  1.1468e+00,  6.4999e-01,  2.3872e-01,\n",
      "         1.0284e+00,  1.2512e+00, -8.7244e-01,  5.5472e-01, -1.6827e-01,\n",
      "         1.5104e-01, -2.1553e-01, -5.7044e-01,  1.8440e+00, -5.1181e-01,\n",
      "         2.1450e-01, -1.4765e+00,  2.6953e+00, -3.1944e-01,  8.5945e-02,\n",
      "        -2.2132e-02, -8.4921e-01,  1.6617e+00,  2.5365e-01,  6.6453e-01,\n",
      "        -3.8075e-01,  7.7890e-01,  1.2080e+00,  1.1690e+00, -3.3418e-01,\n",
      "        -5.5534e-01, -1.1890e+00,  7.7200e-01, -5.6220e-02, -1.7841e-01,\n",
      "         8.0801e-01, -2.6431e-01,  6.5584e-01, -8.8060e-01,  1.0529e-01,\n",
      "        -1.7761e+00,  3.5243e-01,  1.9503e-01, -6.6101e-01, -2.2250e-01,\n",
      "         2.3303e-01,  9.5133e-01, -2.0490e+00, -2.7332e-01,  1.8032e-02,\n",
      "        -1.5757e+00, -8.4555e-02, -7.1355e-01, -2.5082e-01,  2.3226e-01,\n",
      "        -4.9716e-01, -1.5979e+00, -6.1831e-01, -3.0305e-01, -1.0669e+00,\n",
      "         6.3091e-01,  1.1539e+00, -1.8950e+00,  2.5664e+00, -1.0838e+00,\n",
      "         3.1172e-01,  5.1726e-01, -1.6919e+00,  2.4262e-01, -1.9542e+00,\n",
      "         7.5487e-01, -6.6345e-01,  7.6583e-01, -8.3008e-01,  2.8895e-01,\n",
      "         1.9185e+00, -3.9093e-01,  1.6784e+00,  1.0628e+00,  1.6637e+00,\n",
      "         1.2680e+00, -6.6018e-02,  7.9312e-01,  1.9558e+00, -3.9452e-02,\n",
      "        -8.2781e-01,  6.3911e-01, -2.2574e+00, -1.0108e+00, -9.2464e-01,\n",
      "         1.4909e+00, -1.0946e+00, -2.4483e-01,  1.7986e+00, -1.8070e+00,\n",
      "        -9.8332e-01,  6.2541e-01,  1.2762e+00,  1.6443e-01,  1.9337e+00,\n",
      "        -7.9317e-01,  1.2526e+00,  8.5129e-01, -3.6517e-02, -1.2287e+00,\n",
      "         2.2507e-01, -1.2409e+00,  1.1773e+00,  1.2582e+00, -9.6608e-01,\n",
      "         5.6496e-01, -4.5203e-01, -5.2524e-01, -4.5427e-01,  4.9085e-01,\n",
      "         7.7408e-01, -1.3898e+00, -4.4953e-01, -9.0688e-01, -3.2979e-01,\n",
      "        -4.7652e-01, -1.8782e+00, -6.1307e-01, -1.4764e-01,  9.0117e-01,\n",
      "        -2.0680e+00, -6.8892e-01,  2.0763e+00,  1.8784e+00, -1.6325e-01,\n",
      "        -9.6500e-01,  8.9298e-01,  3.0549e-02,  2.4272e-01, -1.6830e+00,\n",
      "        -1.2119e+00,  1.8836e-01, -7.1516e-02, -4.2638e-01, -4.2114e-01,\n",
      "         7.5164e-01,  8.8087e-01, -1.0940e+00,  3.6833e-01,  8.8503e-01,\n",
      "        -1.0916e+00, -8.2273e-01, -1.0515e+00,  8.1831e-03,  2.4635e+00,\n",
      "        -5.5463e-01, -1.5483e+00,  2.0187e+00, -6.1949e-01,  7.8077e-01,\n",
      "        -4.5609e-01,  1.7949e-02, -8.1237e-01,  2.3998e-01, -3.5603e-01,\n",
      "         3.5062e-01,  1.3384e+00, -7.6017e-01,  1.2522e+00, -8.1690e-01,\n",
      "        -7.6615e-01,  1.3015e+00,  3.5832e+00,  1.7581e+00, -1.1467e+00,\n",
      "         1.9891e+00, -1.4947e+00, -6.5018e-01,  3.0105e-01, -3.7750e-01,\n",
      "        -6.7999e-01, -3.0547e-01,  1.0908e+00,  2.6838e-01,  3.0862e-01,\n",
      "         2.9981e-01, -1.0115e+00,  7.9474e-01, -1.0638e+00, -1.6550e-01,\n",
      "         1.1189e+00,  8.4509e-01, -1.2199e+00,  1.9155e+00,  8.1560e-03,\n",
      "        -4.0374e-01, -3.0584e+00,  7.5176e-01,  3.6497e-01,  1.7824e-01,\n",
      "        -4.8749e-01, -1.3508e+00, -2.8730e+00,  1.1205e+00, -4.3709e-01,\n",
      "        -2.1380e-01, -1.4619e+00,  4.0875e-01,  1.7882e+00, -2.4954e-01,\n",
      "        -4.1083e-01, -1.1227e+00, -9.5167e-01, -9.7279e-01, -1.0363e+00,\n",
      "         8.1403e-01, -9.9864e-01, -1.8603e-01,  4.4059e-01,  2.3072e+00,\n",
      "         1.0999e-01,  1.2772e+00, -4.8330e-01,  1.7010e+00, -4.3399e-01,\n",
      "        -2.9834e-01,  1.2639e+00])\n",
      "span length: 10\n",
      "span position embedding: tensor([[ 0.2646, -0.2359,  0.4529,  ..., -0.5603,  0.3245,  0.3620],\n",
      "        [-0.0196, -0.8800,  1.0720,  ...,  1.2667, -0.2152, -0.3769],\n",
      "        [-0.7504,  0.3307,  1.1889,  ...,  0.4162, -0.3113,  0.6106],\n",
      "        ...,\n",
      "        [-0.4134,  0.3019, -0.8666,  ..., -0.2635,  1.1804,  1.1398],\n",
      "        [ 0.6896,  0.1958, -0.0273,  ..., -1.5553,  0.4302, -1.2178],\n",
      "        [ 1.3378, -1.7574,  0.7789,  ...,  0.4283,  0.7124, -0.6670]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "span position embedding shape: torch.Size([10, 512])\n",
      "p_h: tensor([ 2.6463e-01, -2.3591e-01,  4.5285e-01, -1.1136e-01,  3.0407e-01,\n",
      "        -2.3966e-01, -2.7644e-02,  1.2563e+00,  3.6182e-01,  1.9652e-01,\n",
      "        -8.6246e-01, -7.1119e-01, -1.1506e+00, -8.6195e-01,  1.2013e+00,\n",
      "         1.3645e+00, -4.7164e-01, -1.0417e-02,  5.2249e-01,  1.8408e-01,\n",
      "        -1.4745e-01,  1.5400e+00, -1.0897e+00,  1.2691e+00, -1.9417e+00,\n",
      "        -2.5694e-01,  5.3591e-01,  4.6418e-01, -1.1935e+00,  1.5731e+00,\n",
      "         4.0055e-01,  1.6647e+00,  3.1474e-01, -5.1079e-01, -4.6470e-01,\n",
      "        -1.6623e+00, -1.9396e-02, -1.8199e+00, -4.0583e-01,  8.2175e-02,\n",
      "        -5.3666e-02, -6.3857e-01,  2.9397e-01,  5.2579e-01, -2.1096e+00,\n",
      "         1.7281e+00,  3.8924e-01,  3.7421e-01,  8.1201e-01,  6.8693e-01,\n",
      "        -1.9785e+00,  2.4820e-01,  6.1537e-01, -2.1311e+00,  1.0837e+00,\n",
      "         5.3762e-01,  4.5211e-01,  1.4208e+00,  1.8105e+00,  9.5980e-01,\n",
      "         6.4874e-01,  1.0742e+00,  1.9713e-01, -6.1546e-01, -3.3916e-01,\n",
      "        -3.3302e-02, -1.1120e+00,  1.2290e+00,  3.2036e-01,  4.7312e-01,\n",
      "        -1.0821e-01, -1.0119e+00,  7.7355e-01, -7.3499e-01, -1.4620e+00,\n",
      "         6.8714e-01, -1.4982e+00,  3.4491e-01, -1.1672e+00,  4.2549e-01,\n",
      "         1.1212e+00, -1.4065e+00,  2.5087e-01,  3.4171e-01,  3.1139e-01,\n",
      "         8.3637e-01,  1.2320e+00,  1.0655e-01,  8.9789e-01,  2.3202e-01,\n",
      "        -1.8274e+00,  3.1027e-01,  2.1902e-01, -2.4660e-01,  9.7873e-01,\n",
      "         3.6632e-01,  5.2638e-01,  4.3381e-01, -5.1404e-02,  9.4305e-02,\n",
      "         5.2549e-01, -5.7886e-01,  9.5275e-01, -9.3557e-01,  4.2693e-01,\n",
      "         1.2856e+00,  1.7819e-01,  1.1278e+00, -6.1495e-01,  1.0691e-01,\n",
      "         1.4019e+00, -1.9541e-01, -2.7272e-01, -5.9999e-01,  1.3753e+00,\n",
      "         4.8390e-01, -5.9446e-01,  6.2681e-01,  1.0675e-01,  2.6720e+00,\n",
      "        -4.6258e-01,  1.1697e+00,  1.0102e-01,  5.9059e-01, -1.1562e-01,\n",
      "         1.8833e+00, -1.9221e+00,  8.4052e-01,  1.2141e+00, -1.5262e+00,\n",
      "         1.3867e+00,  5.7718e-01,  7.7591e-01,  1.4728e+00,  2.4874e+00,\n",
      "        -5.0059e-01,  9.5103e-03,  3.5364e-01,  1.4312e+00, -4.0655e-01,\n",
      "         1.3028e+00, -2.3050e-01,  4.9509e-01, -1.8871e-03,  6.7407e-01,\n",
      "         1.6877e+00,  7.6270e-01, -1.0258e+00, -1.0028e+00, -7.8825e-01,\n",
      "         2.5775e-01, -7.2426e-01,  2.5744e-03, -2.3219e+00,  6.9216e-01,\n",
      "         2.6199e-01, -6.8344e-01,  1.6513e+00,  8.0119e-01, -9.5820e-01,\n",
      "         1.4848e-01,  4.2119e-01,  5.4669e-01, -5.4224e-01,  1.3896e+00,\n",
      "         5.5137e-01, -2.9887e+00, -8.5112e-01, -8.3678e-01,  4.3097e-01,\n",
      "        -8.2797e-01,  1.8303e-01, -8.1399e-01,  3.0334e-01,  4.3765e-01,\n",
      "        -1.6117e+00,  4.6604e-01, -1.1909e+00, -1.7815e-01,  4.5396e-01,\n",
      "         1.3874e+00,  1.3422e+00, -7.1142e-02, -5.3129e-01,  4.9093e-01,\n",
      "         8.8818e-01,  6.9741e-01, -4.1026e-01, -4.8009e-01,  7.1111e-01,\n",
      "        -3.7213e-01, -4.3906e-01,  1.4767e+00,  7.1079e-02, -1.7537e-01,\n",
      "        -1.1809e+00,  5.6096e-01, -6.4618e-01,  1.1893e+00,  1.5120e+00,\n",
      "         1.3990e+00, -6.8395e-01,  1.5880e-01, -5.5990e-01, -2.6268e-01,\n",
      "         5.4497e-01, -1.2274e+00,  2.7820e-01, -3.6112e-01,  9.7976e-01,\n",
      "         2.9502e-01,  5.4370e-01,  8.3105e-01,  1.8538e+00, -5.3877e-01,\n",
      "        -9.5267e-01, -9.1673e-01,  1.2531e-03, -2.0213e+00,  9.8051e-01,\n",
      "        -8.8374e-01, -4.2150e-02, -1.6528e+00,  1.9307e-01,  1.5692e+00,\n",
      "        -1.4780e+00, -9.2722e-01,  6.9250e-01, -1.8756e+00,  5.8865e-01,\n",
      "         4.9594e-01,  1.3061e+00, -7.3392e-01,  7.4737e-01,  5.5305e-01,\n",
      "        -1.4458e+00,  6.7631e-01, -2.8349e-01, -4.1311e-02,  9.9215e-01,\n",
      "        -7.9370e-01, -1.3216e+00, -3.7143e-01, -1.9428e-01,  1.7150e+00,\n",
      "        -8.5702e-01,  7.9772e-01,  8.0723e-01,  5.9285e-01, -1.7337e+00,\n",
      "        -3.6545e-01, -3.0930e-02,  9.5934e-02,  7.5442e-01,  2.2453e+00,\n",
      "         6.7726e-01, -1.8739e+00,  3.4552e-01,  1.1640e+00, -3.9320e-01,\n",
      "         5.5008e-01, -6.4734e-01,  2.0954e-01, -1.1305e+00, -7.5992e-01,\n",
      "         8.4470e-01,  1.9466e+00, -1.0329e+00,  1.2538e+00, -1.1546e-01,\n",
      "         1.4509e-01,  1.6514e+00, -1.4655e+00, -7.7295e-01,  1.8134e-01,\n",
      "        -1.8199e-01, -2.2637e-01, -1.4556e+00,  4.7327e-01,  5.7220e-01,\n",
      "         1.1069e+00,  5.3194e-01, -1.1256e+00, -3.2274e+00,  6.3759e-01,\n",
      "         4.2993e-03,  1.2920e-01, -3.1513e-03,  8.9170e-01,  5.2861e-01,\n",
      "        -2.7012e-01, -9.0175e-01, -1.6887e+00, -9.3186e-01,  3.1375e-01,\n",
      "        -1.5741e-01, -1.2657e+00, -2.7680e-03, -6.1508e-01,  1.6279e+00,\n",
      "         1.0891e-01, -1.2797e-01, -1.7622e+00, -1.5778e+00, -4.4926e-01,\n",
      "        -2.8947e-01, -2.0997e-01, -1.2714e+00, -3.0723e-01, -1.7475e+00,\n",
      "        -4.5016e-01, -2.0889e+00, -5.9639e-02, -1.2555e-01,  2.8605e-01,\n",
      "        -1.1658e+00,  1.7329e-02, -1.2733e+00,  6.8152e-01, -7.8875e-01,\n",
      "        -3.6547e-01, -2.8417e-01, -7.3583e-01, -6.6815e-01, -2.2105e-01,\n",
      "        -2.5366e-01, -6.1688e-01,  1.3577e+00, -4.7580e-03, -4.3801e-01,\n",
      "         1.0144e+00,  9.6206e-02,  1.1831e+00, -1.0204e+00, -7.2906e-01,\n",
      "         1.1042e+00,  1.0556e+00, -3.3137e-01, -5.8628e-02,  1.6092e+00,\n",
      "         6.9107e-01,  9.4272e-01, -4.0911e-01,  4.8866e-01, -9.8013e-01,\n",
      "        -5.3689e-01,  1.5416e-01, -4.8419e-01, -1.2030e+00, -1.8621e-01,\n",
      "         1.4200e+00, -5.6757e-01, -1.2296e+00, -8.0300e-01,  8.2033e-01,\n",
      "         9.9433e-01,  3.8412e-01, -2.9066e-01,  1.2961e+00, -5.4361e-01,\n",
      "        -1.3810e-01,  2.6702e-01,  3.3126e-01, -3.1704e-01, -9.3242e-01,\n",
      "         3.7303e-01, -3.5497e-01, -6.0568e-01,  6.2027e-01,  2.3453e-01,\n",
      "        -4.7209e-01,  3.3481e-02,  2.1820e-02, -5.8500e-01, -5.3081e-01,\n",
      "        -6.4882e-01,  2.2216e+00, -7.2217e-01, -2.9424e-01, -1.1246e+00,\n",
      "        -9.9307e-01, -8.4144e-01, -1.7093e+00,  7.5401e-01,  2.0645e-01,\n",
      "        -4.3273e-01, -1.7653e+00, -2.1502e-01,  4.2585e-01, -6.9993e-01,\n",
      "        -1.1024e+00,  9.1361e-01, -1.4485e-01, -1.9265e-01, -1.3256e+00,\n",
      "        -2.3604e-02, -1.9355e+00, -1.0227e+00,  1.1890e+00,  5.9773e-01,\n",
      "        -8.6292e-01, -3.0950e-03, -8.2854e-01,  5.9784e-01, -6.1528e-01,\n",
      "        -1.2698e+00,  5.7545e-01, -8.4002e-01,  1.3896e-01, -9.3209e-02,\n",
      "         7.3866e-01,  7.1812e-01, -6.1141e-01, -3.4375e-02, -1.0954e+00,\n",
      "         1.8022e-01,  3.2163e-01,  7.7503e-02, -1.0133e+00,  1.1984e+00,\n",
      "         9.1484e-01, -4.9774e-01,  2.1523e+00, -1.2008e-01,  3.3075e-02,\n",
      "        -4.0801e-01,  9.1579e-01, -6.9246e-01,  1.2818e+00, -1.7857e+00,\n",
      "         1.8785e+00,  7.0748e-02,  1.3929e+00,  2.0655e-01, -1.2619e+00,\n",
      "        -2.3901e-01,  1.2071e+00,  1.6173e+00, -1.3642e+00,  2.3291e+00,\n",
      "        -6.8836e-01,  8.9147e-01,  1.5207e+00, -1.8084e-01, -1.9412e-01,\n",
      "         7.5915e-01, -1.8645e+00,  5.3172e-01, -8.7955e-01, -2.4235e+00,\n",
      "        -1.0345e+00, -5.3043e-01, -1.7635e+00,  4.9432e-01, -1.3330e+00,\n",
      "         1.0709e+00,  9.4012e-02,  6.9564e-02, -5.0142e-01,  4.6696e-01,\n",
      "        -9.9967e-01,  9.0375e-01,  5.6307e-01, -1.6594e+00, -1.1686e-01,\n",
      "         2.4648e+00,  1.8703e+00,  1.4332e+00,  7.1619e-01,  2.5616e+00,\n",
      "        -2.2084e+00,  1.5308e+00, -1.2692e+00,  1.3647e-01,  1.0541e+00,\n",
      "         3.5369e-01,  1.0998e+00, -1.7216e-01,  1.3324e+00,  4.7375e-01,\n",
      "        -1.0231e+00,  7.9570e-01,  1.3606e+00,  2.0566e-02,  8.9172e-01,\n",
      "        -1.8407e+00,  1.8103e-01,  8.0128e-01,  9.9860e-01,  7.4569e-02,\n",
      "        -6.2979e-01, -1.1183e+00,  7.5391e-01,  2.5534e-01, -1.0144e+00,\n",
      "        -4.8885e-01, -1.3235e-01, -5.8060e-01,  5.4132e-02, -1.5560e+00,\n",
      "        -2.2478e+00,  9.4176e-01, -1.2558e+00,  4.1022e-01, -8.7279e-01,\n",
      "         8.9475e-02,  5.2558e-01, -1.1772e+00, -9.8584e-01, -5.6031e-01,\n",
      "         3.2450e-01,  3.6195e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.9598e-02, -8.8004e-01,  1.0720e+00, -2.7167e-01, -1.1181e-01,\n",
      "         1.2305e+00, -7.0031e-01, -4.4509e-01, -1.0202e+00,  1.7274e+00,\n",
      "         2.6604e-01, -2.7644e+00, -2.9702e-01,  7.5236e-01, -5.5668e-01,\n",
      "        -5.4757e-01,  1.4329e+00,  3.3933e-01, -2.2905e+00, -6.3927e-02,\n",
      "        -3.9277e-01, -1.3286e+00, -1.0442e+00,  6.3118e-01, -3.9864e-01,\n",
      "         1.1672e+00,  4.9961e-01, -2.4401e+00,  2.0224e+00,  1.4115e-01,\n",
      "         2.9880e-01, -1.7060e-01, -1.0577e+00,  7.1500e-01,  2.9370e-01,\n",
      "        -4.2851e-02, -3.0085e-01, -1.7421e-03, -4.0230e-01,  5.1137e-01,\n",
      "         7.4943e-01, -1.8208e-01,  2.6125e-01, -5.7877e-01,  2.7831e+00,\n",
      "         2.1889e+00, -1.2854e+00,  1.0939e+00,  2.9090e+00, -1.5365e+00,\n",
      "        -1.7057e+00,  1.0591e+00,  2.0244e+00,  2.2355e+00, -1.9716e+00,\n",
      "         1.3339e+00, -1.1843e+00, -1.5504e+00,  3.8147e-01, -1.5133e-01,\n",
      "         2.9308e-01,  9.4728e-01,  5.1063e-01, -9.4425e-01,  4.7430e-01,\n",
      "         3.3420e-01,  4.3306e-01, -1.4448e+00,  1.1767e-01,  2.6016e+00,\n",
      "        -1.0885e+00,  7.2074e-01, -8.0917e-01,  6.9210e-01, -5.1269e-01,\n",
      "         5.4817e-01, -3.4270e-02,  7.2508e-01,  4.0123e-01,  6.3323e-01,\n",
      "         1.3014e+00, -2.5752e-01, -3.7336e-01,  2.4239e-01, -7.1877e-01,\n",
      "        -1.3336e-01,  8.0229e-01,  1.1414e+00,  3.2048e-01, -1.1728e+00,\n",
      "         5.7086e-01, -1.9970e-01, -9.0181e-01, -7.4187e-01, -1.1517e+00,\n",
      "        -4.8143e-01,  3.5825e-02,  8.8615e-01, -8.7241e-01,  7.4572e-01,\n",
      "        -1.0059e+00, -1.2884e+00, -1.4603e+00, -8.2570e-01, -1.4340e-01,\n",
      "        -6.6732e-01, -5.6294e-01,  1.2165e+00,  1.0110e+00, -2.2715e+00,\n",
      "         5.6288e-01, -2.4479e-01,  1.4545e+00,  4.1549e-01, -1.3575e+00,\n",
      "        -7.9776e-02,  1.3199e+00,  5.7921e-01, -7.9095e-01,  9.1039e-01,\n",
      "         2.1433e+00, -1.6521e+00, -1.1074e+00, -5.2481e-01, -2.3083e-01,\n",
      "         1.4427e+00,  6.8813e-01,  9.2377e-01, -4.3607e-01, -6.7831e-01,\n",
      "         1.6607e+00, -6.0901e-01, -1.2238e+00, -1.2792e+00,  7.7615e-01,\n",
      "         1.7335e+00, -3.0826e-01, -1.6324e+00, -2.2841e-02,  7.7872e-01,\n",
      "        -2.3813e-01,  1.7590e+00, -2.6300e+00, -2.2589e+00, -5.7844e-01,\n",
      "        -1.0014e+00, -4.4668e-01, -1.0133e+00,  2.3634e-01, -5.3267e-01,\n",
      "        -9.9985e-01, -2.1989e+00, -3.7624e-01,  6.5364e-01,  7.5254e-01,\n",
      "        -1.3376e+00,  9.7770e-01,  1.1336e+00,  4.7673e-01,  2.9082e-01,\n",
      "        -1.3255e-01,  1.1891e+00, -1.3592e+00,  1.4276e+00,  1.0099e+00,\n",
      "        -2.0686e-01,  4.7024e-01,  6.6699e-01, -1.2182e+00,  4.1511e-01,\n",
      "         3.4016e-01, -1.3129e+00,  6.7744e-01, -9.9545e-01, -1.2289e+00,\n",
      "         1.6814e+00,  1.7367e-01,  4.4566e-01, -3.4744e-01,  7.7216e-01,\n",
      "        -7.9999e-01,  1.0696e+00, -1.9791e+00,  7.5679e-01, -6.2594e-01,\n",
      "         3.3649e-01,  3.2236e-01,  9.3129e-01, -2.6896e-01, -1.1185e+00,\n",
      "         1.2515e+00, -1.4685e-01, -7.1486e-02, -4.7896e-01,  2.8939e-02,\n",
      "        -1.6243e-01,  2.5263e-01,  7.6768e-01,  6.1950e-01, -9.7351e-01,\n",
      "        -8.4524e-01,  1.6915e+00, -7.3563e-01, -3.6067e-02, -1.9589e+00,\n",
      "        -8.4760e-02, -1.7551e-01,  2.5339e+00,  1.2955e+00, -2.5083e+00,\n",
      "         1.0164e+00, -2.3493e+00,  4.3328e-01, -4.7192e-01,  3.8348e-02,\n",
      "         2.2390e-01, -6.9014e-02, -1.4051e-01,  7.9474e-01, -1.8916e-01,\n",
      "         1.6112e-01, -1.3122e+00,  1.0782e+00, -8.3441e-01,  4.5891e-01,\n",
      "        -9.0378e-01,  1.0776e+00,  3.5492e-01,  6.7974e-01,  8.5984e-01,\n",
      "         6.2570e-02,  4.7049e-01,  4.9977e-02, -5.9910e-02,  5.8082e-01,\n",
      "         7.0209e-01,  1.8570e+00,  3.3905e-01, -3.4004e-01,  9.5000e-02,\n",
      "        -7.0462e-01, -1.1546e+00,  2.6067e+00,  2.8814e-01,  9.5239e-01,\n",
      "        -6.3638e-01, -2.4426e-01, -1.0868e+00,  4.2619e-01,  1.0016e-01,\n",
      "        -7.8702e-01, -5.4084e-01, -1.4274e-01, -1.9805e-02, -7.1918e-01,\n",
      "         1.7290e-01, -1.2436e+00,  3.1620e-01, -1.0714e+00,  6.6434e-02,\n",
      "        -4.5941e-01,  7.2912e-02,  6.2007e-01,  5.5581e-01,  1.1954e+00,\n",
      "         2.0939e-01, -5.0785e-01,  2.0959e+00, -8.1876e-02,  4.2700e-01,\n",
      "         5.0943e-01,  1.4900e+00,  4.3161e-01,  1.8884e+00,  6.2704e-01,\n",
      "        -1.4820e+00,  2.1680e-01,  8.0652e-01, -2.0691e-01,  6.6663e-02,\n",
      "        -4.1691e-01,  1.7703e+00,  6.1042e-01,  1.5419e+00, -3.6541e-01,\n",
      "         1.2856e+00, -8.3941e-01, -3.8372e-02,  7.4279e-01, -2.1912e-01,\n",
      "         1.5360e+00,  4.8248e-01,  8.2361e-01,  1.0086e+00, -8.2352e-01,\n",
      "         4.2431e-01,  8.4797e-01, -1.1859e+00, -4.4374e-01,  1.7759e+00,\n",
      "         2.6485e+00, -1.6682e+00,  1.4951e+00,  1.2841e-01,  9.0137e-01,\n",
      "        -5.5399e-01, -5.4908e-01, -1.6300e-01,  5.8974e-02,  7.7423e-01,\n",
      "        -1.1408e+00, -2.3258e+00,  1.7219e+00,  1.4725e+00,  4.4545e-01,\n",
      "         1.3608e-01, -3.4079e-01,  8.4047e-01, -1.5302e+00, -1.3600e+00,\n",
      "        -1.1235e+00, -1.1894e+00, -3.1683e-01, -8.8800e-01, -1.8915e+00,\n",
      "        -2.5639e-01, -2.3428e+00,  4.5652e-01, -4.4602e-01,  5.0303e-01,\n",
      "         7.9082e-01, -5.1529e-01, -7.5383e-01,  1.2808e+00, -1.0749e+00,\n",
      "        -6.3119e-01, -5.7263e-01,  2.3266e-01,  1.6130e+00, -2.6413e-01,\n",
      "        -1.5035e+00,  6.3873e-01,  3.8395e-01, -3.2821e-01, -9.4901e-01,\n",
      "         8.1626e-01,  1.2318e+00, -5.8183e-01,  7.6981e-01,  1.2267e+00,\n",
      "         2.7440e-01,  6.3441e-01, -1.2575e+00, -8.4964e-01, -1.4209e+00,\n",
      "        -2.0525e+00,  8.5586e-01, -2.0060e+00,  5.1493e-01,  4.4926e-02,\n",
      "        -1.1243e+00,  1.6439e+00,  3.8856e-02, -2.6801e-01,  3.7889e-01,\n",
      "        -1.6657e+00,  2.1121e+00,  4.7003e-01,  1.6673e+00,  1.4359e+00,\n",
      "         3.1666e-01, -1.8693e-01,  4.3260e-01, -7.3865e-01, -1.6888e-01,\n",
      "        -8.2745e-01,  4.4106e-01, -9.3589e-01, -6.0546e-01, -1.1373e+00,\n",
      "        -6.7438e-01,  6.9004e-01, -1.2898e+00, -8.5722e-01,  1.2332e+00,\n",
      "        -2.8805e-01, -5.1052e-01,  7.3412e-01,  6.2072e-01, -1.3678e-01,\n",
      "        -1.4201e-01, -7.5883e-03, -2.6767e+00, -7.6234e-01,  8.5236e-01,\n",
      "         5.6856e-02, -7.2773e-01,  1.2267e-01, -9.7834e-01,  5.1376e-01,\n",
      "         3.3411e-01,  1.3300e+00, -4.7372e-01, -1.1496e+00,  1.8684e+00,\n",
      "         7.2719e-01, -6.1977e-02, -1.3151e+00, -6.8870e-01,  8.6271e-01,\n",
      "         3.0699e-01,  5.7380e-01, -9.4069e-02,  4.6136e-01,  8.2800e-01,\n",
      "         3.8674e-01,  1.2559e-01, -4.6637e-01, -6.6718e-01,  7.6186e-01,\n",
      "         5.8211e-01,  1.2183e+00,  1.0905e-01,  3.3896e-01,  1.3243e+00,\n",
      "         2.9844e-01,  1.4861e+00,  4.9099e-01, -1.4104e+00,  1.1438e+00,\n",
      "        -1.6922e+00, -9.0433e-01, -7.5813e-01, -8.7738e-01, -3.2076e-01,\n",
      "        -4.6825e-01, -7.2635e-01,  1.1144e-03, -7.2225e-01, -3.4616e-01,\n",
      "         6.9479e-01,  1.1173e+00,  1.8688e+00,  2.0539e-01, -1.7454e-01,\n",
      "         6.0237e-01, -5.1255e-01, -7.0896e-01,  7.4415e-01,  6.1457e-01,\n",
      "        -1.3599e+00, -1.3151e+00, -9.6092e-01,  2.3501e-01,  4.3561e-01,\n",
      "        -5.8040e-01,  4.6350e-01,  1.0027e+00,  5.3332e-01,  6.2659e-01,\n",
      "         4.7085e-01, -2.4516e+00,  2.2334e-01, -7.2773e-01, -1.5475e-01,\n",
      "        -3.6478e-01, -5.8729e-01, -1.0755e+00,  8.3631e-01,  4.4258e-01,\n",
      "        -4.9116e-01, -1.7064e+00,  6.5128e-01, -1.7775e-01,  5.9177e-01,\n",
      "        -1.7584e+00,  2.9596e-01,  5.9606e-01, -1.0755e+00, -1.2221e+00,\n",
      "         1.5103e+00, -1.7211e+00, -3.5132e-01,  1.9871e+00,  8.4459e-01,\n",
      "         9.5885e-01,  2.2156e-01,  1.2679e+00, -2.6715e-02, -1.1446e-01,\n",
      "        -1.8737e+00, -3.3209e-01, -1.2168e+00, -1.2257e+00,  2.2572e-01,\n",
      "         1.2483e+00, -3.1807e-01,  9.7262e-01,  2.4968e-01,  6.2445e-01,\n",
      "         8.6025e-01,  5.9226e-01, -7.8353e-01, -1.0757e+00,  1.5338e+00,\n",
      "         1.4497e+00,  2.9066e-01,  1.6366e+00, -8.5775e-01,  1.2667e+00,\n",
      "        -2.1525e-01, -3.7695e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-0.7504,  0.3307,  1.1889, -0.1797,  0.4551, -0.2385,  0.3020,  0.3964,\n",
      "        -0.5703, -1.2782, -0.0379, -1.4034,  0.9590,  0.0099,  0.9522,  1.4344,\n",
      "        -1.1014, -1.8471,  0.1693, -0.9546,  1.4319,  0.8903,  0.8522, -1.3764,\n",
      "         0.2885, -0.0727, -1.9786, -1.7993,  0.1210,  0.5786, -0.8996, -0.2015,\n",
      "        -0.2142,  1.3566, -1.0467, -0.2777,  0.9662, -0.9339, -0.8660,  0.5690,\n",
      "        -1.6367, -1.2919, -0.3426, -0.9690,  0.4440, -0.9708,  0.5877, -0.9867,\n",
      "         1.0085,  0.6473,  0.8648,  0.0203, -1.8394,  1.0840,  1.4080,  0.6950,\n",
      "        -0.8276,  0.1367,  1.5239, -0.0234,  1.5090, -0.9798,  0.1744,  0.2268,\n",
      "        -1.1804, -1.1009,  0.1866, -0.2109, -1.2063,  0.4134,  0.6401,  0.8016,\n",
      "        -0.2500,  0.0466, -0.1226,  1.6164,  0.4022, -0.5826, -0.0856,  1.3567,\n",
      "         0.4002, -0.3948,  0.9759,  0.3123,  0.8401, -0.1592,  0.4744,  1.3961,\n",
      "        -0.0657, -0.1925,  0.8939,  0.0873,  1.0628,  1.7551, -0.6340,  0.4578,\n",
      "         0.2988, -0.2587,  0.6627,  1.9613, -1.1302, -0.9525,  0.5244,  0.6685,\n",
      "        -0.7214, -0.2801, -0.5120,  1.4162, -0.5164,  0.8006, -0.6180, -1.2510,\n",
      "        -0.0455, -1.7446,  0.3919,  0.0274, -2.4785,  0.5470, -0.7437, -0.0895,\n",
      "        -0.4452, -0.5428, -0.7256, -0.5121,  0.3895, -0.8705, -1.3791,  0.7412,\n",
      "        -0.4045,  1.1329,  0.5078, -0.6499, -0.9989,  0.3185,  0.8239, -2.3652,\n",
      "         2.0420,  1.1559, -0.2084,  1.9962, -0.9739,  0.9744, -1.1922, -1.8917,\n",
      "         0.9056,  0.1586,  0.7926, -0.6207,  0.8054, -0.1170,  1.2409,  0.6600,\n",
      "         2.1661, -0.1774,  0.1110,  0.4225, -0.0848,  0.3466, -0.7631, -2.1882,\n",
      "         0.2719,  0.1662,  0.2923, -1.0385,  0.4762,  0.7655,  0.4460, -0.2891,\n",
      "        -0.3066, -1.2684,  1.3048, -0.1688, -0.4136,  1.8192, -1.2687,  0.1156,\n",
      "        -0.3577,  0.9496,  0.3266,  0.1149, -1.4874,  1.4921,  0.3631,  0.0513,\n",
      "         0.9077, -0.0278, -0.2975,  0.2053, -0.7905,  1.5896, -1.3326,  1.4535,\n",
      "         1.5136,  0.6979, -0.7753, -0.0797,  0.8933, -1.5865, -2.8705, -0.2598,\n",
      "        -0.5357,  0.9557,  1.5877, -1.3100, -0.8385, -0.4479, -1.5694, -0.5087,\n",
      "         0.9920, -0.0290, -0.4488, -1.1622,  0.7778, -1.0847,  1.1099,  0.3768,\n",
      "        -0.6814,  1.6994,  0.3495,  0.1313, -1.2125, -0.4133,  0.3382, -1.4008,\n",
      "         1.6466,  0.4950, -0.3221,  1.3289,  0.7555,  0.3506, -0.8889, -0.1805,\n",
      "        -0.5240,  0.4309, -0.7121, -0.6457, -0.3073,  0.7066, -1.7207, -2.0986,\n",
      "         0.5175, -0.3444, -0.6635,  0.0468, -1.8558,  0.0919, -0.7158,  0.3148,\n",
      "         1.3764, -0.7770, -0.2787, -0.6062, -0.4592, -0.6404,  1.0975, -1.2084,\n",
      "        -0.0559, -0.7027, -1.0166, -1.8683,  0.3301,  0.7017,  0.4275, -1.1290,\n",
      "         0.1254,  0.9455, -0.4284, -1.2824, -0.2163,  2.0310, -0.5892, -2.6387,\n",
      "         0.2871,  0.9723,  0.8353, -0.0239,  1.5444, -0.7838, -0.6200, -0.2476,\n",
      "        -2.2379,  1.1104, -0.3804,  0.0345,  0.9600, -0.1915,  1.1250,  1.5672,\n",
      "         0.0503, -0.5717,  0.5345, -0.2425,  0.4562, -0.4484, -0.6491,  1.1844,\n",
      "        -1.0267,  1.0339,  0.3380, -0.2015,  0.6605,  0.0422,  0.1583,  1.1028,\n",
      "        -1.3520, -0.3794,  1.2837,  0.6935,  2.4659,  0.0182,  0.6813, -1.8906,\n",
      "         0.5508, -1.3803, -0.5619, -0.5565,  1.9952,  1.2809,  0.3816,  0.3348,\n",
      "         0.7241,  0.2163, -3.2037, -0.0758,  0.0477,  0.9328,  1.1508,  1.6287,\n",
      "        -0.5876, -0.3290, -0.5660,  0.6235,  0.8290,  0.4471,  1.4814, -0.6217,\n",
      "        -1.0007, -0.4594, -1.1678,  0.9717, -1.2264,  1.0469,  0.5557, -0.5625,\n",
      "         0.9440, -0.9814, -0.7207, -0.8293,  0.3572, -0.3558,  0.6082, -0.8350,\n",
      "        -0.1453,  0.9702, -0.2615, -1.0350,  1.1619, -0.9494, -1.1617, -2.2713,\n",
      "        -1.3153,  2.1866, -0.5869,  0.5863,  0.5625,  0.9849, -0.5078, -0.2339,\n",
      "        -1.0275, -0.7601,  0.1333, -0.8738, -0.6843,  1.6700,  1.2572,  0.2745,\n",
      "        -1.6771, -0.1209,  1.0814, -0.3502, -0.8827,  0.3480, -0.2602,  0.6152,\n",
      "         0.1692,  0.6783, -0.6858, -0.1144,  0.1485, -0.9948, -0.1695, -0.6526,\n",
      "         0.4156,  1.9687, -0.5675,  0.2630, -0.6254,  0.7081, -0.9420, -0.8826,\n",
      "        -1.8052,  0.5378,  0.0949, -0.4008,  1.2614,  1.3561, -0.5987, -0.0456,\n",
      "         0.3407,  0.7499,  0.2387, -0.5059, -0.3471, -1.6377, -1.8931, -0.5449,\n",
      "        -0.8162,  0.0195, -2.5477, -0.0890,  1.1402,  2.0917,  1.0522,  1.5690,\n",
      "        -1.3152,  0.0594,  0.6033, -0.8900,  0.8229, -0.7064, -0.4799, -0.1496,\n",
      "         0.1460, -0.6779, -1.1489,  0.7961, -2.4001,  0.4305,  2.0857,  0.4562,\n",
      "        -0.4430, -0.1794, -0.6101, -0.4280,  0.3718,  2.2594, -0.6633, -0.2723,\n",
      "         1.7358, -0.7143, -0.8630, -0.0437, -0.2681, -1.5857,  2.6693,  0.8341,\n",
      "         1.5734,  0.9690, -0.8671,  0.0320, -1.4927,  0.3371, -1.1928,  1.0526,\n",
      "         0.3028,  0.3294,  0.0487,  0.0846,  0.9330,  0.8237, -0.5224, -1.4377,\n",
      "        -2.4455,  0.0306, -1.2102,  0.0402,  0.9468, -0.1233,  1.1659,  0.6326,\n",
      "        -0.2395, -0.4908, -0.0631,  0.6146,  1.2287,  0.9718, -1.3850,  1.0913,\n",
      "        -0.6968, -2.5954,  0.6071,  0.6172,  0.6222,  1.1954, -1.2100, -0.6661,\n",
      "         1.3550,  1.5153, -0.8437, -0.6585, -1.5876,  1.0028,  0.6496, -1.2787,\n",
      "        -1.5123,  0.3077, -2.7209, -0.4437,  2.0181,  0.4162, -0.3113,  0.6106],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 0.7531, -0.7363,  0.8928, -0.6926, -0.9729, -0.9755,  1.0935,  1.0393,\n",
      "        -0.9137,  0.5936,  0.9871, -0.3495,  0.7887,  0.1816,  0.4229,  0.9720,\n",
      "        -0.3118, -1.5541, -0.6221,  0.4309,  0.6774, -0.5444,  0.3009, -0.9206,\n",
      "        -0.0292,  0.4168, -1.0160,  0.4018, -1.3898,  0.8555, -1.0936, -0.9428,\n",
      "        -0.3020,  0.3498,  0.1285,  0.0478, -0.2251,  1.2518, -1.7093, -0.5349,\n",
      "        -0.4390, -0.4821,  1.5870, -0.9253, -0.7118,  0.2389,  0.1552, -0.1675,\n",
      "        -0.0340, -0.9234,  0.4944,  0.8247, -0.8528, -0.8063, -0.0886,  0.5622,\n",
      "         0.5651,  0.9036,  2.2625,  0.9145,  0.1182, -1.7542, -0.2661, -0.3209,\n",
      "         0.0141, -1.1732,  0.4513, -1.7826, -0.7659,  1.0393, -0.7496, -0.3706,\n",
      "        -0.4737,  0.4156, -1.3194, -0.0606, -0.1240, -0.3378,  0.1365,  0.4346,\n",
      "        -0.0226,  0.3109, -0.6643,  0.1879,  0.2790, -0.6583, -0.3708, -1.4896,\n",
      "        -1.2785, -1.6092, -0.2999,  0.5370, -0.5264, -0.7987, -1.6887, -0.8052,\n",
      "         1.6229, -2.0226,  0.7470, -1.8787, -0.2243, -1.7264,  0.5807,  0.3209,\n",
      "        -0.0954,  0.0412, -0.6439,  0.3075, -1.9031,  1.1356,  0.1921, -0.9154,\n",
      "         0.5824,  0.0662, -0.4993, -0.1421, -1.1804, -0.0766,  1.3365, -0.9382,\n",
      "        -1.2681,  0.3607, -0.4597, -0.0202, -0.1164, -0.7065, -0.5318,  1.0709,\n",
      "         0.4391, -0.4096, -0.6896,  0.5782,  0.3683,  0.3523,  0.2609, -0.5519,\n",
      "        -1.0848,  0.0516, -0.2046,  0.0396, -0.1243, -2.1491,  1.6711,  0.8034,\n",
      "         0.6021, -0.2712,  0.3674, -0.7799,  0.4861, -1.5102, -1.1974, -0.0139,\n",
      "         1.6280,  0.9664, -0.2378, -1.8276,  0.8376,  0.3006, -0.7687, -0.3457,\n",
      "         0.3601,  0.1684, -1.3267,  0.6908, -0.1530,  1.6892,  0.1517, -1.4973,\n",
      "        -0.0112,  1.5692,  0.7724,  0.2470,  1.5443,  1.7797,  0.7531,  1.0053,\n",
      "        -0.0217,  0.7802,  0.8498,  2.0872, -0.3318,  0.5337, -0.2782, -0.0662,\n",
      "         0.5003, -1.7339, -0.6287, -0.7887, -1.8656,  1.0569,  1.4321, -0.6949,\n",
      "        -0.4006,  1.0018, -0.2719,  1.1059, -0.5218, -1.1461,  0.1634,  1.0861,\n",
      "        -0.5496,  1.5562, -0.9962,  0.0463,  0.1726,  0.5462, -0.6034, -0.5219,\n",
      "         0.8430,  1.0978,  1.2473,  0.5526,  1.6220, -0.6585, -1.6148, -0.4585,\n",
      "        -0.1562, -0.1353, -0.5096,  0.6394, -1.2088, -0.5361, -1.1708, -0.3309,\n",
      "        -0.8581, -1.0179,  0.5968, -0.9728, -0.3434, -0.1339, -0.6434,  0.4880,\n",
      "         2.2742, -0.0944,  2.0528, -2.7674,  1.3111, -0.2010,  1.1696, -0.2611,\n",
      "         0.8821, -0.6592, -0.7563,  0.4887, -0.6544, -1.1268, -1.3197,  0.9344,\n",
      "         1.7936, -1.6109, -0.2454, -0.9013,  0.0880,  0.5533,  1.0549, -0.9758,\n",
      "        -0.1407,  2.8095, -0.9099, -0.7303, -0.3417,  0.6089,  0.9300,  1.0198,\n",
      "        -1.1946,  0.2425,  0.6574,  0.0875,  0.2764,  0.4373,  0.9318,  0.2355,\n",
      "        -0.5537,  0.5667,  2.8802, -1.3356,  0.8170, -0.4472,  0.4926,  0.5994,\n",
      "         0.4054,  0.6441,  0.5927,  1.8441, -1.5811,  0.3903, -0.4566, -1.6355,\n",
      "         1.1076, -0.4159, -0.6460, -0.6793, -1.5635, -0.9606,  1.1145, -0.5555,\n",
      "         0.4238,  0.4527,  0.2129, -2.1143, -0.9769,  0.6322, -0.3952, -0.5822,\n",
      "         0.7836,  1.3863, -1.2708, -0.5403, -0.9627,  0.0259,  0.6504, -0.3424,\n",
      "        -0.7688,  0.3877, -1.0616,  0.4675,  0.6993, -0.1053, -0.5111, -0.7019,\n",
      "        -0.4515, -0.7530, -2.1695, -1.7280,  0.7451, -0.9084,  1.5538, -1.5810,\n",
      "        -0.5175, -1.4113,  0.8039,  0.5204, -0.9799, -0.1805, -0.4348,  1.4107,\n",
      "         0.3819,  1.4586,  0.1360, -0.9129,  1.0682,  0.3539, -0.6722, -1.7417,\n",
      "         0.5952, -0.1645,  1.2694,  0.2523, -0.2948,  0.0218, -0.0507,  0.6350,\n",
      "         0.7397,  0.0163, -0.7734, -0.4175,  0.2264, -1.0855, -1.7458, -0.2367,\n",
      "        -0.7154,  0.7537, -0.0368, -0.0862,  0.0316, -1.5801,  0.7899, -1.0933,\n",
      "        -1.0679,  0.5226,  0.6205,  2.6632, -0.5921, -1.1175, -1.2108,  2.3375,\n",
      "         0.1418, -0.6485,  1.8897, -1.5954, -1.4534, -1.1107, -1.1256, -0.8515,\n",
      "         0.8228, -0.8361, -0.0713,  0.5084,  0.3113,  1.0339, -0.8551, -0.5366,\n",
      "        -0.4159,  0.8081, -1.2260, -0.2649,  0.5234, -0.3557, -0.3537,  0.1824,\n",
      "         0.6466, -0.0899,  1.2596,  1.6836, -1.1636,  0.1605, -1.3545, -0.3573,\n",
      "         0.6436, -1.5709,  1.4277,  0.5909, -0.4769, -1.0870, -0.8652, -0.5768,\n",
      "         0.7664, -0.5004, -0.2625,  0.8998,  0.1734,  0.1667,  0.7461, -0.4351,\n",
      "         1.4735,  1.0565, -0.2099, -0.2343,  1.9185, -0.6999, -0.3322,  0.5428,\n",
      "         1.7023, -0.4736, -0.9804,  0.2349, -0.4837, -0.4915, -0.0168, -0.2390,\n",
      "         0.0975, -0.9108, -0.6732, -0.8357,  0.5374,  0.8895, -0.1526,  2.2781,\n",
      "        -2.0240, -0.1147, -0.1071, -0.9650,  0.8701, -0.5172,  1.5668,  1.0746,\n",
      "         0.5556,  0.5889, -1.1191, -0.1289,  3.0657,  0.8460, -0.3935,  0.5152,\n",
      "         0.5259,  1.7780, -1.0691,  0.7091, -1.0254,  2.3092, -2.1163, -0.5794,\n",
      "         1.1337,  0.0414, -0.4115,  1.2584, -0.2627,  0.8886, -1.8166,  0.1700,\n",
      "         2.4251,  0.6248,  0.3373,  0.6689,  0.7182, -0.6244,  0.2550, -1.6057,\n",
      "         0.6256, -0.5297, -1.6698,  1.1108, -0.5659, -0.0678, -0.5951,  0.3956,\n",
      "         0.3492, -0.6980, -0.2782, -0.3279, -0.3704, -1.4156,  0.1850,  0.8713,\n",
      "         0.3335,  0.5357, -1.3410, -0.5683,  1.7524,  1.1073,  1.1675, -0.4112],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-0.7338, -1.6763, -0.3549, -0.1941,  0.3507,  0.3863,  1.3906, -0.9792,\n",
      "         0.1711,  0.0990, -1.9581, -0.5358, -1.1627,  2.4011, -0.4018,  0.3463,\n",
      "        -0.1664,  0.4906, -0.5144,  0.7186, -0.2562,  1.0769,  0.0741, -1.4500,\n",
      "         0.3929,  0.5912,  3.0157, -0.0272,  0.1921, -0.6166, -1.9523,  0.3198,\n",
      "        -1.1175,  2.1696,  0.5832,  0.2077,  0.1342,  0.0925,  0.3341,  0.1134,\n",
      "        -0.6895, -0.7507,  0.2076,  0.5485,  0.3010, -0.3393, -1.3200, -0.0404,\n",
      "        -0.1357,  1.4580,  0.2741,  0.2274, -0.0402, -1.3432,  0.3028, -0.2210,\n",
      "         0.2724, -2.1004,  1.5401, -1.6025, -0.2388,  0.4070,  0.0787,  1.2822,\n",
      "        -1.1841, -0.5006,  0.4060,  0.8559, -0.6285, -0.8204, -1.2236,  0.1593,\n",
      "         1.4061, -0.9433, -0.5365, -0.5187, -1.4857, -0.8593, -0.2498,  0.1610,\n",
      "        -0.7126,  1.8801,  0.8612,  2.0391,  1.0779, -1.6493,  0.9477,  0.4302,\n",
      "         1.4652, -1.4035,  0.5981,  1.3011,  0.1538, -2.1954,  0.0304, -0.6577,\n",
      "        -0.5688,  1.2119,  1.8449, -0.0929, -0.2530, -0.6101, -1.6535, -0.2272,\n",
      "        -0.3697, -0.5863, -0.7604, -0.1907, -0.9142,  1.1486,  0.1790,  0.7350,\n",
      "         0.2150, -0.7916, -2.3360, -0.1395,  1.1555,  1.2025,  0.3322, -0.0598,\n",
      "         0.7787, -2.1193,  2.3882,  0.1306, -2.3048,  0.8446,  0.1590,  0.9846,\n",
      "        -1.2836, -0.8413,  0.6786,  0.8275,  1.1225, -0.9149, -0.6512,  1.1000,\n",
      "        -0.0643, -1.4170, -1.1849,  0.6092,  1.9047, -0.5397, -1.6372,  1.1076,\n",
      "         0.0221,  0.2886, -0.6413, -1.2043, -1.3903,  0.6350,  0.2534, -0.9842,\n",
      "        -1.4864, -0.6768, -0.7498,  1.2174, -0.1388,  0.9520, -0.3750,  2.2531,\n",
      "        -0.5735,  0.2455,  0.3494,  0.6056,  0.4169,  1.3836, -1.1760,  0.1170,\n",
      "         0.4367, -0.8242,  1.3980, -1.5933, -1.1925,  1.1181,  0.1971, -0.8573,\n",
      "        -0.9522,  0.6428,  1.5156,  0.0772,  0.3084, -0.4216, -1.9453, -0.7647,\n",
      "         0.4886,  1.0581,  0.5702,  0.0923,  0.4273,  0.2854, -0.3893, -0.7235,\n",
      "        -0.8131,  0.8662, -1.3173,  0.1910,  0.6195, -0.6078,  0.6392,  0.0195,\n",
      "         0.3726, -0.7921,  0.4373,  0.8827,  1.3645, -1.5965, -0.6290, -0.8963,\n",
      "        -0.6834, -0.2782, -1.2055,  0.1063,  1.8505,  0.4095,  0.4303, -0.2768,\n",
      "        -0.4975, -2.0144, -0.1946, -1.6336,  0.9752,  1.0738,  0.1957,  0.0630,\n",
      "        -0.7218, -0.3753, -0.5283, -0.0433,  0.5155, -0.5307,  1.5380, -0.5625,\n",
      "         1.2306,  1.5754,  0.7936, -0.1982,  1.4018, -1.6278,  2.4439, -0.1695,\n",
      "         0.8430,  0.3452, -0.2385, -1.4015,  0.3448,  0.3881,  1.0378,  0.1916,\n",
      "         2.2678,  0.5522,  0.1512,  0.3308, -0.3852, -2.0678,  1.3751,  0.9036,\n",
      "         0.9258, -0.0641, -0.2367,  1.5500,  0.9170, -0.9806,  1.1248,  0.6027,\n",
      "         1.9543,  0.0732, -0.8426,  1.1737, -0.2688,  0.0542,  0.5795, -1.5697,\n",
      "         1.1623, -1.3557, -0.3886,  1.1713,  0.1084, -0.4921, -0.8760, -0.7379,\n",
      "         1.0748, -0.8175,  1.4752, -1.5153, -0.4777,  0.2789, -0.4888, -0.0713,\n",
      "        -0.2453, -1.2795, -0.3798, -2.0271,  0.4051, -0.4117,  0.7516,  0.0076,\n",
      "         0.4287, -0.3696,  0.9039, -1.2289,  0.4509, -0.1373,  0.1655,  0.1205,\n",
      "        -0.8257,  0.4885,  1.4767, -0.2893,  1.3626, -1.0587,  0.8032,  0.4658,\n",
      "         0.7951, -0.0034,  1.4459, -1.4115, -0.1051,  0.1208, -1.5846, -0.5750,\n",
      "         1.6063, -0.6273,  1.0118, -1.7413,  0.4996,  2.3617, -1.8307,  0.1838,\n",
      "        -0.8856,  0.7201, -0.6958, -0.3077, -0.2590,  1.4315, -0.4085, -0.4394,\n",
      "        -0.1711,  0.4258,  0.7069,  0.8904,  0.0216,  0.9054,  0.5254, -1.7269,\n",
      "         0.3079,  1.4548, -2.2236,  1.8306, -0.1132,  1.7285,  1.8789,  1.0517,\n",
      "         1.5911, -0.0982,  1.8796, -0.3041,  2.0230,  0.1169, -0.4599, -0.5594,\n",
      "         0.4784,  0.4133, -0.5586, -1.3170, -1.3394,  0.2354,  0.2709,  2.2993,\n",
      "        -2.2636, -0.3295,  1.6524, -1.0919, -1.1053, -1.2513,  0.8901, -0.7066,\n",
      "         0.1894,  1.0276, -0.3520,  0.1459,  1.2593, -0.2546,  1.4322, -0.9330,\n",
      "         1.1960, -0.0747,  1.2727, -1.6243, -1.0163,  1.1843,  0.4317,  0.3775,\n",
      "         1.2234, -0.1683,  0.1165,  0.4793,  0.7389, -0.0092,  0.2473,  1.2257,\n",
      "         0.3983,  1.2734,  1.8937,  0.4771,  0.0320,  0.5802, -0.0719, -0.0478,\n",
      "         0.3242,  0.7125, -0.8031,  0.5583,  0.2270,  0.6165,  0.3771, -0.6013,\n",
      "         1.2926, -0.6156,  0.5517, -0.2977, -0.9133, -0.1515,  0.8524, -2.1772,\n",
      "        -0.9094, -0.9203, -1.3816,  0.0569,  1.5110, -1.6256,  0.5694, -0.8779,\n",
      "        -0.1757,  3.2988,  1.3390,  0.2852, -1.2785, -0.1847,  0.7580,  0.3324,\n",
      "        -0.5955,  0.7144,  0.2778,  0.4948,  0.3947,  0.2881, -1.2016, -1.1354,\n",
      "         1.4017,  0.0230, -0.2190,  0.1290, -2.3471,  0.9612,  0.4295, -0.2501,\n",
      "         1.5302, -0.0325, -1.6149, -1.7699, -0.5582,  0.7023, -0.7368, -1.3348,\n",
      "         0.1609,  0.4887,  0.0353,  0.3208,  1.6906, -0.6111,  1.5532,  0.4070,\n",
      "         1.2926,  1.6172, -2.4906,  0.1140,  0.1138,  0.0368,  2.0958, -1.2861,\n",
      "         0.6318,  1.2962,  1.3057, -0.3549, -1.0906,  0.5602, -1.4186,  1.3241,\n",
      "        -0.1216,  0.3878, -0.5689,  1.0375, -0.2962, -0.3892, -0.0404, -0.3786,\n",
      "        -0.6090, -1.0190,  0.6503, -0.7232, -1.3875, -0.3297,  0.8695, -0.2434,\n",
      "         1.0456, -0.6400,  0.4192,  0.7664, -0.3389, -0.2505, -0.5215,  0.2441],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.8494e-01, -5.3083e-01,  5.0437e-01, -2.2348e+00,  1.2542e+00,\n",
      "         1.5338e+00,  7.8169e-01, -2.3317e-01,  1.5286e+00,  1.3569e-01,\n",
      "         4.0290e-01,  1.8493e+00, -7.9454e-01, -1.5602e+00, -1.8538e-01,\n",
      "        -9.3167e-01, -1.3116e+00,  8.5722e-01,  5.9915e-03,  3.6848e-01,\n",
      "         4.7708e-02,  5.7125e-01, -1.5200e+00,  2.2264e-01, -9.6997e-02,\n",
      "         1.2475e+00, -3.0700e-01,  1.5349e+00,  1.4274e+00, -1.0634e+00,\n",
      "         1.1297e+00,  8.9071e-01, -1.1357e+00, -2.3466e+00,  1.3380e+00,\n",
      "         7.3773e-01, -5.5525e-01,  3.3381e-01, -5.3148e-02, -1.8414e+00,\n",
      "        -7.1288e-01, -1.4630e+00,  2.5522e-01, -2.5110e-01,  6.3704e-01,\n",
      "         7.2710e-01,  2.5356e-01, -1.7897e+00,  1.8913e-01,  2.4156e+00,\n",
      "         1.2734e+00, -5.2081e-01, -1.6202e-01, -4.2685e-01,  6.4619e-01,\n",
      "        -1.2554e+00,  4.4385e-01, -9.7687e-02,  7.7042e-01,  6.5347e-01,\n",
      "         5.2222e-01,  9.4024e-02, -1.1131e+00, -6.5163e-01, -9.9953e-01,\n",
      "         1.6715e-01, -2.3913e-01,  2.3532e-01,  2.0519e+00, -1.0220e+00,\n",
      "        -1.1361e+00,  2.4424e-01, -1.5875e+00,  7.2025e-01, -1.1364e-02,\n",
      "        -8.6575e-01,  1.0265e+00,  4.2020e-01,  1.1184e-02,  4.5980e-01,\n",
      "         5.0124e-01, -6.4380e-01,  2.0758e+00, -2.9185e-01, -5.6476e-01,\n",
      "        -2.4026e-01,  1.0855e-01, -1.3413e+00,  3.3621e-02, -5.7377e-01,\n",
      "        -8.1297e-01,  8.5123e-01, -9.8318e-02, -1.6718e+00, -9.8202e-01,\n",
      "         7.3319e-01,  1.3893e+00,  1.0714e+00,  2.0570e-01, -1.3056e-01,\n",
      "         1.4529e-01, -1.2653e-01, -2.0280e+00,  1.4347e+00, -2.7985e-01,\n",
      "        -1.1501e+00, -3.0113e-01,  1.2010e+00, -1.3659e+00, -2.1032e+00,\n",
      "        -1.7644e-01, -2.3151e-01, -4.8522e-01,  1.6083e+00, -8.8058e-01,\n",
      "        -9.8956e-01,  2.5451e-01,  1.0917e+00,  4.6900e-01,  1.2549e+00,\n",
      "        -1.9479e+00, -3.1013e-01,  1.0314e-02,  7.5544e-01,  1.6273e+00,\n",
      "        -2.0081e+00,  3.9316e-01,  6.0180e-01,  4.5822e-02,  8.9867e-01,\n",
      "        -2.6616e-01, -8.7266e-01, -6.8965e-01, -1.0193e-01,  5.6791e-01,\n",
      "        -2.8493e+00, -1.3319e+00, -2.2998e-01,  7.0324e-01,  6.6508e-01,\n",
      "         1.1100e+00,  5.5022e-01, -6.8976e-01,  1.5039e+00,  1.4083e+00,\n",
      "         8.7571e-01,  2.9360e+00,  1.0661e-02, -1.0201e-01,  2.5496e-01,\n",
      "         1.1868e+00,  9.9701e-01,  2.5359e+00,  6.3222e-01, -1.1614e+00,\n",
      "        -9.9059e-01, -1.0969e+00,  2.6930e+00,  9.7306e-03, -3.8605e-01,\n",
      "         1.2273e+00, -9.9410e-01, -1.1639e+00,  2.3151e+00, -2.1877e-01,\n",
      "         1.1039e+00,  6.7242e-01, -3.9824e-01, -1.8376e-01,  2.7450e-01,\n",
      "        -8.2624e-01, -2.6267e+00, -1.9227e+00, -5.4743e-01,  4.5923e-01,\n",
      "         1.1836e+00, -1.0979e+00, -1.1686e+00,  6.0074e-01,  9.9204e-01,\n",
      "        -1.0314e+00,  6.6879e-01, -6.7411e-01, -2.4292e+00, -2.0132e+00,\n",
      "         1.3071e+00, -2.2148e+00,  7.4446e-01,  8.1050e-01, -6.7657e-01,\n",
      "        -3.7547e-01,  5.5803e-02,  7.6287e-01,  8.0579e-01, -9.9187e-01,\n",
      "         7.2487e-01,  2.1018e+00, -8.2545e-01,  1.2863e-01,  1.2077e+00,\n",
      "         7.7330e-01, -1.8775e-01,  2.5892e-01,  2.7393e-01, -2.1341e+00,\n",
      "        -2.1400e-01,  4.3941e-01,  1.2994e+00, -3.3512e-01,  1.0251e+00,\n",
      "        -3.1259e-01,  1.6658e+00,  8.1700e-01,  1.1019e+00, -2.0538e-01,\n",
      "        -7.2627e-01, -2.9143e-01,  6.1002e-01,  2.8126e+00, -2.6082e-01,\n",
      "        -2.3117e-01,  1.0460e+00,  5.2025e-01, -2.3104e-01, -4.8281e-01,\n",
      "         1.2033e+00,  1.7325e+00, -5.1106e-01,  1.0929e+00,  1.2990e+00,\n",
      "        -1.0250e+00,  1.8018e+00,  1.2824e+00,  2.1462e+00, -7.9390e-01,\n",
      "         4.7252e-01, -1.7480e+00, -1.3392e+00, -8.6747e-01, -8.2664e-02,\n",
      "         2.3397e+00, -4.6811e-01,  8.8751e-01, -1.4594e+00, -5.6935e-01,\n",
      "         5.0961e-01,  8.3484e-01,  1.7012e-01,  1.3390e+00, -6.1806e-02,\n",
      "        -5.7468e-01,  1.3116e+00,  5.4598e-01, -2.5181e+00,  2.1035e-01,\n",
      "        -1.8985e-03,  1.6371e+00,  3.3547e-01,  6.7048e-01, -9.6956e-01,\n",
      "         5.4599e-01,  1.0069e+00, -2.2140e+00, -8.6218e-02,  3.5032e-01,\n",
      "         1.0314e-01,  6.6352e-01,  1.2339e+00, -1.0548e+00, -3.1536e-01,\n",
      "         4.5344e-01,  9.0382e-01,  1.6796e-01,  1.9390e-01, -7.0939e-02,\n",
      "         1.0526e+00,  8.8158e-02, -1.7172e+00,  1.0594e+00,  7.3139e-01,\n",
      "         2.4339e-01, -5.5323e-01, -1.8158e+00, -1.1148e+00, -7.9146e-01,\n",
      "         9.5212e-01, -7.7432e-01, -1.0271e-01, -5.3889e-01, -4.3248e-02,\n",
      "         6.1978e-01, -4.4540e-01,  1.6308e+00, -2.9676e-01, -2.2510e-01,\n",
      "         5.5301e-01, -7.5100e-02,  7.3965e-01,  2.1249e-01, -9.0268e-01,\n",
      "         1.6348e-01,  5.9654e-01, -1.4402e+00, -7.2802e-01,  8.4184e-01,\n",
      "        -1.4770e+00, -1.4944e-01, -8.6175e-01,  4.4818e-01, -5.7287e-01,\n",
      "        -5.7963e-01,  8.1081e-01, -1.4113e+00,  7.0815e-01, -1.5359e-01,\n",
      "         9.4431e-01,  1.5226e-01, -2.4177e-01,  1.8355e+00,  3.8035e-01,\n",
      "         1.4277e+00,  3.5892e-01,  5.1784e-01, -1.0406e+00, -8.1807e-01,\n",
      "         9.4077e-01, -5.4342e-01,  7.4878e-01, -5.6647e-01, -2.9158e-02,\n",
      "        -8.3583e-01,  1.5249e+00,  1.6380e-01,  2.6280e-01,  1.7382e-01,\n",
      "        -8.4719e-01, -7.1524e-02,  3.5117e-01, -1.3056e+00, -2.5551e+00,\n",
      "        -2.5588e+00,  6.5705e-01, -8.3318e-01, -2.1086e-01,  6.4568e-01,\n",
      "         5.1686e-01,  2.0706e-01,  1.4585e+00, -1.1359e-01, -6.3840e-01,\n",
      "         5.9003e-01,  1.3226e+00,  1.8790e+00,  1.7409e-01, -9.7798e-01,\n",
      "        -2.1582e+00, -1.9792e-01,  1.3617e+00,  9.7169e-02, -3.4257e-01,\n",
      "         5.0364e-01,  7.0160e-01,  2.5264e-01, -3.0277e-01, -8.8872e-02,\n",
      "         1.4782e+00,  1.2595e+00,  1.7062e+00, -9.8213e-01, -8.6793e-01,\n",
      "        -5.5957e-01,  5.3964e-01,  8.2897e-01,  1.4538e+00, -5.3004e-01,\n",
      "         1.0238e+00,  3.1112e-01, -5.4034e-01,  1.2097e+00,  4.2087e-01,\n",
      "         1.3177e+00, -1.3627e+00,  1.2301e-01, -8.2273e-01,  1.3489e+00,\n",
      "         5.6412e-01,  4.4240e-01,  1.5432e+00, -6.5495e-01,  4.8399e-01,\n",
      "        -8.1070e-01,  3.4751e-02,  5.3816e-01, -3.7201e-01,  3.2387e+00,\n",
      "        -8.1723e-01,  1.0183e+00, -6.4435e-01, -2.0318e-01, -1.7039e+00,\n",
      "        -9.5705e-01,  1.0293e+00, -6.0194e-02,  3.7015e-01,  3.9594e-01,\n",
      "        -2.7618e-01, -3.8931e-01, -4.0274e-01, -1.6167e+00, -5.3803e-01,\n",
      "         8.4657e-01, -1.2888e+00,  6.8032e-02, -2.0344e+00, -1.1979e+00,\n",
      "        -1.4070e-01, -1.6259e+00, -2.6542e-01,  5.5067e-01, -3.3141e-01,\n",
      "         9.0733e-01,  2.4775e-02, -1.2490e+00, -2.9502e-02,  3.3948e-01,\n",
      "        -6.0957e-01, -2.7840e+00, -9.4870e-01, -1.0262e+00,  1.2745e+00,\n",
      "         4.8812e-01,  2.0229e-01, -9.7506e-02,  1.0950e+00, -1.0176e+00,\n",
      "        -1.0305e+00, -6.4481e-01,  6.4164e-01, -2.9828e-01, -6.4573e-01,\n",
      "         1.3924e+00,  1.8329e+00,  2.3573e-01,  1.5202e-01,  7.8046e-01,\n",
      "         1.8348e+00,  5.7221e-01,  7.9079e-01, -1.6365e+00, -7.2097e-01,\n",
      "        -4.9818e-01, -1.1362e+00, -8.6395e-01, -2.5962e+00,  2.9025e-01,\n",
      "        -1.4630e+00,  9.7318e-01,  1.8503e+00, -9.0954e-01, -1.9161e+00,\n",
      "         3.6747e-01,  4.8166e-01,  8.4021e-01,  8.0009e-01, -1.0457e+00,\n",
      "        -6.1527e-01, -2.2077e-01, -6.4154e-01, -6.8613e-01,  4.8809e-01,\n",
      "         1.0239e+00, -1.2033e+00,  2.4721e-01, -2.5116e+00, -1.1259e+00,\n",
      "         2.1770e-01, -8.7179e-01, -1.3066e+00,  1.1798e-01,  2.2069e-01,\n",
      "        -4.1657e-01, -4.2480e-01,  1.0564e+00,  1.4128e+00, -2.5341e-01,\n",
      "         4.2452e-01,  2.0375e-01,  2.5851e-01,  5.5514e-01, -1.0675e-01,\n",
      "         6.2537e-01,  1.5423e+00,  1.2052e+00, -6.9371e-01, -5.7489e-01,\n",
      "        -1.6547e+00,  3.8874e-01,  4.8932e-01,  5.3868e-01, -3.3492e-01,\n",
      "         3.8575e-01, -4.7486e-01, -4.0958e-01,  1.1256e+00, -1.0248e+00,\n",
      "         5.5547e-01, -3.0076e-01, -9.9239e-01,  1.0192e+00, -1.6432e+00,\n",
      "        -1.4299e-02, -5.4758e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-1.5828, -2.5850, -0.4184, -1.4366,  0.4899,  1.2690,  0.0762, -0.2088,\n",
      "        -0.2807,  1.4218, -1.6907,  0.5848,  0.4817,  1.4945, -0.6189,  1.2972,\n",
      "         0.0674, -0.0747, -0.4317, -0.1685,  0.9797, -1.6274, -0.6748,  0.4099,\n",
      "        -0.5779,  0.3418,  0.3432,  1.2628, -1.2016, -0.7941,  0.8008, -0.1901,\n",
      "        -0.4885,  0.4134,  1.3825,  1.4457, -0.9252, -0.4914, -0.4576,  1.7002,\n",
      "         0.9585,  0.7553, -0.0948,  0.1450, -0.4939,  0.7574, -2.3014, -1.3179,\n",
      "        -1.0397,  0.9058,  0.3476,  1.0643,  0.1655, -1.2083, -1.1139,  0.4503,\n",
      "        -0.5100,  1.6227, -1.3723, -2.4958,  0.0358, -1.1878, -2.1305,  0.5133,\n",
      "         0.1955, -0.2032, -0.3839, -0.0883, -0.4293,  0.3451,  0.2779,  0.3813,\n",
      "         1.0922, -0.5503, -0.1928, -1.5591,  1.5928,  0.3625, -1.3894,  0.7410,\n",
      "        -0.9530, -0.8856, -1.2927, -0.3117, -0.3066, -0.0126,  0.1811,  0.1278,\n",
      "         0.3031,  0.5067, -0.8633, -0.1588,  0.5480, -0.4393, -0.0624, -0.4171,\n",
      "         0.7000, -0.7898, -0.7727, -0.2323,  2.1912, -0.7568, -0.1447, -0.3940,\n",
      "         1.8874, -0.9683,  0.8311,  0.9498,  2.7729, -1.5473,  0.0107, -0.0945,\n",
      "        -0.6174,  0.9125, -0.6663, -0.3886, -0.9036,  0.7050, -0.4302, -0.3134,\n",
      "        -0.9042,  0.8806,  1.4535, -0.7280, -0.4544, -0.0679,  0.8120,  0.1381,\n",
      "         1.8955,  1.0214,  0.6163,  0.4770,  0.4028, -1.9344, -0.4082,  0.5134,\n",
      "         1.1876, -0.9408,  1.6259,  1.4079,  0.0990, -0.1446, -0.8125, -0.9130,\n",
      "        -1.9667,  0.7770, -0.2023,  0.7761,  0.9414, -0.6948,  0.5187, -1.5244,\n",
      "        -0.9573,  2.5048, -0.3807,  0.1852,  0.1889,  0.3015,  0.0398,  2.0591,\n",
      "         1.1935, -0.1493, -0.4827, -1.1698,  0.7542,  0.3112,  1.1759, -0.3157,\n",
      "        -0.9479,  0.5538,  0.0620, -0.2759,  0.8776,  1.7487,  0.6623,  0.1467,\n",
      "         0.5255,  0.6878, -0.4850,  1.1396,  1.1819,  0.3123,  0.0760,  0.0977,\n",
      "        -0.8294, -0.5236, -0.5486, -0.9224,  0.9445,  0.5642, -0.2666, -2.0391,\n",
      "        -1.0619,  0.0532, -0.2695,  1.2224, -0.7397, -0.0030,  0.9943, -0.0245,\n",
      "         0.7209,  0.2041, -0.3528,  0.1138, -1.0456, -1.0203, -0.2492,  1.7174,\n",
      "        -0.0498,  0.4253,  0.5539,  1.5119,  0.4033,  0.0309,  0.9902, -0.5004,\n",
      "         1.2347, -0.9031, -2.3338,  2.0800,  0.2021,  0.7355,  0.1414, -0.5528,\n",
      "        -0.8634,  0.2581, -0.4707,  0.6302, -1.2080,  0.6636, -1.5823, -2.2376,\n",
      "         0.6514, -0.2646,  0.9188,  0.1573, -0.0922, -0.4532,  0.3207,  0.8153,\n",
      "         0.6653,  1.0361,  0.1784, -0.4251, -1.0736, -0.8142, -1.9507, -2.2962,\n",
      "        -0.8754, -0.7089,  0.2072,  1.6705,  1.0408, -0.3692,  1.0904, -1.6921,\n",
      "         0.3758, -0.9309, -0.8446,  0.0804, -0.9621, -1.4788, -1.2969,  1.7944,\n",
      "        -0.9324, -0.1954, -1.7262,  0.0990,  0.5251,  0.3665,  0.5633, -0.0508,\n",
      "        -1.0322,  0.4198,  0.6945, -0.6119,  0.6567,  0.5072,  0.1868,  0.6258,\n",
      "         0.0284, -1.1335,  0.9889,  0.3544,  0.9512, -0.0577, -0.4595, -1.2572,\n",
      "         0.3570, -1.0405, -0.5893,  0.2128,  0.2447, -0.2262,  0.6286, -1.0193,\n",
      "         1.3453, -0.2571,  1.3045,  0.7340, -0.4093,  0.0394,  2.5489, -0.0644,\n",
      "        -0.7820,  0.9673, -0.4993,  0.4136,  0.3636,  0.6402, -2.2121, -0.4092,\n",
      "         0.8483,  1.5174,  1.7731, -0.9300,  0.2929, -0.2923, -1.2141, -0.9003,\n",
      "        -0.9572, -2.4981,  2.1381,  0.0636, -1.7255,  0.7167, -0.1095,  0.0799,\n",
      "        -0.3274, -0.1597, -0.5532, -0.3212,  1.9419, -1.3146,  0.5795, -0.0967,\n",
      "         0.0736,  0.0484, -0.1479,  0.0889,  0.5474,  0.5927,  0.9624,  0.4553,\n",
      "        -0.4383, -0.2208, -0.5395, -0.5973,  0.4655, -0.4649, -0.0671, -0.9617,\n",
      "         0.0676, -0.4749, -0.2652,  1.7372,  2.8410, -0.4673,  0.4714,  1.1061,\n",
      "         0.3491, -0.8600,  0.5664, -0.1018, -1.5382, -0.5899, -0.0456, -0.2153,\n",
      "        -0.3922,  0.0218,  0.0979, -0.8745,  0.8840,  1.8319,  0.3396, -0.1920,\n",
      "         1.0503, -1.2735,  0.6541,  0.4892, -1.0430, -1.6922, -1.6445,  1.3302,\n",
      "         0.0815,  0.5069,  1.0136, -1.0569, -0.1679, -0.1517,  0.0064, -2.4330,\n",
      "         0.5920,  0.7088,  0.0263, -0.0219,  0.4910, -1.7334,  1.1527, -1.2753,\n",
      "        -0.8800,  0.8794, -0.4958,  0.5104, -0.4025,  0.8056,  2.8292, -0.5673,\n",
      "        -1.2021, -0.3201, -0.5742, -1.2168,  1.4681,  2.0476, -1.1091,  1.0665,\n",
      "         1.1632, -0.0253, -0.3468, -0.0065,  0.3165, -0.7493, -1.0977, -0.5913,\n",
      "         1.6626, -0.3426, -1.6241, -0.7627, -0.6986, -0.7392,  1.5739,  1.2055,\n",
      "        -1.3409, -0.6977, -0.3443, -1.7656, -0.1550, -0.0749,  1.1653, -0.3337,\n",
      "        -0.5978, -0.1993, -0.5117, -0.6743,  0.2145, -1.5921,  0.7318, -1.2669,\n",
      "        -0.4003,  0.9041, -0.9971, -1.8852,  0.5888, -0.2214, -0.8071, -0.3920,\n",
      "         0.4100,  0.3823,  1.8321,  0.3763, -1.2166, -1.5916,  2.4214, -0.2978,\n",
      "         0.2680,  0.0908,  0.5556,  0.6589,  1.2538,  0.0254, -0.4505,  0.0394,\n",
      "         0.4848, -0.0898,  0.6251,  0.1655, -0.8924,  1.8206, -0.4292,  1.1566,\n",
      "         0.5127,  0.4901, -0.9831, -0.7782,  1.7233, -1.3599,  0.6642, -0.7032,\n",
      "         0.6932,  0.1401,  1.0949, -0.7925, -1.6023, -0.5686,  0.8661,  1.0545,\n",
      "         0.4710,  0.2157, -2.5942, -0.6999,  0.4272, -1.4660, -0.9969,  0.7555,\n",
      "         1.9208,  0.0485,  1.1973, -0.1755,  1.0845,  1.4210,  0.1811,  1.1691],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([-4.1335e-01,  3.0194e-01, -8.6662e-01, -5.1956e-01,  2.0644e-02,\n",
      "         8.7843e-01,  4.6416e-01, -3.6445e-01,  5.5976e-01,  2.2415e+00,\n",
      "        -1.5920e-01, -1.5543e+00,  4.0056e-01,  1.0187e+00,  9.4412e-01,\n",
      "        -6.4578e-01, -1.3567e+00,  1.1428e+00, -1.2860e+00,  4.2874e-01,\n",
      "         5.8904e-01, -4.8331e-02, -6.7086e-01,  7.2160e-01,  2.7882e-01,\n",
      "        -5.2857e-01,  5.9314e-01,  3.8809e-01, -9.1477e-01, -9.3298e-03,\n",
      "        -1.3226e+00, -3.9493e-01,  1.8224e+00, -1.2021e+00, -2.1620e+00,\n",
      "         9.7691e-01,  9.1869e-01, -1.4267e+00,  3.4721e-01,  8.0544e-01,\n",
      "         2.2163e+00,  4.6547e-02,  1.1199e+00,  2.4461e+00, -3.9709e-02,\n",
      "         6.9700e-01,  5.4505e-02, -1.2430e+00,  9.6754e-02,  1.5747e+00,\n",
      "         2.5621e-01,  5.5351e-01,  9.3672e-01,  3.2950e-01, -2.7166e-02,\n",
      "         6.3785e-01,  9.3300e-01,  1.0223e+00, -3.6151e-01, -5.4905e-01,\n",
      "        -1.1431e+00, -1.9924e-01, -3.2397e-01, -1.1236e+00, -2.6307e-01,\n",
      "        -5.1192e-01,  6.0801e-01, -6.7362e-01,  1.0835e+00,  6.4580e-01,\n",
      "        -3.8988e-01,  1.3635e+00,  5.1380e-01, -1.7313e+00,  8.1522e-01,\n",
      "        -1.0845e+00,  7.7664e-01, -6.8341e-02, -9.3345e-01, -2.3089e-01,\n",
      "        -4.5868e-01, -3.0104e-01,  2.4353e-01, -1.4776e+00,  9.6629e-01,\n",
      "        -5.1185e-01, -8.7357e-03, -5.6503e-01, -1.2521e-01, -8.0175e-01,\n",
      "        -1.8740e+00, -1.8989e+00,  3.9713e-01, -8.2771e-01,  4.5705e-02,\n",
      "         4.7766e-01,  1.1524e-01,  1.2772e+00, -9.5006e-01,  1.3849e+00,\n",
      "        -2.4613e+00,  1.2244e+00,  1.1899e-01, -7.2924e-01,  5.8722e-01,\n",
      "        -1.1759e+00,  1.6305e+00, -1.4126e+00, -6.6637e-01,  3.5115e-02,\n",
      "         5.9192e-01,  8.5371e-01, -5.4469e-01, -2.3474e-01,  1.5379e-01,\n",
      "        -1.0321e+00, -4.1937e-01,  2.4457e+00, -6.9040e-01, -6.0176e-04,\n",
      "         7.1143e-01, -1.3871e+00,  1.2326e+00,  7.2407e-01, -3.6976e-01,\n",
      "        -9.9232e-01,  1.3184e+00,  3.7834e-01,  6.5659e-01, -1.4258e+00,\n",
      "         4.6254e-01,  1.3403e+00, -6.5844e-01,  3.6992e-01, -1.9558e-01,\n",
      "        -7.5600e-01,  5.0978e-02, -8.0274e-02, -1.8317e+00,  1.3535e-01,\n",
      "        -2.1433e-01,  1.7002e+00,  5.2727e-01,  4.1556e-01,  2.8203e-01,\n",
      "        -4.0308e-01, -5.1460e-01, -1.0282e+00,  9.1132e-01, -6.9203e-01,\n",
      "         9.5491e-01, -4.8312e-01, -2.0151e+00,  3.9984e-01, -3.9439e-01,\n",
      "         1.1244e-01, -1.3616e+00,  2.8091e-01,  4.8651e-01,  1.9647e+00,\n",
      "         1.1098e+00,  1.4086e-01, -9.8093e-01, -1.4961e-01,  1.8313e+00,\n",
      "        -4.8995e-02,  3.6877e-02,  6.6078e-01, -3.3763e-02, -1.3888e-02,\n",
      "        -2.0514e+00,  5.6821e-01,  7.6813e-02,  1.5756e+00,  3.0344e-01,\n",
      "         5.2650e-01,  1.9541e-02,  5.2943e-01, -7.8409e-02, -3.7240e-01,\n",
      "        -9.0894e-01, -4.2264e-01, -2.0834e+00, -1.4424e+00, -1.5131e+00,\n",
      "        -1.6616e-01,  1.9593e+00,  9.1752e-01,  2.0256e-01,  2.1732e+00,\n",
      "        -2.0630e+00,  2.9367e-01,  2.2575e+00, -1.2909e+00,  5.4846e-01,\n",
      "        -6.8178e-01, -1.4412e-01, -8.6090e-01,  2.0179e-02, -5.0194e-02,\n",
      "        -1.0183e+00,  5.0720e-01,  9.9006e-01,  1.6785e+00,  1.8008e-01,\n",
      "         1.1972e+00, -2.1119e+00,  1.7205e-01, -1.4419e+00,  2.4696e-01,\n",
      "        -3.8177e-02,  2.2978e-01,  1.8492e+00, -1.4650e+00, -4.7577e-01,\n",
      "        -4.8931e-01, -9.5392e-02, -1.4543e+00,  4.0232e-01, -9.6220e-01,\n",
      "        -3.2430e-01, -3.5116e-01, -1.3372e+00,  4.3064e-01,  9.9846e-02,\n",
      "        -7.0995e-01, -1.1239e+00,  1.2466e+00, -1.2288e+00, -1.4926e+00,\n",
      "         3.3931e-01, -2.8187e-01,  8.7579e-01,  6.8007e-01, -5.6920e-01,\n",
      "        -9.9680e-01, -8.4879e-01, -1.2740e+00,  7.0993e-01,  8.6184e-01,\n",
      "        -5.8467e-01, -6.3103e-01, -4.1728e-01,  2.4824e+00, -4.5224e-01,\n",
      "         1.4914e-01, -2.1037e-01, -9.5287e-01,  1.6116e-01, -4.9333e-01,\n",
      "        -4.5950e-01,  9.8948e-01,  9.6986e-01, -5.0328e-01,  1.3626e-01,\n",
      "        -5.7057e-01,  2.3906e-01,  3.8331e-01, -1.3116e+00, -1.2842e+00,\n",
      "         1.2588e+00, -1.2924e-01,  1.0400e-01, -1.9237e+00, -1.1332e-02,\n",
      "         1.2617e+00,  6.1810e-01,  1.0584e-01,  9.6540e-01,  1.4493e-01,\n",
      "         3.8850e-01, -1.9402e+00,  8.3756e-02, -2.4229e-01,  8.7467e-01,\n",
      "         9.2331e-01,  6.0489e-01,  5.0711e-01,  8.4319e-02,  2.8285e-01,\n",
      "         1.3660e-01, -1.9480e-01,  3.3564e-01,  6.0156e-01,  1.5566e+00,\n",
      "        -4.6052e-01, -1.3313e-01, -4.3425e-01, -2.1645e-01, -4.5560e-01,\n",
      "         1.1711e-02, -3.8922e-01,  1.2593e+00, -9.5279e-01,  4.8343e-01,\n",
      "        -1.1958e-01, -1.8046e-01, -2.3377e+00,  9.3903e-01, -2.9313e-01,\n",
      "         1.5197e+00, -2.5872e-01,  1.2901e+00,  4.8193e-01, -5.1689e-01,\n",
      "         2.4458e-01, -4.6502e-01,  4.7922e-01,  5.2395e-01, -8.5800e-01,\n",
      "         2.5151e-01, -9.2566e-01,  5.7566e-01,  1.7971e+00, -1.3775e+00,\n",
      "        -3.0756e-01,  1.0986e+00,  1.3814e+00, -1.0144e+00,  2.1327e+00,\n",
      "         8.4659e-01,  3.7139e-01,  1.9258e+00, -1.6683e+00, -2.9113e-01,\n",
      "        -1.0880e+00, -7.8000e-01, -1.2050e+00, -7.9468e-01, -1.6691e+00,\n",
      "         9.9575e-01, -1.0240e+00,  6.0198e-01, -4.1158e-01,  5.6293e-01,\n",
      "        -6.3020e-03, -1.3453e-03, -3.4628e-02,  1.6458e-01, -1.2524e+00,\n",
      "         1.1385e+00,  1.6364e+00,  6.4809e-01, -2.6707e-03, -3.6337e-01,\n",
      "         4.8156e-01, -5.3286e-01,  1.6644e+00, -3.5725e-01, -2.9376e-01,\n",
      "        -1.7470e+00,  2.0427e+00, -1.0019e+00, -1.0024e+00, -3.0126e-01,\n",
      "         1.0444e+00, -6.1765e-01, -9.9216e-01,  6.3791e-01, -1.6509e+00,\n",
      "        -8.8304e-03, -9.0588e-02, -1.0946e+00, -3.1794e-01, -5.4478e-01,\n",
      "        -1.4985e+00,  4.6722e-01, -1.8330e+00, -7.8114e-01, -3.6914e-01,\n",
      "        -1.1258e+00,  1.4083e-01, -2.4867e-01,  4.3832e-01, -3.1052e-01,\n",
      "        -3.4069e-01, -2.6882e-01,  1.5560e+00,  7.1809e-02,  6.4502e-01,\n",
      "        -7.8866e-02, -2.8762e-01, -1.1773e-02, -9.7713e-02,  1.2261e+00,\n",
      "        -1.2088e+00, -2.3335e-01, -1.4423e+00, -7.1285e-01,  8.3110e-01,\n",
      "         2.8207e-01,  1.0377e+00,  1.3427e+00, -6.4276e-02,  9.1108e-01,\n",
      "         1.8732e-01, -2.2964e-01, -1.1929e+00, -6.7086e-01, -1.7078e-01,\n",
      "        -1.3651e+00, -8.7463e-01,  5.2636e-02,  7.4194e-01, -2.1247e-01,\n",
      "         1.7840e+00,  1.2896e+00,  8.1151e-01, -1.8439e+00,  1.1458e+00,\n",
      "         3.7538e-01, -2.0001e+00,  2.0142e-01,  2.7754e-02,  1.6740e+00,\n",
      "        -1.2785e+00,  7.4206e-01, -2.8672e-01,  1.4824e-01,  3.2577e-01,\n",
      "        -1.4911e+00,  1.2554e+00, -1.9318e-01, -2.8900e+00, -2.8427e+00,\n",
      "        -7.8476e-02,  1.2897e+00,  1.0982e+00, -4.1798e-01,  1.7098e-01,\n",
      "         6.5278e-01, -8.3212e-01,  1.2142e-01, -1.6468e+00, -1.6267e+00,\n",
      "        -3.0198e-02,  9.4695e-01,  4.7775e-01, -6.6321e-01, -1.1824e+00,\n",
      "         3.9484e-02, -9.9277e-01, -1.0724e-01,  2.0841e-01, -8.3189e-02,\n",
      "         9.2519e-01, -1.6020e+00, -5.6388e-01, -1.8250e+00,  8.1990e-01,\n",
      "         1.0130e+00, -1.4518e+00, -1.5830e-01,  3.6712e-01, -8.3498e-01,\n",
      "         7.5342e-01, -2.6071e-01,  1.3795e+00, -1.6581e+00, -1.6116e+00,\n",
      "         1.6775e-01,  1.8619e-01,  2.4087e-01, -1.0784e+00, -7.2980e-01,\n",
      "         4.9069e-01, -9.0804e-01, -1.2049e+00,  7.9558e-02,  1.0112e+00,\n",
      "         1.1919e+00, -2.8646e-01,  1.8098e+00, -7.7600e-01,  7.4352e-01,\n",
      "        -6.7261e-02,  4.2826e-01, -1.4841e-01,  2.2695e-02, -1.0356e+00,\n",
      "        -1.2856e-01,  9.0108e-01,  2.5476e+00, -5.5252e-01, -1.3899e+00,\n",
      "         4.0998e-01, -7.2052e-01, -3.3714e-01,  1.1965e+00,  1.8183e-01,\n",
      "        -2.4641e-01, -2.4035e-01, -1.2380e+00, -4.7481e-01,  2.5771e-01,\n",
      "        -2.3005e+00,  3.0100e-01,  1.0530e+00,  1.4244e+00, -1.6358e+00,\n",
      "         1.5540e+00,  8.2757e-01,  1.2252e+00, -3.5348e-01,  1.1624e+00,\n",
      "         3.1833e-01,  1.0952e+00, -5.9730e-01, -4.4952e-01, -2.6347e-01,\n",
      "         1.1804e+00,  1.1398e+00], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 6.8959e-01,  1.9578e-01, -2.7348e-02, -1.0140e+00, -2.7087e-01,\n",
      "         5.4964e-01,  6.4762e-01,  5.6917e-02, -2.4305e-01,  3.3667e-01,\n",
      "         1.3997e+00, -5.7851e-01,  4.8028e-01,  7.8750e-01, -1.4634e-01,\n",
      "         1.1515e+00,  3.7908e-02,  1.3175e+00,  1.5857e-01,  3.2813e-01,\n",
      "         2.2909e+00, -2.3603e-01, -2.0880e-01,  1.9747e+00,  4.5371e-01,\n",
      "         1.4964e+00, -7.2664e-01, -3.2924e-02, -1.2290e+00, -5.8619e-01,\n",
      "        -1.3075e+00, -9.2281e-01, -2.5965e-01,  8.7289e-01, -7.9056e-01,\n",
      "         1.7694e-01, -1.1409e+00, -7.0447e-01,  3.3018e-01, -1.3882e-01,\n",
      "         6.8301e-01,  9.0442e-01,  1.2863e+00,  3.7828e-01,  4.6970e-01,\n",
      "         3.1867e-01,  1.0424e+00,  6.3944e-01,  8.7179e-01, -6.1918e-01,\n",
      "        -9.3955e-01, -1.5795e-01, -6.6081e-02, -2.1641e-01, -4.0505e-02,\n",
      "        -2.4814e-02,  8.4200e-01,  1.1062e-01,  6.6414e-02, -8.3811e-01,\n",
      "         9.2452e-01, -1.0713e+00,  1.6362e-02, -1.0721e+00,  1.9611e+00,\n",
      "        -2.2817e+00, -1.3223e+00,  1.1526e+00,  9.2941e-01,  1.7352e+00,\n",
      "         1.5129e+00,  5.8977e-02, -3.6364e-01, -5.9913e-01, -6.6114e-01,\n",
      "        -2.7857e-01,  1.1156e+00, -1.8345e+00, -9.0540e-01, -6.8619e-01,\n",
      "         1.2540e+00,  7.2345e-01, -2.9085e-01, -2.9677e-01,  3.0626e+00,\n",
      "         5.7196e-01,  1.1529e-01,  4.1032e-01, -5.8531e-01,  1.4687e-01,\n",
      "         2.4253e-01, -3.7265e-01, -1.4957e+00,  3.1341e-01,  9.7644e-01,\n",
      "         1.2833e-01,  1.1179e+00, -1.3103e-01, -6.7962e-01,  8.4076e-01,\n",
      "        -2.2091e+00, -1.0951e-01,  1.3998e+00, -5.9847e-01, -9.6521e-01,\n",
      "         5.9842e-01,  1.3621e+00, -8.2915e-01,  6.9307e-01,  1.8260e+00,\n",
      "        -2.0677e-01,  1.5691e+00,  1.3443e+00,  5.6282e-01,  1.1590e+00,\n",
      "        -8.2495e-01, -2.9446e-02, -1.6363e+00,  7.1992e-01,  1.1467e+00,\n",
      "         1.3139e+00, -1.0070e+00, -7.9134e-01,  5.4269e-02,  6.0076e-01,\n",
      "         6.3374e-01,  2.4810e-01,  2.5725e-01,  1.3358e+00, -3.8166e-01,\n",
      "        -6.9914e-02, -8.9404e-03, -2.9113e-01, -1.6915e+00, -9.8418e-02,\n",
      "        -1.2081e+00,  3.6249e-01,  9.9006e-01,  1.6060e-01,  7.0385e-01,\n",
      "         1.5001e-01,  1.0924e+00, -6.1860e-01,  4.0496e-01,  1.7699e-01,\n",
      "         1.6225e+00,  6.3249e-02, -1.7781e-01,  1.2013e+00,  1.6996e+00,\n",
      "         1.1363e-01, -1.1313e+00,  1.6454e+00, -3.9534e-01,  7.2792e-01,\n",
      "        -3.5912e-01,  9.2930e-01, -4.4443e-01, -8.3078e-01,  1.3855e+00,\n",
      "        -5.3391e-01,  3.0963e+00, -1.5767e-01, -1.2676e+00, -8.1141e-01,\n",
      "        -1.7722e+00, -2.0941e-01,  5.2635e-01, -6.7627e-01,  8.2310e-01,\n",
      "         1.9325e-01, -1.5507e+00,  3.8287e-01, -3.4627e-01,  8.3732e-02,\n",
      "        -5.0375e-01,  3.2760e-01, -7.8361e-01,  2.2861e-01, -1.0347e+00,\n",
      "        -1.9505e-01, -5.0762e-01, -1.2952e+00, -2.2829e-01,  8.0824e-01,\n",
      "        -4.8287e-01, -7.6719e-01, -1.1979e+00,  1.0106e+00,  7.0537e-02,\n",
      "         1.9508e-01,  1.3228e+00,  1.2068e+00,  2.5613e-01, -1.0229e+00,\n",
      "         5.6795e-01,  1.5514e+00,  9.4147e-01,  2.7394e-01,  1.1641e-01,\n",
      "        -9.9636e-01,  8.6735e-01,  1.6688e-01, -1.4639e+00, -4.0940e-01,\n",
      "        -1.2389e+00,  5.5241e-02,  8.9772e-01,  3.5854e-02,  9.3296e-01,\n",
      "        -3.7601e-01, -1.1234e+00, -1.7732e+00, -4.4943e-01,  2.4546e-01,\n",
      "        -5.4883e-01,  7.3157e-01,  2.8268e-01,  3.9225e-01,  3.0489e+00,\n",
      "         2.6713e+00,  1.0702e+00, -8.8865e-01, -1.3777e+00, -1.4461e+00,\n",
      "        -9.4731e-01,  6.6618e-01, -1.7636e-01, -1.3917e+00, -9.1205e-01,\n",
      "        -1.8485e+00, -7.4824e-02, -1.9752e-01,  9.0524e-01, -4.0007e-01,\n",
      "        -3.1437e-02,  2.0418e+00, -2.9156e+00,  2.9400e-01,  8.0135e-03,\n",
      "        -4.3569e-01,  2.6242e-01, -1.1589e+00,  2.6331e-01,  1.5692e+00,\n",
      "        -1.9539e+00,  1.2078e+00, -1.6457e+00,  7.3462e-01, -1.9357e+00,\n",
      "         6.4377e-01, -2.8388e+00,  5.2163e-01,  4.6839e-01, -7.0089e-01,\n",
      "        -8.9434e-01,  2.0291e-03,  1.4223e+00,  1.0761e-01,  4.3142e-01,\n",
      "        -5.1610e-02,  4.7491e-01, -2.7326e-01, -5.8714e-01,  6.0114e-01,\n",
      "        -2.4824e-01,  4.3042e-02,  7.1157e-01, -1.1419e+00,  4.9362e-01,\n",
      "         1.1753e+00,  6.9426e-01, -1.8828e+00,  1.6005e+00, -1.0271e+00,\n",
      "        -5.8610e-01,  3.6323e-01, -5.1944e-01, -1.2805e+00, -5.3928e-01,\n",
      "         2.8997e-01, -2.4934e-01, -2.3912e-01, -6.5801e-01,  2.2165e+00,\n",
      "         2.6942e-01,  5.5633e-01, -1.6952e+00, -8.2189e-02, -9.9941e-01,\n",
      "         1.1807e+00, -8.3562e-01, -1.5650e+00,  7.4209e-01, -2.9089e-01,\n",
      "        -5.5114e-01, -5.6004e-01,  7.9492e-01, -2.1742e+00, -1.4349e+00,\n",
      "         9.4938e-01,  9.6071e-01, -1.4162e+00, -1.0776e+00,  6.5685e-01,\n",
      "        -1.7579e+00,  1.2082e+00,  1.4852e+00,  1.1027e+00, -2.1240e-01,\n",
      "         9.1257e-01,  7.7422e-01, -4.2610e-01,  8.6209e-01,  1.2364e+00,\n",
      "        -5.4831e-01,  1.5830e+00, -8.1045e-01, -9.3045e-01,  1.0953e+00,\n",
      "        -5.5514e-01, -2.1822e+00,  3.7085e-02, -8.0933e-01, -8.7608e-01,\n",
      "         9.5839e-01, -9.7323e-01,  4.4357e-01,  2.0998e-01,  8.4564e-01,\n",
      "        -1.1228e-01, -1.2183e-01,  7.3444e-01,  6.9224e-02, -1.8260e-01,\n",
      "         2.2683e+00,  3.3947e-02, -3.0931e-01, -1.5742e+00, -2.8988e-01,\n",
      "         2.3535e+00, -1.2900e+00,  8.7987e-01,  2.9074e-01, -1.0320e-01,\n",
      "         6.3080e-01,  6.1236e-01, -9.3849e-01, -5.2639e-01, -4.3571e-02,\n",
      "        -2.4483e-01,  1.2576e+00, -3.3036e-01, -1.4637e+00, -1.8021e+00,\n",
      "        -2.3595e-01, -2.4871e+00, -4.2259e-01, -1.0910e+00, -4.9351e-01,\n",
      "         1.7933e+00, -2.4389e-01, -3.6292e-01,  8.9720e-01, -1.7324e+00,\n",
      "        -8.9076e-02, -5.2670e-01, -1.2729e-01, -8.1000e-01, -4.8999e-01,\n",
      "         8.8614e-01,  2.2695e-01,  2.8627e-02, -1.2875e+00,  4.3302e-01,\n",
      "         1.1309e+00,  8.1072e-01,  4.9472e-01,  1.9056e+00,  8.3826e-01,\n",
      "         1.2243e-01,  2.2297e-01,  5.8859e-01, -1.0834e+00, -7.3375e-03,\n",
      "        -5.4179e-01,  1.8360e+00,  7.4176e-01, -8.3887e-01,  1.2348e+00,\n",
      "        -1.0221e+00,  9.7006e-01, -1.3325e-01,  3.5118e-01,  1.1261e-01,\n",
      "         2.4538e+00, -2.8221e-01,  7.9512e-01,  6.1134e-01, -3.2783e-01,\n",
      "        -2.7133e-01,  1.7692e+00,  2.2080e-01, -1.6375e+00, -1.5998e+00,\n",
      "         4.7948e-01, -3.6392e-01,  7.0572e-02, -1.0655e+00,  2.9926e-01,\n",
      "         1.1933e+00, -4.8968e-01, -1.6400e-02, -1.6562e+00, -1.7258e+00,\n",
      "        -1.6327e+00, -5.2549e-02, -1.3954e-03, -9.2572e-01, -8.4890e-01,\n",
      "         1.1737e+00, -8.6506e-03,  2.5049e-01,  2.3216e-01, -1.7140e-01,\n",
      "         1.4050e+00, -3.3479e-01, -2.7174e-02, -1.4063e+00, -3.5870e-01,\n",
      "         1.4133e+00,  1.0158e+00,  4.7641e-01, -2.0241e+00,  1.4922e+00,\n",
      "         1.5014e+00,  9.2783e-01,  9.9409e-01,  1.1670e-01,  6.0830e-01,\n",
      "        -1.8123e-01,  7.2458e-01,  1.5259e+00, -6.8250e-01, -6.3551e-02,\n",
      "        -1.3010e-01,  8.7836e-01, -1.5129e+00,  2.1785e+00, -1.5566e+00,\n",
      "        -7.9806e-01, -1.2679e+00, -2.7267e+00, -1.7204e-01, -3.4798e-02,\n",
      "        -1.5537e-01, -1.4328e+00,  2.9090e-01,  1.5268e+00, -1.5308e+00,\n",
      "         1.3139e-01, -3.6066e-02,  1.1716e+00, -1.6313e+00, -9.9574e-01,\n",
      "         9.2461e-01,  5.0857e-01,  1.4311e+00,  1.8388e-01,  2.8582e-01,\n",
      "        -1.7209e+00, -1.1425e+00, -1.3228e+00, -2.5200e+00, -2.0980e-01,\n",
      "         1.5647e+00,  5.9821e-01,  8.5884e-01, -8.6424e-01, -1.5175e+00,\n",
      "         4.2683e-01,  6.4841e-01, -4.6104e-01,  6.0117e-01, -1.2615e+00,\n",
      "        -1.2289e+00,  8.9144e-01, -3.3520e-01,  6.7347e-01, -9.7040e-01,\n",
      "        -3.1997e-01,  5.5413e-01, -1.7189e+00, -2.0284e+00, -8.5971e-01,\n",
      "        -1.7601e+00, -7.6058e-01, -8.5098e-02, -1.0292e+00, -1.7046e+00,\n",
      "         2.2797e+00,  2.3535e-01, -8.3762e-01,  9.3960e-01, -1.4121e+00,\n",
      "         1.7506e+00, -3.6442e-01, -7.7617e-02, -3.3592e-01, -1.5553e+00,\n",
      "         4.3025e-01, -1.2178e+00], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n",
      "p_h: tensor([ 1.3378e+00, -1.7574e+00,  7.7895e-01,  1.3577e+00,  4.5171e-01,\n",
      "         1.1284e+00, -2.7932e-01,  1.2496e+00,  4.3491e-01, -2.5349e+00,\n",
      "         1.0216e+00, -1.4387e+00, -1.5672e+00,  2.3250e-02, -1.6154e+00,\n",
      "        -6.6138e-01, -3.8621e+00,  6.8692e-03, -1.5035e+00,  3.1686e-01,\n",
      "        -9.5652e-01,  1.0628e+00,  2.2072e-01,  1.5761e+00,  3.6322e-01,\n",
      "         5.0772e-01,  2.5195e+00,  4.8471e-01, -1.7560e+00, -2.2407e+00,\n",
      "        -4.2652e-01, -5.3035e-01,  6.3301e-01,  1.7405e-01,  1.2252e+00,\n",
      "         1.0494e+00,  5.6955e-01,  5.0624e-01,  2.6796e-01,  6.0135e-02,\n",
      "         3.2632e-01, -1.1963e+00,  1.0301e-01,  1.1652e+00, -1.6620e+00,\n",
      "        -7.0642e-02,  1.0514e-01, -9.0798e-01, -7.8326e-01,  6.7686e-01,\n",
      "         1.8613e-01,  4.1161e-02, -5.0892e-01, -1.8839e-01,  6.6431e-01,\n",
      "         4.6446e-02,  3.7530e-01, -6.1265e-01,  1.6858e+00, -1.4189e+00,\n",
      "         2.2138e+00,  1.1727e+00,  1.0900e+00, -2.5804e-01, -8.6108e-01,\n",
      "         6.9648e-01,  1.4779e+00, -1.5208e+00, -3.7577e-01,  1.4037e-01,\n",
      "        -1.1886e+00, -3.5453e-01,  1.1596e+00, -4.4908e-01,  2.4077e-02,\n",
      "        -4.7661e-01, -7.0983e-01,  2.1009e+00, -8.5975e-01, -3.3839e-01,\n",
      "        -6.0363e-01, -5.1800e-01, -2.8580e-01,  2.0152e+00,  7.9156e-01,\n",
      "         6.3754e-01,  8.5429e-01, -2.4498e-01,  1.6545e+00, -1.5117e-01,\n",
      "         1.4007e-01, -2.6312e+00, -6.5414e-01, -1.8427e+00, -3.1251e-01,\n",
      "        -1.0768e-01,  6.6724e-01, -1.1217e+00, -2.5941e-01, -8.1249e-01,\n",
      "         9.5356e-02,  1.4450e-01,  5.5018e-01, -3.6192e-01,  1.1870e-02,\n",
      "        -1.1086e+00,  1.2545e+00, -8.4202e-01, -4.3636e-01, -4.5583e-01,\n",
      "        -2.0012e+00, -2.8281e-01, -1.1568e+00,  9.8183e-01,  7.8300e-01,\n",
      "        -1.1552e+00,  1.4923e-01,  2.8632e-01,  2.3063e-01,  1.2845e+00,\n",
      "         6.1095e-01, -7.8545e-01, -1.2078e-01, -9.8488e-02,  2.1548e-01,\n",
      "        -9.6518e-01,  7.1351e-01,  3.3677e-01,  1.7538e-01,  6.9063e-02,\n",
      "         4.4733e-01,  6.0638e-01,  9.8120e-01, -1.3219e+00, -5.2896e-01,\n",
      "         9.2822e-01,  5.8993e-01,  3.1405e-02,  1.3448e+00, -7.8238e-01,\n",
      "        -1.4276e+00,  1.9365e+00, -3.5776e-01, -6.6423e-01, -7.4555e-01,\n",
      "         6.9599e-03, -3.1355e-01, -1.9865e-01,  1.7057e+00, -3.2092e-02,\n",
      "        -6.3207e-01,  5.4329e-01, -2.2011e+00, -2.9281e-01, -6.2251e-01,\n",
      "        -4.5056e-01,  2.0766e-01, -1.7941e-01, -8.9957e-01, -1.5458e+00,\n",
      "         7.7318e-01, -1.5648e+00, -1.5364e+00,  1.3754e+00,  1.2520e+00,\n",
      "        -2.1418e+00, -7.1237e-01,  6.0374e-02,  6.0233e-01, -5.2959e-01,\n",
      "        -3.4130e-01,  9.4965e-01,  1.9413e-01,  8.3097e-01,  8.1046e-01,\n",
      "         5.5241e-01,  7.0747e-01,  2.3037e+00, -8.6772e-01, -2.3979e-01,\n",
      "        -8.1892e-01,  5.6773e-01,  2.0453e+00, -1.0734e+00, -4.8652e-01,\n",
      "        -8.9261e-01,  2.4075e-01, -2.4669e-01, -1.2215e+00,  5.6063e-01,\n",
      "        -3.6845e-01,  3.3333e-02, -3.1855e-01, -1.9889e+00, -6.4225e-01,\n",
      "        -1.2166e-01, -1.8008e-01,  1.2227e+00,  7.6009e-01, -3.3177e-01,\n",
      "         7.3803e-01,  5.9317e-02,  4.4425e-01,  1.5398e-01, -3.8847e-01,\n",
      "        -1.6201e+00,  8.6881e-01, -5.8047e-01,  1.8975e-01,  7.4270e-01,\n",
      "         9.4042e-01,  4.6618e-01, -1.1321e+00,  8.0418e-01,  1.8335e-01,\n",
      "         2.3918e+00, -1.7638e+00,  5.6224e-02,  1.5096e-01, -6.9073e-01,\n",
      "        -1.1218e+00, -7.8060e-01,  1.1894e+00,  1.9596e+00,  2.4884e-01,\n",
      "         1.6411e-01,  1.1601e+00,  1.2505e-01,  7.7287e-01, -4.1172e-01,\n",
      "        -1.3936e+00, -4.3792e-01, -4.6844e-01,  1.5951e+00,  2.1082e+00,\n",
      "        -2.0321e+00,  7.5155e-02,  2.2223e-02,  2.5685e-01,  1.7453e-01,\n",
      "         1.9502e+00,  1.6271e-01, -6.2299e-01, -4.2443e-01,  3.9486e-01,\n",
      "         1.3730e-01,  2.6352e-01,  9.1788e-01,  6.2602e-02,  5.0478e-01,\n",
      "         2.6247e-01, -1.5821e-01,  1.0857e+00, -1.3168e+00,  1.2502e+00,\n",
      "        -5.6213e-01,  1.0366e-01,  1.4524e+00,  6.5711e-01, -7.0969e-01,\n",
      "        -1.1807e+00, -6.9832e-01, -1.2348e+00, -9.7450e-01, -9.8426e-01,\n",
      "        -1.3555e+00, -1.0456e+00, -6.9710e-01,  3.7179e-01, -5.9176e-01,\n",
      "        -3.7158e-01,  3.8953e-01,  1.5409e+00,  2.7630e-01,  1.6572e+00,\n",
      "        -1.3497e+00,  8.3813e-02,  1.3991e+00,  6.0334e-01, -1.7363e+00,\n",
      "         1.3401e+00,  8.1319e-01, -7.1918e-01,  1.5897e-01, -4.9626e-01,\n",
      "        -1.4756e+00,  1.8016e+00, -5.7496e-01, -2.4098e-01, -1.0227e-01,\n",
      "         4.9541e-01, -5.2977e-01, -1.0464e+00, -1.1109e+00, -1.1866e-01,\n",
      "        -1.5160e+00,  6.9261e-01,  7.8567e-01,  9.2497e-01, -1.8673e+00,\n",
      "        -1.7981e-01, -7.8807e-01,  1.0675e+00, -5.4632e-01, -1.3145e+00,\n",
      "         1.5859e-01,  9.9035e-01, -2.8716e-01,  1.3887e+00,  2.7852e+00,\n",
      "         1.4667e+00, -2.1630e-03,  1.3122e-01, -4.4082e-01,  1.4388e+00,\n",
      "         2.7012e-01,  1.8311e-01,  8.7286e-02,  7.0655e-01,  8.5583e-02,\n",
      "        -8.0453e-01,  4.9520e-01, -4.5858e-02,  1.4293e-01,  1.3324e-01,\n",
      "        -7.6789e-01,  1.2833e+00, -1.5717e+00,  3.7064e-01, -6.9137e-02,\n",
      "        -2.3351e-01, -1.0496e+00, -7.1519e-01, -3.1503e-01,  2.4134e-01,\n",
      "        -2.1327e+00, -7.0920e-02, -8.5889e-01, -2.1502e-01, -3.9418e-01,\n",
      "        -1.7573e+00,  5.0271e-01, -1.8717e+00, -2.8780e-01,  1.0373e+00,\n",
      "        -1.9540e+00, -2.8975e+00, -3.7805e-02,  5.9749e-01,  1.8649e+00,\n",
      "        -1.8234e-01,  8.9876e-02,  1.0113e+00, -1.0590e+00, -2.5694e+00,\n",
      "        -3.6618e-01,  1.1363e+00,  2.9621e+00, -6.4946e-01,  5.2534e-01,\n",
      "         8.5458e-01,  1.1530e-01,  7.4480e-01, -9.1495e-01, -3.4917e-01,\n",
      "         8.2525e-01, -4.6126e-01, -6.1585e-01,  5.0931e-01, -1.4049e-01,\n",
      "         4.4019e-02,  1.9994e+00,  1.2511e+00,  9.2711e-01, -9.3070e-01,\n",
      "         1.2189e+00, -1.4664e+00,  2.0946e-01,  8.3740e-01, -1.1316e+00,\n",
      "         2.1325e+00,  3.0934e-01,  2.4597e-01,  1.5155e+00, -5.9255e-01,\n",
      "        -7.1502e-01,  5.6260e-01,  1.3257e+00,  3.0931e-02,  1.9564e+00,\n",
      "         2.6448e+00, -9.7250e-01,  2.9212e-01, -6.0533e-01,  2.0877e+00,\n",
      "        -2.0522e-01, -3.7066e-01,  4.1269e-01, -1.5873e+00, -3.8223e-01,\n",
      "         4.5748e-01,  1.7029e+00, -1.8429e+00,  9.2457e-01,  5.1284e-01,\n",
      "         6.6726e-01,  1.1963e+00, -5.0064e-01, -5.3246e-01,  6.9767e-01,\n",
      "        -4.8854e-01,  3.4013e-01,  2.7424e-01, -7.0709e-02,  1.1260e+00,\n",
      "        -1.4537e-01, -1.4229e+00, -1.7384e+00,  2.6901e-01, -6.3280e-02,\n",
      "         1.5646e-01,  8.9145e-01, -2.0361e+00, -1.2101e+00,  5.3662e-01,\n",
      "        -2.0959e+00, -5.4110e-01,  8.2315e-01, -4.3355e-02,  2.1027e-01,\n",
      "        -7.0236e-01,  3.1297e-01,  2.1490e+00, -3.8548e-01, -9.6717e-01,\n",
      "        -5.9997e-01, -3.0140e-01, -7.4357e-01,  1.5301e+00, -3.1532e-01,\n",
      "        -1.1947e+00,  1.4834e+00, -9.0908e-01, -1.1689e+00, -6.1742e-01,\n",
      "         4.5516e-01, -1.5063e+00, -3.1754e-01,  5.9486e-01,  5.6021e-01,\n",
      "         2.5182e-01, -6.8701e-01, -1.1398e+00, -9.4239e-01,  6.2022e-01,\n",
      "        -1.7724e-01, -5.4568e-01,  5.6724e-01, -3.2044e-01,  7.9431e-01,\n",
      "        -8.1198e-01,  1.9527e+00, -1.5011e+00, -1.1080e+00, -1.4306e+00,\n",
      "         3.5481e-02, -2.3049e-02, -1.6953e-01,  2.3860e+00,  1.0630e+00,\n",
      "        -1.4932e+00,  2.5329e-01, -5.7798e-01,  1.5582e+00,  6.9588e-01,\n",
      "        -8.9027e-02,  1.6316e+00, -1.0228e+00,  1.8693e-01,  1.2849e+00,\n",
      "        -9.6505e-02,  8.0098e-01, -1.3400e+00,  9.5497e-01,  1.7876e+00,\n",
      "         2.4873e-02,  7.3946e-01, -1.8697e-02,  4.0401e-01, -9.1567e-01,\n",
      "         8.5603e-01, -3.4786e-01,  3.7784e-02, -1.7795e-01, -7.3329e-01,\n",
      "        -3.4399e-02, -4.4117e-01,  9.1771e-01,  1.8784e+00,  4.8392e-01,\n",
      "        -4.4497e-01, -7.7221e-01,  2.7877e-01, -7.6384e-01,  1.5674e+00,\n",
      "         7.4855e-01, -7.2604e-01,  5.0055e-01,  5.9569e-01,  4.2833e-01,\n",
      "         7.1239e-01, -6.6702e-01], grad_fn=<UnbindBackward0>)\n",
      "p_h shape: torch.Size([512])\n",
      "context_s shape: torch.Size([512])\n",
      "context_e shape: torch.Size([512])\n",
      "torch.Size([1536])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1, 186, 1536])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Experiment for SBO Objective Function \n",
    "    - 1) concatenate context_s, contex_e, span_pos_emb\n",
    "    - 2) reassign h tensor value to each index of tensor\n",
    "\"\"\"\n",
    "\n",
    "for i, batch in enumerate(consecutive_groups_result):  # batch level\n",
    "    for j, span in enumerate(batch):  # span level\n",
    "        start, end = span[\"start\"], span[\"end\"]\n",
    "        length = end - start + 1\n",
    "        idx = torch.arange(length)\n",
    "        context_s = test_inputs[i, start - 1, :]\n",
    "        context_e = test_inputs[i, end + 1, :]\n",
    "        span_pos_emb = span_rel_emb(idx).squeeze(0)\n",
    "        print(f\"start: {span['start'] - 1}, end: {span['end'] + 1}\")\n",
    "        print(f\"start embedding: {context_s}, end embedding: {context_e}\")\n",
    "        print(f\"span length: {length}\")\n",
    "        print(f\"span position embedding: {span_pos_emb}\")\n",
    "        print(f\"span position embedding shape: {span_pos_emb.shape}\")        \n",
    "        \n",
    "        for k, p_h in enumerate(span_pos_emb):  # length of span_pos_emb == length of span of this iterations\n",
    "            \"\"\" concat 하게 되면 그냥 선형 변환 시켜버리자 귀찬헥 저거 벡터 또 만들어서 하지 말고\n",
    "            그렇게 해버리면 귀찮게 뭐 또 라벨 마스킹 만들고 그럴 필요가 사라지니까\n",
    "            \"\"\"\n",
    "            \n",
    "            print(f\"p_h: {p_h}\")\n",
    "            print(f\"p_h shape: {p_h.shape}\")\n",
    "            print(f\"context_s shape: {context_s.shape}\")\n",
    "            print(f\"context_e shape: {context_e.shape}\")\n",
    "            sbo_inputs[i, start+k, :] = torch.cat([context_s, p_h, context_e], dim=0)\n",
    "            print(sbo_inputs[i, start+k, :].shape)\n",
    "sbo_inputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:34:21.984352Z",
     "start_time": "2024-01-03T09:34:21.912221Z"
    }
   },
   "id": "3d7833373f68edf0"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1536) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [12, 1536].  Tensor sizes: [14, 512]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m span_pos_emb \u001B[38;5;241m=\u001B[39m span_rel_emb(idx)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Update hidden_states directly using slicing\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m \u001B[43msbo_inputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([context_s\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m), span_pos_emb, context_e\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The expanded size of the tensor (1536) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [12, 1536].  Tensor sizes: [14, 512]"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(consecutive_groups_result):  # batch level\n",
    "    for span in batch:  # span level\n",
    "        start, end = span[\"start\"], span[\"end\"]\n",
    "        length = end - start + 1\n",
    "        idx = torch.arange(length)\n",
    "        print(idx)\n",
    "        # Extract context_s, context_e\n",
    "        context_s = test_inputs[i, start - 1, :]\n",
    "        context_e = test_inputs[i, end + 1, :]\n",
    "\n",
    "        # Calculate span_pos_emb\n",
    "        span_pos_emb = span_rel_emb(idx).squeeze(0)\n",
    "\n",
    "        # Update hidden_states directly using slicing\n",
    "        sbo_inputs[i, start:end + 1, :] = torch.cat([context_s.unsqueeze(0), span_pos_emb, context_e.unsqueeze(0)], dim=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:27:28.693294Z",
     "start_time": "2024-01-03T09:27:28.660479Z"
    }
   },
   "id": "f94f64dab4013678"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 186, 1536])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbo_inputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T07:41:19.310995Z",
     "start_time": "2024-01-03T07:41:19.275193Z"
    }
   },
   "id": "2f4ba82ce56f1070"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Tensor shape: torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 주어진 텐서들\n",
    "p_h = torch.randn(512)\n",
    "context_s = torch.randn(512)\n",
    "context_e = torch.randn(512)\n",
    "\n",
    "# 텐서 연결\n",
    "concatenated_tensor = torch.cat((p_h, context_s, context_e), dim=0)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Concatenated Tensor shape:\", concatenated_tensor.size())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T07:30:00.565643Z",
     "start_time": "2024-01-03T07:30:00.539131Z"
    }
   },
   "id": "445258ecfcca5c2b"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0674e-01,  1.5010e-01,  2.8648e-01,  4.3527e-02,  5.5293e-01,\n",
      "          4.3704e-02,  4.3280e-01, -1.7497e-01, -6.0524e-01, -1.5137e+00,\n",
      "          6.3072e-01,  9.5070e-01,  2.5640e-01, -5.1775e-01, -1.1149e+00,\n",
      "          1.8001e+00,  7.5599e-01,  6.6276e-01,  1.3045e+00,  4.2922e-01,\n",
      "          1.6121e+00, -4.3758e-01,  2.1913e+00,  2.3489e-01, -5.8649e-01,\n",
      "         -6.1535e-01,  9.8207e-01,  5.4912e-01, -2.1245e-01,  5.3565e-01,\n",
      "         -3.8250e-01,  1.9522e+00, -9.6879e-01,  7.8207e-01,  1.8897e-01,\n",
      "         -1.4546e-01,  1.1465e+00,  1.1909e+00, -7.4609e-01,  2.1862e-02,\n",
      "          4.0188e-01,  5.2788e-01, -1.9433e-01, -7.1187e-01, -1.6604e+00,\n",
      "         -3.5056e-01,  1.4802e+00, -2.3789e-01,  4.5543e-01, -5.5184e-01,\n",
      "          1.0057e+00, -1.1052e+00,  1.6899e+00, -1.3222e+00, -5.5259e-01,\n",
      "          5.5051e-02,  1.1141e-01, -1.0041e+00,  9.4797e-01,  3.6263e-01,\n",
      "         -1.5454e+00,  8.3555e-01,  5.7793e-02,  1.8421e-01, -6.8851e-02,\n",
      "          5.7642e-01, -1.2175e+00,  1.3364e-01,  1.3391e+00,  9.6975e-01,\n",
      "         -3.4178e-01,  1.2949e-02, -1.2215e-01,  2.9195e-01,  1.4798e+00,\n",
      "         -1.2126e-01, -8.5459e-01,  6.6244e-01,  1.9704e+00,  5.3234e-01,\n",
      "          6.8962e-01,  1.8806e+00, -4.8023e-01, -1.0470e+00,  5.4175e-01,\n",
      "          1.2668e+00, -7.0870e-01,  1.1513e+00, -1.5358e+00, -6.0648e-01,\n",
      "          4.1617e-01,  5.5146e-02,  1.1712e-01,  1.1519e+00, -8.2269e-01,\n",
      "          6.9703e-01, -1.0632e-02, -2.0950e-01,  1.3493e+00,  6.0341e-01,\n",
      "          3.9064e-01,  8.9972e-01, -1.1005e+00,  3.2832e-01, -1.0319e+00,\n",
      "          4.4814e-01,  1.0272e+00, -6.8841e-01,  4.8859e-01,  1.7776e-01,\n",
      "          5.0319e-02,  2.1504e-01, -3.6955e-01,  7.3507e-01,  1.0974e+00,\n",
      "         -5.5052e-01, -8.0276e-01,  4.6331e-01,  2.0289e-01,  5.7382e-01,\n",
      "          6.9938e-01, -9.8670e-02, -5.2654e-01,  7.8012e-01, -9.3576e-01,\n",
      "         -1.3719e-01,  5.4403e-01,  5.1271e-01, -3.0276e-01,  5.5785e-01,\n",
      "         -3.6869e-01, -8.3361e-01, -9.5447e-01, -2.1101e+00,  5.2167e-01,\n",
      "         -2.2926e-01,  9.6777e-01,  1.4076e+00,  1.1211e+00,  1.2498e-01,\n",
      "          2.2948e-01,  6.7145e-01, -1.0796e+00, -7.5907e-01,  4.4169e-01,\n",
      "          9.0383e-01, -1.4999e-01, -3.3580e-01, -4.5601e-01,  7.1436e-01,\n",
      "         -2.8994e-01, -6.3817e-01,  7.5112e-01, -6.1155e-01,  4.8295e-01,\n",
      "          8.6417e-01, -1.3481e-01, -9.7112e-02, -8.3028e-01, -3.7268e-01,\n",
      "         -1.0772e-01, -8.5309e-01,  1.0855e+00,  1.0134e+00,  1.5301e+00,\n",
      "         -1.0133e-01, -1.1609e+00,  2.2945e-01, -3.7455e-01, -9.9160e-02,\n",
      "          3.7499e-01,  2.0092e+00,  3.1794e-01,  4.8970e-01, -1.0764e-01,\n",
      "         -1.1024e+00,  3.7126e-01,  3.9364e-01,  1.0848e-03,  1.6740e+00,\n",
      "          7.6036e-01, -8.2722e-01,  9.8603e-01, -5.8556e-01,  8.1752e-01,\n",
      "         -5.8228e-01,  6.9064e-02,  2.9504e-02, -7.4991e-01, -1.4724e+00,\n",
      "          1.4093e+00, -5.0669e-01,  1.5840e+00,  9.6949e-01, -3.7570e-01,\n",
      "         -2.2117e+00, -1.6455e-01,  1.0650e-02, -2.2553e-01,  6.3623e-01,\n",
      "          1.2171e+00, -1.1246e-01, -1.9174e-01, -8.9006e-02, -1.3424e+00,\n",
      "         -9.1327e-01, -1.5022e+00, -2.3781e-01,  1.4996e+00,  2.7160e-01,\n",
      "          4.9528e-01,  2.4315e-01,  7.2221e-01, -7.0697e-01, -8.1666e-01,\n",
      "         -1.0562e+00,  2.4037e+00,  1.1413e+00, -2.7000e-01,  1.9606e-01,\n",
      "         -1.2456e+00, -3.9905e-01,  7.8047e-02, -1.3682e-01, -3.2289e-01,\n",
      "         -7.9298e-01, -6.0361e-02, -3.5560e-01, -1.1638e+00,  1.1789e-01,\n",
      "         -1.0295e+00,  9.2728e-01,  1.0399e+00,  1.2550e-01,  1.2053e+00,\n",
      "         -7.2403e-01,  1.4892e+00,  1.6137e+00, -2.8464e-01, -4.9643e-01,\n",
      "         -9.9057e-01,  4.9260e-01,  1.0197e+00, -4.9488e-01,  6.6427e-03,\n",
      "          5.5383e-01,  8.4529e-01,  1.1131e+00, -1.6997e+00,  4.5005e-01,\n",
      "          8.7084e-01,  2.0360e-01, -2.3744e+00,  4.1323e-01, -2.8419e-01,\n",
      "          1.6797e+00,  4.5041e-01,  5.9207e-01,  1.0682e+00,  7.0931e-01,\n",
      "          1.0638e+00,  5.6541e-01,  1.1695e+00,  6.9562e-01,  8.6243e-01,\n",
      "         -2.6820e-02, -5.7254e-01,  7.5383e-01,  6.5385e-01, -1.9895e-01,\n",
      "          7.4797e-01,  6.7780e-01, -2.5299e+00,  7.7612e-02, -6.6752e-01,\n",
      "          1.1773e+00, -1.1070e+00, -4.6183e-01,  4.6731e-01, -7.9440e-01,\n",
      "          1.2639e-02,  1.8701e-01, -1.7553e+00, -1.1593e+00,  1.2610e+00,\n",
      "         -1.2684e+00, -1.7807e-01,  1.2212e+00, -3.6387e-01, -1.0422e-01,\n",
      "         -1.1080e-01,  3.5364e-01, -2.1442e+00, -1.8186e+00, -3.6365e-01,\n",
      "          6.8202e-01, -2.2331e+00,  1.2353e+00, -5.3650e-01,  1.5073e+00,\n",
      "          1.2670e-01, -1.2417e+00,  5.2094e-01,  4.1353e-01, -1.0790e-01,\n",
      "          5.8862e-01, -5.4459e-01,  7.7975e-01, -6.6101e-01, -9.3573e-01,\n",
      "         -1.4547e+00,  7.4476e-01, -3.0381e-01, -1.7263e-01, -1.2500e+00,\n",
      "         -9.0779e-01,  4.1784e-01,  1.8067e+00, -3.8675e-01,  1.0628e+00,\n",
      "          1.5156e+00, -2.2428e+00,  3.7260e-01,  3.9079e-01,  4.0667e-01,\n",
      "          4.3975e-01, -2.2956e-01, -5.7480e-01, -1.5199e+00,  1.1919e+00,\n",
      "          3.8556e-01,  3.1167e-01,  2.1164e+00, -3.0853e-01,  1.2040e+00,\n",
      "         -1.8423e-01,  1.4416e+00,  4.8298e-01, -1.6275e+00, -1.2183e+00,\n",
      "         -5.9676e-01,  7.2053e-01,  5.8082e-01, -2.5038e-01, -1.2162e+00,\n",
      "          1.3516e+00,  1.0387e-01, -7.0298e-01,  1.8996e-02, -6.5075e-01,\n",
      "          1.5072e+00,  1.5851e+00,  1.1915e+00, -2.5423e-01,  2.0837e+00,\n",
      "          5.2769e-01, -9.5717e-01,  5.0375e-02,  1.1826e+00, -8.1068e-01,\n",
      "          3.3212e-01,  6.9706e-01,  1.2709e+00, -6.0718e-01, -1.9595e+00,\n",
      "          8.4271e-01,  1.0461e+00, -9.6986e-01,  2.3589e-01, -5.0060e-01,\n",
      "         -1.6140e+00, -1.3112e+00, -1.7896e+00, -1.6544e+00,  2.4911e+00,\n",
      "          2.1607e-01, -1.4741e+00, -7.2221e-01, -1.7117e+00,  1.0181e+00,\n",
      "          2.9795e-01,  9.9015e-01,  2.4809e-01,  4.6874e-01,  3.2746e-01,\n",
      "         -6.5623e-02,  9.5237e-01, -2.3121e+00,  7.6749e-01, -1.5787e+00,\n",
      "         -1.0992e+00,  4.5535e-01,  2.9241e-01, -7.0782e-02, -8.2226e-01,\n",
      "          1.7079e+00, -6.0342e-01, -6.0391e-03,  5.8933e-01, -1.4740e+00,\n",
      "          5.6443e-01, -1.1626e+00, -2.0529e+00, -7.6604e-03, -1.6142e+00,\n",
      "          2.1149e+00,  1.8320e+00, -8.9033e-01,  3.2642e-02,  2.4886e+00,\n",
      "          1.4990e+00,  3.6979e-01,  1.4986e+00,  4.6729e-01,  7.7044e-01,\n",
      "          1.7223e-01, -5.1344e-01,  8.8495e-01, -2.4499e-01,  8.2217e-01,\n",
      "          1.9637e-01, -8.9557e-01, -1.4104e-02,  1.7596e-01,  9.6442e-01,\n",
      "         -1.2446e-02, -3.6109e-01, -1.0787e+00, -3.7034e-01, -1.8588e+00,\n",
      "         -1.1593e+00,  1.2743e+00, -1.1176e-01,  9.7367e-01,  1.2836e+00,\n",
      "         -1.4151e+00, -5.0774e-01,  1.5037e-01, -9.9776e-02,  9.3398e-01,\n",
      "         -6.8532e-01, -3.6928e-01,  6.8173e-01,  6.6892e-01, -4.4693e-01,\n",
      "          5.3543e-01, -1.0917e+00,  7.7409e-01, -2.2713e+00,  1.2588e-01,\n",
      "         -1.1613e-01, -1.1781e+00,  4.5477e-01,  1.9036e+00,  1.6226e-01,\n",
      "         -1.0098e+00,  1.7169e+00, -6.9451e-01,  1.4275e+00,  6.6643e-01,\n",
      "          6.6356e-01,  1.6817e+00,  8.4985e-01,  1.3966e-01, -2.2522e-01,\n",
      "          4.6796e-01,  5.9650e-01,  1.9884e+00, -1.7169e-01,  9.0539e-01,\n",
      "         -2.2422e+00, -1.8791e-02,  2.0706e-01, -7.9939e-01,  4.8317e-01,\n",
      "         -4.1524e-01, -1.1132e+00,  3.0146e-02, -1.1224e+00, -1.5036e+00,\n",
      "         -6.9672e-01, -5.6278e-01, -1.7566e+00, -5.4951e-01, -9.9512e-01,\n",
      "          4.9886e-01,  1.7474e+00, -6.2883e-01, -8.0000e-01,  3.3347e-01,\n",
      "         -1.0735e+00, -1.3619e+00, -3.5748e-01, -8.1966e-01, -2.3881e-02,\n",
      "         -2.7087e-01, -2.9975e-01, -2.5732e-01,  1.0039e+00,  1.2846e+00,\n",
      "          2.1957e-01, -1.6003e-01,  5.3541e-02,  7.9968e-01, -2.4148e-01,\n",
      "          7.7812e-01,  1.0209e+00,  7.7423e-01, -5.7004e-01, -2.5844e-01,\n",
      "          1.4749e+00, -1.6749e-01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (512) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 35\u001B[0m\n\u001B[1;32m     33\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(relative_position_embedding)\n\u001B[1;32m     34\u001B[0m                 \u001B[38;5;66;03m# Add relative position embedding to the corresponding position in the input tensor\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m                 test_input_tensor[i, j:j\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlen\u001B[39m(group)] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m relative_position_embedding\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Print the resulting tensor\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(test_input_tensor)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (4) must match the size of tensor b (512) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "\n",
    "# Given tensors\n",
    "test_masking_tensor = torch.tensor([\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "test_input_tensor = torch.zeros((6, 34))\n",
    "test_input_tensor = torch.fill(test_input_tensor, 100)\n",
    "span_rel_emb = nn.Embedding(10, 512)\n",
    "\n",
    "# Find consecutive groups of 1's in the masking tensor\n",
    "consecutive_groups = []\n",
    "for row in test_masking_tensor:\n",
    "    consecutive_groups.append([\n",
    "        list(group) for key, group in itertools.groupby(row) if key == 1\n",
    "    ])\n",
    "\n",
    "# Iterate over each row and apply relative position embeddings\n",
    "for i, groups in enumerate(consecutive_groups):\n",
    "    for group in groups:\n",
    "        for j, is_one in enumerate(group):\n",
    "            if is_one:\n",
    "                # Get relative position embedding\n",
    "                relative_position_embedding = span_rel_emb(torch.tensor([j]))\n",
    "                print(relative_position_embedding)\n",
    "                # Add relative position embedding to the corresponding position in the input tensor\n",
    "                test_input_tensor[i, j:j+len(group)] += relative_position_embedding.squeeze()\n",
    "\n",
    "# Print the resulting tensor\n",
    "print(test_input_tensor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T07:09:41.997406Z",
     "start_time": "2024-01-03T07:09:41.965608Z"
    }
   },
   "id": "f2d46c9230ac4eae"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그룹 시작 위치: 4, 그룹 끝 위치: 10\n",
      "그룹 시작 위치: 15, 그룹 끝 위치: 18\n",
      "그룹 시작 위치: 24, 그룹 끝 위치: 26\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_consecutive_groups(tensor, target_value):\n",
    "    consecutive_groups = []\n",
    "    current_group = None\n",
    "\n",
    "    for i, value in enumerate(tensor):\n",
    "        if value == target_value:\n",
    "            if current_group is None:\n",
    "                current_group = {\"start\": i, \"end\": i}\n",
    "            else:\n",
    "                current_group[\"end\"] = i\n",
    "        else:\n",
    "            if current_group is not None:\n",
    "                consecutive_groups.append(current_group)\n",
    "                current_group = None\n",
    "\n",
    "    # 추가: 마지막 그룹이 끝까지 이어진 경우\n",
    "    if current_group is not None:\n",
    "        consecutive_groups.append(current_group)\n",
    "\n",
    "    return consecutive_groups\n",
    "\n",
    "# 예시 텐서\n",
    "# 1이 연속된 그룹의 시작과 끝 위치 찾기\n",
    "consecutive_groups = find_consecutive_groups(test, target_value=1)\n",
    "\n",
    "# 결과 출력\n",
    "for group in consecutive_groups:\n",
    "    start, end = group[\"start\"], group[\"end\"]\n",
    "    print(f\"그룹 시작 위치: {start}, 그룹 끝 위치: {end}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T20:34:43.394589Z",
     "start_time": "2024-01-02T20:34:43.380038Z"
    }
   },
   "id": "71ec2030d805ca0e"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "'▁train'"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._convert_id_to_token(2184)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T20:16:58.291693Z",
     "start_time": "2024-01-02T20:16:58.280426Z"
    }
   },
   "id": "58c372f3fcdb49ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'vocab_file': 'spm.model', 'tokenizer_file': 'tokenizer.json'}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_files_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:43:19.828506155Z",
     "start_time": "2024-01-02T08:43:19.772276081Z"
    }
   },
   "id": "27ff48a2990d9c45",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-100, -100,   99,   98,   97,   96])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Experiment for ELECTRA get discriminator input\n",
    "1) flatten logit tensor and label tensor\n",
    "2) get highest logit\n",
    "3) masked select for mlm masking index\n",
    "4) get index of mlm masking index\n",
    "5) index select for discriminator input \n",
    "\"\"\"\n",
    "flat_logit = torch.tensor([99, 98, 97, 96])\n",
    "test = torch.tensor([-100, -100, 1, 2, 3, 4])\n",
    "mlm_mask_idx = torch.where(test != -100)\n",
    "\n",
    "test2 = test.clone()\n",
    "test[mlm_mask_idx] = flat_logit\n",
    "test\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T08:16:45.737064Z",
     "start_time": "2023-12-31T08:16:45.728843Z"
    }
   },
   "id": "cb1887885007a163"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 0, 0, 0, 0])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(test, test2).long()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T08:16:50.262452Z",
     "start_time": "2023-12-31T08:16:50.259370Z"
    }
   },
   "id": "2eb6dd39dea96f1a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-100, -100],\n        [   1,    2],\n        [   3,    4]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.tensor([1, 2])\n",
    "\n",
    "test = torch.tensor([-100, -100, 1, 2, 3, 4])\n",
    "test.view(-1, a.size(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T08:21:25.369486Z",
     "start_time": "2023-12-31T08:21:25.359518Z"
    }
   },
   "id": "d118d5f272197b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Experiment for Huggingface Tokenizer for Building MLM Algorithm \n",
    "meaning of special token in Huggingface Tokenizer is corrspoding to [CLS], [SEP], [MASK], [PAD] ... etc\n",
    "\"\"\"\n",
    "\n",
    "text = 'I am a boy [MASK] [MASK] are a girl [PAD]'\n",
    "tokens = CFG.tokenizer(text)\n",
    "input_ids = [torch.tensor(x) for x in tokens[\"input_ids\"]]\n",
    "special_tokens_mask = CFG.tokenizer.get_special_tokens_mask(input_ids, already_has_special_tokens=True)\n",
    "special_tokens_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T22:44:13.446160Z",
     "start_time": "2023-12-29T22:44:13.441479Z"
    }
   },
   "id": "7a31d5ebf9b1632a"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n        0.1500, 0.1500, 0.1500])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Experiment for Huggingface Tokenizer for Building MLM Algorithm \n",
    "\"\"\"\n",
    "mlm_probability = 0.15\n",
    "probability_matrix = torch.full(torch.tensor(input_ids).shape, mlm_probability)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T22:44:14.030451Z",
     "start_time": "2023-12-29T22:44:14.025780Z"
    }
   },
   "id": "487442037a73caed"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "masked_fill_() received an invalid combination of arguments - got (list, value=float), but expected one of:\n * (Tensor mask, Tensor value)\n      didn't match because some of the arguments have invalid types: (!list of [int, int, int, int, int, int, int, int, int, int, int, int]!, !value=float!)\n * (Tensor mask, Number value)\n      didn't match because some of the arguments have invalid types: (!list of [int, int, int, int, int, int, int, int, int, int, int, int]!, !value=float!)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\" Experiment for Huggingface Tokenizer for Building MLM Algorithm \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mprobability_matrix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasked_fill_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspecial_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m masked_indices \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbernoulli(probability_matrix)\u001B[38;5;241m.\u001B[39mbool()\n\u001B[1;32m      5\u001B[0m masked_indices\n",
      "\u001B[0;31mTypeError\u001B[0m: masked_fill_() received an invalid combination of arguments - got (list, value=float), but expected one of:\n * (Tensor mask, Tensor value)\n      didn't match because some of the arguments have invalid types: (!list of [int, int, int, int, int, int, int, int, int, int, int, int]!, !value=float!)\n * (Tensor mask, Number value)\n      didn't match because some of the arguments have invalid types: (!list of [int, int, int, int, int, int, int, int, int, int, int, int]!, !value=float!)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Experiment for Huggingface Tokenizer for Building MLM Algorithm \n",
    "\"\"\"\n",
    "probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "masked_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T22:44:15.035358Z",
     "start_time": "2023-12-29T22:44:15.033134Z"
    }
   },
   "id": "96982a7b1365afaa"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43minput_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m~\u001B[39;49m\u001B[43mmasked_indices\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "input_ids[~masked_indices] = -100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T22:43:21.978416Z",
     "start_time": "2023-12-29T22:43:21.966992Z"
    }
   },
   "id": "5cf33010e2468866"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def hf_load_dataset(cfg: CFG) -> DatasetDict:\n",
    "    \"\"\" Load dataset from Huggingface Datasets\n",
    "    Notes:\n",
    "        This function is temporary just fit-able for Wikipedia dataset\n",
    "    References:\n",
    "        https://github.com/huggingface/datasets/blob/main/src/datasets/load.py#2247\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(cfg.hf_dataset, cfg.language)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def hf_split_dataset(cfg: CFG, dataset: Dataset) -> Tuple[Dataset, Dataset]:\n",
    "    \"\"\" Split dataset from Huggingface Datasets with huggingface method \"train_test_split\"\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load split ratio, seed value\n",
    "        dataset: Huggingface Datasets object, dataset from Huggingface Datasets\n",
    "    Notes:\n",
    "        This function is temporary just fit-able for Wikipedia dataset & MLM Task\n",
    "    \"\"\"\n",
    "    dataset = dataset.train_test_split(cfg.split_ratio, seed=cfg.seed)\n",
    "    train, valid = dataset['train'], dataset['test']\n",
    "    return train, valid\n",
    "\n",
    "\n",
    "def chunking(sequences: Dict, cfg: CFG = CFG) -> List[str]:\n",
    "    \"\"\" Chunking sentence to token using pretrained tokenizer\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load pretrained tokenizer\n",
    "        sequences: list, sentence to chunking\n",
    "    References:\n",
    "        https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling\n",
    "    \"\"\"\n",
    "    return cfg.tokenizer([\" \".join(x) for x in sequences['text']])\n",
    "\n",
    "\n",
    "def group_texts(sequences: Dict, cfg: CFG = CFG) -> Dict:\n",
    "    \"\"\" Dealing Problem: some of data instances are longer than the maximum input length for the model,\n",
    "    This function is ONLY used to HF Dataset Object\n",
    "    1) Concatenate all texts\n",
    "    2) We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    3) customize this part to your needs\n",
    "    4) Split by chunks of max_len\n",
    "    \"\"\"\n",
    "    concatenated_sequences = {k: sum(sequences[k], []) for k in sequences.keys()}\n",
    "    total_length = len(concatenated_sequences[list(sequences.keys())[0]])\n",
    "    if total_length >= cfg.max_seq:\n",
    "        total_length = (total_length // cfg.max_seq) * cfg.max_seq\n",
    "    result = {\n",
    "        k: [t[i: i + cfg.max_seq] for i in range(0, total_length, cfg.max_seq)]\n",
    "        for k, t in concatenated_sequences.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def apply_preprocess(dataset: Dataset, function: Callable, batched: bool = True, num_proc: int = 4, remove_columns: any = None) -> Dataset:\n",
    "    \"\"\" Apply preprocessing to text data, which is using huggingface dataset method \"map()\"\n",
    "    for pretrained training (MLM, CLM)\n",
    "    Args:\n",
    "        dataset: Huggingface Datasets object, dataset from Huggingface Datasets\n",
    "        function: Callable, function that you want to apply\n",
    "        batched: bool, default True, if you want to apply function to batched data, set True\n",
    "        num_proc: int, default 4, number of process for multiprocessing\n",
    "        remove_columns: any, default None, if you want to remove some columns, set column name\n",
    "    References:\n",
    "        https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling\n",
    "    \"\"\"\n",
    "    mapped_dataset = dataset.map(\n",
    "        function,\n",
    "        batched=batched,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=remove_columns,\n",
    "    )\n",
    "    return mapped_dataset\n",
    "\n",
    "\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\" Load data_folder from csv file like as train.csv, test.csv, val.csv\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def no_char(text):\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\^[a-zA-Z]\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]$\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def no_multi_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text, flags=re.I)\n",
    "\n",
    "\n",
    "def underscore_to_space(text: str):\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(source):\n",
    "    \"\"\" Remove all the special characters\n",
    "    \"\"\"\n",
    "    source = re.sub(r'\\W', ' ', str(source))\n",
    "    source = re.sub(r'^b\\s+', '', source)\n",
    "    source = source.lower()\n",
    "    return source\n",
    "\n",
    "\n",
    "def cleaning_words(text: str) -> str:\n",
    "    \"\"\" Apply all of cleaning process to text data\n",
    "    \"\"\"\n",
    "    tmp_text = underscore_to_space(text)\n",
    "    tmp_text = no_char(tmp_text)\n",
    "    tmp_text = preprocess_text(tmp_text)\n",
    "    tmp_text = no_multi_spaces(tmp_text)\n",
    "    return tmp_text\n",
    "\n",
    "\n",
    "def split_token(inputs: str):\n",
    "    \"\"\" Convert malform list to Python List Object & elementwise type casting\n",
    "    \"\"\"\n",
    "    inputs = cleaning_words(inputs)\n",
    "    tmp = inputs.split()\n",
    "    result = list(map(int, tmp))\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_list(inputs: List, max_length: int) -> List[List]:\n",
    "    \"\"\" Split List into sub shorter list, which is longer than max_length\n",
    "    \"\"\"\n",
    "    result = [inputs[i:i + max_length] for i in range(0, len(inputs), max_length)]\n",
    "    return result\n",
    "\n",
    "\n",
    "def flatten_sublist(inputs: List[List], max_length: int = 512) -> List[List]:\n",
    "    \"\"\" Flatten Nested List to 1D-List \"\"\"\n",
    "    result = []\n",
    "    for instance in tqdm(inputs):\n",
    "        tmp = split_token(instance)\n",
    "        if len(tmp) > max_length:\n",
    "            tmp = split_list(tmp, max_length)\n",
    "            for i in range(len(tmp)):\n",
    "                result.append(tmp[i])\n",
    "        else:\n",
    "            result.append(tmp)\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess4tokenizer(input_ids: List, token_type_ids: List, attention_mask: List):\n",
    "    for i, inputs in tqdm(enumerate(input_ids)):\n",
    "        if inputs[0] != 1:\n",
    "            inputs.insert(0, 1)\n",
    "            token_type_ids[i].insert(0, 0)\n",
    "            attention_mask[i].insert(0, 1)\n",
    "        if inputs[-1] != 2:\n",
    "            inputs.append(2)\n",
    "            token_type_ids[i].append(0)\n",
    "            attention_mask[i].append(1)\n",
    "    return input_ids, token_type_ids, attention_mask\n",
    "\n",
    "\n",
    "def cut_instance(input_ids: List, token_type_ids: List, attention_mask: List, min_length: int = 256):\n",
    "    n_input_ids, n_token_type_ids, n_attention_mask = [], [], []\n",
    "    for i, inputs in tqdm(enumerate(input_ids)):\n",
    "        if len(inputs) >= min_length:\n",
    "            n_input_ids.append(inputs)\n",
    "            n_token_type_ids.append(token_type_ids[i])\n",
    "            n_attention_mask.append(attention_mask[i])\n",
    "    return n_input_ids, n_token_type_ids, n_attention_mask\n",
    "\n",
    "\n",
    "def save_pkl(input_dict: Any, filename: str) -> None:\n",
    "    with open(f'{filename}.pkl', 'wb') as file:\n",
    "        pickle.dump(input_dict, file)\n",
    "\n",
    "\n",
    "def load_pkl(filepath: str) -> Any:\n",
    "    \"\"\"  Load pickle file\n",
    "    Examples:\n",
    "        filepath = './dataset_class/data_folder/train'\n",
    "    \"\"\"\n",
    "    with open(f'{filepath}.pkl', 'rb') as file:\n",
    "        output = pickle.load(file)\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:31:18.201421201Z",
     "start_time": "2024-01-02T09:31:18.194621731Z"
    }
   },
   "id": "a4b602dc2a95d746",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m1) Load Dataset, Tokenizer\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m2) Split Dataset, preprocess dataset for MLM Task\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mhf_load_dataset\u001B[49m(CFG)\n\u001B[1;32m      6\u001B[0m _, sub_ds \u001B[38;5;241m=\u001B[39m hf_split_dataset(CFG, ds[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      7\u001B[0m train, valid \u001B[38;5;241m=\u001B[39m hf_split_dataset(CFG, sub_ds)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'hf_load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1) Load Dataset, Tokenizer\n",
    "2) Split Dataset, preprocess dataset for MLM Task\n",
    "\"\"\"\n",
    "ds = hf_load_dataset(CFG)\n",
    "_, sub_ds = hf_split_dataset(CFG, ds['train'])\n",
    "train, valid = hf_split_dataset(CFG, sub_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T05:58:37.078524Z",
     "start_time": "2023-12-28T05:58:36.985803Z"
    }
   },
   "id": "3dd1380b24923e54",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/1025250 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2864e98a41a54796be60b508bf91d442"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/256313 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f839d04ba1ae47a2ac881fcf1aef0589"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Apply preprocessing to dataset \"\"\"\n",
    "\n",
    "chunked_train = apply_preprocess(\n",
    "    train,\n",
    "    chunking,\n",
    "    remove_columns=train.column_names\n",
    ")\n",
    "\n",
    "chunked_valid = apply_preprocess(\n",
    "    valid,\n",
    "    chunking,\n",
    "    remove_columns=valid.column_names\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T08:04:26.000451213Z",
     "start_time": "2023-12-26T07:11:17.408675415Z"
    }
   },
   "id": "34e27b69bc4e33a7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=8):   0%|          | 0/1025250 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "323d0bc5d14543a7ad5b34458b4b9ecc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001B[0m in \u001B[0;36miflatmap_unordered\u001B[0;34m(pool, func, kwargs_iterable)\u001B[0m\n\u001B[1;32m    639\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 640\u001B[0;31m                     \u001B[0;32myield\u001B[0m \u001B[0mqueue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.05\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    641\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<string>\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, *args, **kwds)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/multiprocess/managers.py\u001B[0m in \u001B[0;36m_callmethod\u001B[0;34m(self, methodname, args, kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m         \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethodname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 810\u001B[0;31m         \u001B[0mkind\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    811\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/multiprocess/connection.py\u001B[0m in \u001B[0;36mrecv\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    252\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_readable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 253\u001B[0;31m         \u001B[0mbuf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recv_bytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    254\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_ForkingPickler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetbuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/multiprocess/connection.py\u001B[0m in \u001B[0;36m_recv_bytes\u001B[0;34m(self, maxsize)\u001B[0m\n\u001B[1;32m    416\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_recv_bytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 417\u001B[0;31m         \u001B[0mbuf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    418\u001B[0m         \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstruct\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munpack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"!i\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/multiprocess/connection.py\u001B[0m in \u001B[0;36m_recv\u001B[0;34m(self, size, read)\u001B[0m\n\u001B[1;32m    381\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mremaining\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m             \u001B[0mchunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mremaining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m             \u001B[0mn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_8506/2765937612.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\"\"\" Grouping text data to fit the maximum input length for the model \"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m grouped_train = apply_preprocess(\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mchunked_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mgroup_texts\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_8506/3833045376.py\u001B[0m in \u001B[0;36mapply_preprocess\u001B[0;34m(dataset, function, batched, num_proc, remove_columns)\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mhttps\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0mhuggingface\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mco\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mdocs\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mtransformers\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mmain\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mmasked_language_modeling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m     \"\"\"\n\u001B[0;32m---> 67\u001B[0;31m     mapped_dataset = dataset.map(\n\u001B[0m\u001B[1;32m     68\u001B[0m         \u001B[0mfunction\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0mbatched\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatched\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    590\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"Dataset\"\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"self\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    591\u001B[0m         \u001B[0;31m# apply actual function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 592\u001B[0;31m         \u001B[0mout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Dataset\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"DatasetDict\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    593\u001B[0m         \u001B[0mdatasets\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Dataset\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    594\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdataset\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    555\u001B[0m         }\n\u001B[1;32m    556\u001B[0m         \u001B[0;31m# apply actual function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 557\u001B[0;31m         \u001B[0mout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Dataset\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"DatasetDict\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    558\u001B[0m         \u001B[0mdatasets\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Dataset\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m         \u001B[0;31m# re-apply format to the output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   3183\u001B[0m                         \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdesc\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m\"Map\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mf\" (num_proc={num_proc})\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3184\u001B[0m                     ) as pbar:\n\u001B[0;32m-> 3185\u001B[0;31m                         for rank, done, content in iflatmap_unordered(\n\u001B[0m\u001B[1;32m   3186\u001B[0m                             \u001B[0mpool\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_single\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs_iterable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs_per_job\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3187\u001B[0m                         ):\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001B[0m in \u001B[0;36miflatmap_unordered\u001B[0;34m(pool, func, kwargs_iterable)\u001B[0m\n\u001B[1;32m    652\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpool_changed\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    653\u001B[0m                 \u001B[0;31m# we get the result in case there's an error to raise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 654\u001B[0;31m                 \u001B[0;34m[\u001B[0m\u001B[0masync_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.05\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0masync_result\u001B[0m \u001B[0;32min\u001B[0m \u001B[0masync_results\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    652\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpool_changed\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    653\u001B[0m                 \u001B[0;31m# we get the result in case there's an error to raise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 654\u001B[0;31m                 \u001B[0;34m[\u001B[0m\u001B[0masync_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.05\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0masync_result\u001B[0m \u001B[0;32min\u001B[0m \u001B[0masync_results\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    765\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    766\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mready\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 767\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    768\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_success\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    769\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTimeoutError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Grouping text data to fit the maximum input length for the model \"\"\"\n",
    "\n",
    "grouped_train = apply_preprocess(\n",
    "    chunked_train,\n",
    "    group_texts,\n",
    "    num_proc=8,\n",
    ")\n",
    "\n",
    "grouped_valid = apply_preprocess(\n",
    "    chunked_train,\n",
    "    group_texts,\n",
    "    num_proc=8,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T08:13:11.370459308Z",
     "start_time": "2023-12-26T08:10:05.225477717Z"
    }
   },
   "id": "23d7abc06fd50bb1",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'trained train pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining pretrained pretraining'"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"trained, train, Pretrained, Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining. Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining, Pretrained, Pretraining\"\n",
    "\n",
    "cleaning_words(input_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:31:20.604222646Z",
     "start_time": "2024-01-02T09:31:20.600308365Z"
    }
   },
   "id": "768529dd22d186c8",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f6ec65fceb9f62eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
