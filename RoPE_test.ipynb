{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoModel, AutoConfig\n",
    "import experiment.metrics.metric as metric\n",
    "from experiment.metrics.metric import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T07:42:08.921662Z",
     "start_time": "2024-04-01T07:42:07.314018Z"
    }
   },
   "id": "f1b867fbf9578cf4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" set default device to mps \"\"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T07:42:08.926219Z",
     "start_time": "2024-04-01T07:42:08.922644Z"
    }
   },
   "id": "eedaeeb4c236e989",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_a: torch.Size([768, 4])\n",
      "lora_b: torch.Size([4, 768])\n",
      "delta_w: torch.Size([768, 768])\n",
      "U: torch.Size([768, 768])\n",
      "S: torch.Size([768])\n",
      "V: torch.Size([768, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/l_9fgbw95hl79rj750047d1c0000gn/T/ipykernel_32615/277932229.py:13: UserWarning: The operator 'aten::linalg_svd' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  U, S, V = torch.svd(delta_w)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LoRA 결과 해석 데모 버전\n",
    "1) 실제는 DeBERTa 사전 학습 버젼, 파인튜닝 버젼 가중치 행렬에 직접 수행\n",
    "\"\"\"\n",
    "\n",
    "pretrain_w = torch.randn(768, 768, device=device)\n",
    "lora_a, lora_b = torch.randn(768, 4, device=device), torch.randn(4, 768, device=device)\n",
    "delta_w = torch.matmul(lora_a, lora_b)\n",
    "\n",
    "print(f\"lora_a: {lora_a.shape}\")\n",
    "print(f\"lora_b: {lora_b.shape}\")\n",
    "print(f\"delta_w: {delta_w.shape}\")\n",
    "\n",
    "U, S, V = torch.svd(delta_w)\n",
    "print(f\"U: {U.shape}\")\n",
    "print(f\"S: {S.shape}\")\n",
    "print(f\"V: {V.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T04:47:18.938370Z",
     "start_time": "2024-04-01T04:47:18.743656Z"
    }
   },
   "id": "d00de209ac9e86b3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.2021, -0.0627,  1.4396, -0.0408],\n         [-1.3369, -1.4538, -0.3073, -0.4908],\n         [ 0.2128, -1.6067, -0.9427, -0.1693],\n         [-0.2723, -0.3725,  1.2293, -0.6210]], device='mps:0'),\n tensor(3.4654, device='mps:0'))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ||U⊤WqV ⊤|| \"\"\"\n",
    "\n",
    "r = 4\n",
    "r_U, r_V = U[:4, :], V[:, :4]\n",
    "result = torch.matmul(r_U @ pretrain_w, r_V)\n",
    "f_norm = torch.norm(result)\n",
    "result, f_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T10:35:29.465314Z",
     "start_time": "2024-03-29T10:35:29.448753Z"
    }
   },
   "id": "e2af871bb7cba87d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "OrderedDict([('roberta.encoder.layer.0.attention.self.query.lora_A',\n              tensor([[ 0.0144, -0.0180,  0.0811,  ..., -0.0082,  0.0915, -0.0301],\n                      [-0.0231, -0.0129, -0.0659,  ...,  0.0245,  0.0474, -0.0645],\n                      [-0.0081,  0.0331,  0.0666,  ..., -0.0378,  0.0596, -0.0176],\n                      ...,\n                      [-0.0296, -0.0362,  0.0024,  ...,  0.0099, -0.0136, -0.0613],\n                      [-0.0010, -0.0004,  0.0037,  ..., -0.0238,  0.0650,  0.0728],\n                      [ 0.0102, -0.0249, -0.0064,  ...,  0.0540, -0.0471, -0.0616]])),\n             ('roberta.encoder.layer.0.attention.self.query.lora_B',\n              tensor([[-1.0878e-02, -1.1407e-01,  1.9040e-02,  ..., -5.1958e-03,\n                        4.4807e-02, -6.5387e-02],\n                      [-1.3314e-02, -3.8988e-02,  1.8823e-02,  ...,  2.2530e-02,\n                        1.7791e-02, -1.5717e-02],\n                      [ 1.5858e-02,  3.6482e-02, -2.4141e-02,  ...,  5.3104e-03,\n                       -3.8048e-02,  3.3360e-02],\n                      ...,\n                      [-9.9511e-03, -8.5142e-03,  1.0750e-02,  ...,  3.0715e-02,\n                        3.0012e-03,  1.3261e-02],\n                      [-3.3710e-03, -1.1333e-03,  1.6545e-02,  ...,  2.8644e-03,\n                       -2.0739e-03,  4.8358e-05],\n                      [ 1.8678e-02, -1.5605e-03,  3.7675e-02,  ...,  1.3114e-02,\n                        2.4063e-02,  1.9562e-02]])),\n             ('roberta.encoder.layer.0.attention.self.value.lora_A',\n              tensor([[ 0.0260,  0.0425, -0.0364,  ..., -0.1066,  0.0056, -0.0201],\n                      [-0.0202, -0.0101, -0.0139,  ..., -0.0626,  0.0068, -0.0492],\n                      [-0.0210,  0.0164,  0.0300,  ..., -0.0034,  0.0411, -0.0529],\n                      ...,\n                      [ 0.0120,  0.0195,  0.0377,  ..., -0.0169,  0.0229, -0.0098],\n                      [ 0.0469,  0.0442, -0.0121,  ...,  0.0389,  0.0460,  0.0059],\n                      [ 0.0427,  0.0033,  0.0449,  ..., -0.0327,  0.0065,  0.0006]])),\n             ('roberta.encoder.layer.0.attention.self.value.lora_B',\n              tensor([[ 0.0298,  0.0065, -0.0269,  ..., -0.0183, -0.0292, -0.0277],\n                      [ 0.0412,  0.0247, -0.0333,  ..., -0.0761,  0.0445, -0.0518],\n                      [-0.0224,  0.0174, -0.0618,  ...,  0.0389,  0.0011,  0.0110],\n                      ...,\n                      [ 0.0199,  0.0245, -0.0681,  ..., -0.0163,  0.0444,  0.0211],\n                      [ 0.0111, -0.0135, -0.0699,  ...,  0.0044, -0.0208,  0.0262],\n                      [ 0.0561, -0.0146, -0.0082,  ..., -0.0374,  0.0318,  0.0256]])),\n             ('roberta.encoder.layer.1.attention.self.query.lora_A',\n              tensor([[-0.0510, -0.0418,  0.0182,  ...,  0.0241, -0.0247, -0.0366],\n                      [-0.0408, -0.0176, -0.0149,  ...,  0.0276,  0.0392, -0.0126],\n                      [ 0.0255, -0.0429, -0.0032,  ...,  0.0375, -0.0371,  0.0221],\n                      ...,\n                      [ 0.0126, -0.0200,  0.0131,  ...,  0.0015, -0.0208,  0.0426],\n                      [-0.0296,  0.0053,  0.1092,  ..., -0.0194, -0.0161, -0.0271],\n                      [ 0.0990, -0.0159, -0.0773,  ...,  0.0015, -0.0119,  0.0099]])),\n             ('roberta.encoder.layer.1.attention.self.query.lora_B',\n              tensor([[ 0.0083,  0.0468,  0.0066,  ...,  0.0242,  0.0254,  0.0245],\n                      [ 0.0506, -0.0228,  0.0239,  ...,  0.0461,  0.0051, -0.0381],\n                      [-0.0079,  0.0068, -0.0460,  ..., -0.0077,  0.0161,  0.0182],\n                      ...,\n                      [ 0.0518, -0.0078,  0.0171,  ...,  0.0594,  0.0499, -0.0655],\n                      [ 0.0555,  0.0192, -0.0373,  ..., -0.0198, -0.0186,  0.0331],\n                      [ 0.0283, -0.0136, -0.0148,  ..., -0.0478,  0.0192,  0.0106]])),\n             ('roberta.encoder.layer.1.attention.self.value.lora_A',\n              tensor([[-0.0163, -0.0340, -0.0021,  ...,  0.0059,  0.0406, -0.0369],\n                      [-0.0453,  0.0575,  0.0229,  ..., -0.0322,  0.0623, -0.0166],\n                      [ 0.0484,  0.0413,  0.0497,  ...,  0.0254,  0.0043,  0.0079],\n                      ...,\n                      [ 0.0280, -0.0667, -0.0224,  ...,  0.0311, -0.0467,  0.0335],\n                      [-0.0061, -0.0330, -0.0104,  ...,  0.0128, -0.0485,  0.0476],\n                      [-0.0792, -0.0211, -0.0147,  ..., -0.0111, -0.0129,  0.0528]])),\n             ('roberta.encoder.layer.1.attention.self.value.lora_B',\n              tensor([[ 0.0375,  0.0134, -0.0291,  ...,  0.0163,  0.0106, -0.0181],\n                      [-0.0228, -0.0299,  0.0251,  ...,  0.0293,  0.0129, -0.0073],\n                      [ 0.0409, -0.0085, -0.0016,  ..., -0.0231, -0.0425, -0.0739],\n                      ...,\n                      [-0.0096,  0.0005, -0.0118,  ..., -0.0128,  0.0095,  0.0373],\n                      [ 0.0031, -0.0138,  0.0347,  ...,  0.0243, -0.0275,  0.0278],\n                      [-0.0466, -0.0366, -0.0208,  ..., -0.0001, -0.0084,  0.0164]])),\n             ('roberta.encoder.layer.2.attention.self.query.lora_A',\n              tensor([[ 0.0334, -0.0382, -0.0706,  ...,  0.0623, -0.0108, -0.0647],\n                      [ 0.0044,  0.0807,  0.0561,  ...,  0.0143,  0.0503, -0.0530],\n                      [ 0.0858, -0.0256, -0.0203,  ..., -0.0570,  0.0145, -0.0290],\n                      ...,\n                      [ 0.0734,  0.0078, -0.0260,  ...,  0.0077,  0.0340, -0.0112],\n                      [-0.0256, -0.0301, -0.0496,  ..., -0.0146, -0.0254,  0.0166],\n                      [ 0.0231,  0.0265, -0.0369,  ...,  0.0439, -0.0092,  0.0382]])),\n             ('roberta.encoder.layer.2.attention.self.query.lora_B',\n              tensor([[-0.0495,  0.0296, -0.0225,  ...,  0.0204,  0.0415, -0.0292],\n                      [ 0.0277, -0.0421, -0.0193,  ...,  0.0123,  0.0244, -0.0108],\n                      [ 0.0323,  0.0406, -0.0047,  ...,  0.0750, -0.0132,  0.0249],\n                      ...,\n                      [-0.0016,  0.0061, -0.0092,  ...,  0.0039, -0.0675, -0.0515],\n                      [-0.0553, -0.1370, -0.0413,  ...,  0.0482, -0.0513, -0.1170],\n                      [ 0.1291,  0.0241, -0.0177,  ..., -0.0039,  0.0658,  0.0679]])),\n             ('roberta.encoder.layer.2.attention.self.value.lora_A',\n              tensor([[ 0.0121, -0.0753,  0.0153,  ...,  0.0313,  0.0522,  0.0033],\n                      [ 0.0931,  0.0625,  0.0369,  ..., -0.0131,  0.0102,  0.0235],\n                      [ 0.0151,  0.0753,  0.0111,  ...,  0.0537,  0.0123, -0.0457],\n                      ...,\n                      [-0.0820,  0.0476,  0.0454,  ...,  0.0808,  0.0420, -0.0609],\n                      [ 0.0478, -0.0635,  0.0680,  ...,  0.0263,  0.0484,  0.0607],\n                      [ 0.0274, -0.0252, -0.0372,  ...,  0.0433,  0.0246,  0.0585]])),\n             ('roberta.encoder.layer.2.attention.self.value.lora_B',\n              tensor([[-0.0279,  0.0172, -0.0549,  ..., -0.0360, -0.0061, -0.0238],\n                      [-0.0135, -0.0282, -0.0622,  ...,  0.0122,  0.0140, -0.0155],\n                      [-0.0186,  0.0640, -0.0240,  ..., -0.0571,  0.0141,  0.0349],\n                      ...,\n                      [ 0.0259,  0.0824, -0.0281,  ..., -0.0011,  0.0122, -0.0166],\n                      [-0.0134,  0.0166, -0.0398,  ...,  0.0301, -0.0316,  0.0262],\n                      [-0.0309, -0.0453, -0.0112,  ..., -0.0094, -0.0573,  0.0172]])),\n             ('roberta.encoder.layer.3.attention.self.query.lora_A',\n              tensor([[ 0.0705,  0.0360,  0.0527,  ...,  0.0098, -0.0304,  0.0416],\n                      [-0.0012, -0.0479, -0.1085,  ...,  0.1024, -0.0712,  0.0328],\n                      [-0.0954,  0.0619, -0.0265,  ...,  0.0179, -0.0884,  0.0201],\n                      ...,\n                      [ 0.0494,  0.0171, -0.0536,  ...,  0.0101, -0.0770, -0.0325],\n                      [ 0.0528,  0.0080, -0.0890,  ...,  0.0220, -0.0082,  0.0261],\n                      [ 0.0100,  0.0408,  0.0855,  ...,  0.0539, -0.0153,  0.0380]])),\n             ('roberta.encoder.layer.3.attention.self.query.lora_B',\n              tensor([[ 0.0347,  0.0496, -0.0958,  ..., -0.0155,  0.0604,  0.0056],\n                      [-0.0053,  0.0242, -0.0125,  ...,  0.0655, -0.0020,  0.0467],\n                      [ 0.0362, -0.0120,  0.0098,  ..., -0.0159, -0.0132,  0.0195],\n                      ...,\n                      [ 0.0265,  0.0335,  0.0331,  ..., -0.0791,  0.0343, -0.0268],\n                      [-0.0419, -0.0282,  0.0228,  ..., -0.0432, -0.0353,  0.0248],\n                      [ 0.0020,  0.0448,  0.0165,  ...,  0.0163,  0.0281, -0.0094]])),\n             ('roberta.encoder.layer.3.attention.self.value.lora_A',\n              tensor([[ 8.4126e-02, -1.8702e-02,  9.9994e-05,  ...,  7.5239e-02,\n                       -3.0672e-02, -4.3451e-02],\n                      [ 5.2148e-02,  4.5055e-03,  6.7427e-02,  ...,  4.2611e-03,\n                        8.4538e-03,  1.9672e-02],\n                      [-3.3304e-03,  6.9128e-02, -3.1854e-02,  ...,  6.1480e-02,\n                       -4.7597e-03, -5.6946e-02],\n                      ...,\n                      [-6.2381e-02, -1.7788e-04,  4.1930e-02,  ..., -5.1809e-02,\n                       -2.4801e-02, -5.7687e-02],\n                      [-3.2305e-02,  1.5562e-02,  1.5769e-02,  ..., -3.7406e-02,\n                       -8.5554e-02,  5.5735e-02],\n                      [ 4.2574e-02,  7.4901e-02,  2.4464e-02,  ..., -2.9075e-02,\n                        1.8830e-02,  3.2204e-02]])),\n             ('roberta.encoder.layer.3.attention.self.value.lora_B',\n              tensor([[-0.0191,  0.0064, -0.0598,  ..., -0.0175, -0.0516,  0.0155],\n                      [-0.0169, -0.0080,  0.0284,  ..., -0.0115, -0.0081, -0.0053],\n                      [ 0.0006,  0.0261,  0.0297,  ...,  0.0069,  0.0330,  0.0073],\n                      ...,\n                      [ 0.0034,  0.0075, -0.0229,  ...,  0.0216,  0.0103, -0.0189],\n                      [ 0.0488, -0.0421,  0.0411,  ...,  0.0410, -0.0119, -0.0541],\n                      [ 0.0024,  0.0089, -0.0337,  ..., -0.0345, -0.0431,  0.0177]])),\n             ('roberta.encoder.layer.4.attention.self.query.lora_A',\n              tensor([[-0.0887, -0.0463, -0.0313,  ..., -0.0554,  0.0229, -0.0158],\n                      [ 0.0226, -0.0511,  0.0422,  ...,  0.0436, -0.0109,  0.0301],\n                      [-0.0486,  0.0081,  0.0428,  ..., -0.0142,  0.0648, -0.1113],\n                      ...,\n                      [-0.0017,  0.0088, -0.0152,  ...,  0.0028,  0.0486, -0.0597],\n                      [ 0.0071,  0.0044,  0.0756,  ...,  0.0363,  0.0557, -0.0016],\n                      [-0.0214, -0.0441,  0.0225,  ...,  0.0180,  0.0222, -0.0919]])),\n             ('roberta.encoder.layer.4.attention.self.query.lora_B',\n              tensor([[-0.0307,  0.0840, -0.0724,  ...,  0.0434, -0.0037,  0.0607],\n                      [-0.0179,  0.0149,  0.0061,  ...,  0.0159,  0.0732, -0.0455],\n                      [-0.0050, -0.0238,  0.0064,  ..., -0.0162, -0.0135, -0.0062],\n                      ...,\n                      [ 0.0148, -0.0860,  0.0171,  ...,  0.0082,  0.0617,  0.0009],\n                      [-0.0024, -0.0247, -0.0782,  ..., -0.0351, -0.0173, -0.0162],\n                      [ 0.0839,  0.0123, -0.0298,  ..., -0.0018, -0.0411, -0.0006]])),\n             ('roberta.encoder.layer.4.attention.self.value.lora_A',\n              tensor([[ 0.0243,  0.0457,  0.0510,  ...,  0.0293,  0.0514, -0.0213],\n                      [-0.0164, -0.0207, -0.0249,  ...,  0.0685, -0.0716, -0.0050],\n                      [ 0.1038, -0.0874, -0.0135,  ...,  0.0169, -0.0427, -0.0528],\n                      ...,\n                      [ 0.0408,  0.0150, -0.0036,  ..., -0.0846,  0.0515, -0.0591],\n                      [-0.1140, -0.0563, -0.0311,  ...,  0.0562,  0.0417, -0.0188],\n                      [ 0.0966, -0.0076, -0.0645,  ...,  0.0087, -0.0289, -0.0373]])),\n             ('roberta.encoder.layer.4.attention.self.value.lora_B',\n              tensor([[ 0.0298, -0.0661,  0.0064,  ...,  0.0270, -0.0728,  0.0280],\n                      [ 0.0358, -0.0723,  0.0958,  ...,  0.0311, -0.1034,  0.0214],\n                      [-0.0197,  0.0081,  0.0075,  ...,  0.0324, -0.0174,  0.0540],\n                      ...,\n                      [ 0.0652, -0.0116, -0.0227,  ..., -0.0175, -0.0019, -0.0365],\n                      [-0.0246,  0.0106, -0.0107,  ..., -0.0192, -0.0099, -0.0090],\n                      [-0.0196,  0.0126,  0.0313,  ...,  0.0326, -0.0045,  0.0191]])),\n             ('roberta.encoder.layer.5.attention.self.query.lora_A',\n              tensor([[ 1.3522e-02, -3.4309e-03, -9.3906e-03,  ..., -7.9473e-02,\n                        8.4987e-02, -3.9745e-02],\n                      [-1.9509e-02, -4.1113e-02,  1.6730e-02,  ...,  2.4459e-02,\n                       -7.3262e-02,  2.3600e-02],\n                      [-3.5021e-02, -5.3008e-02,  3.9958e-02,  ...,  1.5610e-02,\n                       -8.7770e-02,  4.2173e-02],\n                      ...,\n                      [-6.2688e-02,  2.5047e-02, -9.5159e-02,  ..., -1.0448e-02,\n                        1.4089e-02,  4.3348e-07],\n                      [ 7.4189e-03, -5.3168e-02, -6.2067e-02,  ..., -3.1490e-02,\n                       -1.2707e-02,  4.5181e-02],\n                      [-5.8916e-03,  4.3201e-02,  4.8939e-03,  ..., -6.0904e-02,\n                        9.1987e-02, -1.3283e-02]])),\n             ('roberta.encoder.layer.5.attention.self.query.lora_B',\n              tensor([[-0.0222, -0.1107, -0.0946,  ...,  0.0687, -0.0498,  0.0657],\n                      [-0.0019, -0.0004,  0.0681,  ..., -0.0226, -0.0202, -0.0161],\n                      [ 0.0589, -0.0698, -0.0558,  ...,  0.0145, -0.0226,  0.0552],\n                      ...,\n                      [ 0.0148, -0.0379, -0.0209,  ..., -0.0125,  0.0307,  0.0465],\n                      [-0.0432,  0.0200, -0.0056,  ...,  0.0328,  0.0153, -0.0436],\n                      [ 0.0913, -0.0019,  0.0033,  ..., -0.0024, -0.0052, -0.0227]])),\n             ('roberta.encoder.layer.5.attention.self.value.lora_A',\n              tensor([[ 0.0337,  0.0230,  0.0741,  ...,  0.0178,  0.0499,  0.0304],\n                      [-0.0387,  0.0132, -0.0237,  ...,  0.0266,  0.0640,  0.0156],\n                      [ 0.0325, -0.0158,  0.0121,  ..., -0.0227,  0.0388, -0.0429],\n                      ...,\n                      [-0.1119, -0.1104,  0.0431,  ...,  0.0431, -0.0573,  0.0224],\n                      [-0.0240, -0.0625,  0.0601,  ...,  0.0679, -0.0199, -0.0328],\n                      [-0.0257, -0.0839,  0.0334,  ...,  0.0128, -0.1560,  0.1106]])),\n             ('roberta.encoder.layer.5.attention.self.value.lora_B',\n              tensor([[ 0.0623,  0.0499,  0.0293,  ..., -0.0713,  0.0548,  0.0118],\n                      [ 0.0599,  0.0473, -0.0020,  ..., -0.0252, -0.0169, -0.0184],\n                      [ 0.0345, -0.0448, -0.0351,  ..., -0.0190,  0.0045, -0.0437],\n                      ...,\n                      [-0.0151, -0.0263, -0.0458,  ..., -0.0072, -0.0304, -0.0352],\n                      [-0.0196, -0.0235, -0.0389,  ...,  0.0314, -0.0134,  0.1053],\n                      [ 0.0132,  0.0248,  0.0062,  ...,  0.0470, -0.0119,  0.0392]])),\n             ('roberta.encoder.layer.6.attention.self.query.lora_A',\n              tensor([[-0.0476,  0.0368,  0.0397,  ..., -0.0176,  0.0209, -0.0098],\n                      [-0.0151, -0.0378,  0.0807,  ..., -0.0263, -0.1088, -0.0511],\n                      [-0.0531, -0.0543,  0.0608,  ...,  0.0301,  0.0371, -0.0022],\n                      ...,\n                      [-0.0311,  0.0949,  0.0306,  ..., -0.0579,  0.0997,  0.0040],\n                      [-0.1046,  0.0168, -0.0447,  ..., -0.0517,  0.0608,  0.0738],\n                      [-0.0162,  0.0198, -0.0418,  ..., -0.0500, -0.0240,  0.0119]])),\n             ('roberta.encoder.layer.6.attention.self.query.lora_B',\n              tensor([[ 0.0067, -0.0357,  0.0428,  ...,  0.0191,  0.0127, -0.0126],\n                      [ 0.0145,  0.0789,  0.0069,  ...,  0.0116,  0.0179,  0.1020],\n                      [-0.0645,  0.0543,  0.0670,  ...,  0.0187, -0.0544, -0.0426],\n                      ...,\n                      [-0.0086, -0.0478,  0.0427,  ..., -0.0203,  0.0071, -0.0376],\n                      [-0.0245, -0.0026, -0.0449,  ...,  0.0511, -0.0540, -0.0156],\n                      [-0.0016, -0.0141, -0.0862,  ..., -0.0438, -0.0097,  0.0390]])),\n             ('roberta.encoder.layer.6.attention.self.value.lora_A',\n              tensor([[ 0.0326, -0.1410, -0.0213,  ..., -0.0064,  0.0746, -0.0776],\n                      [ 0.1255,  0.0187, -0.0186,  ..., -0.0011,  0.0871,  0.0271],\n                      [ 0.0402,  0.0767,  0.0165,  ...,  0.0127,  0.0879, -0.0200],\n                      ...,\n                      [-0.0954, -0.0480,  0.0477,  ...,  0.0076,  0.0423, -0.0220],\n                      [-0.0134, -0.0525, -0.0177,  ..., -0.0542, -0.0436,  0.0402],\n                      [ 0.0783, -0.0933,  0.0162,  ...,  0.0257, -0.0205, -0.0545]])),\n             ('roberta.encoder.layer.6.attention.self.value.lora_B',\n              tensor([[ 0.0059,  0.0124, -0.0514,  ...,  0.0636,  0.0036, -0.0005],\n                      [-0.0669,  0.0190,  0.0229,  ...,  0.0404,  0.0044,  0.0315],\n                      [-0.0579,  0.0167, -0.0591,  ...,  0.0494,  0.0212,  0.0327],\n                      ...,\n                      [-0.0127,  0.0390,  0.0322,  ..., -0.0188, -0.0153, -0.0113],\n                      [-0.0083, -0.0193,  0.0129,  ..., -0.0114, -0.0500, -0.0228],\n                      [ 0.0134,  0.0015, -0.0057,  ..., -0.0366,  0.0517, -0.0127]])),\n             ('roberta.encoder.layer.7.attention.self.query.lora_A',\n              tensor([[ 0.0596,  0.0189, -0.0201,  ..., -0.0413, -0.0076, -0.0625],\n                      [-0.0713, -0.0131,  0.0864,  ...,  0.0728,  0.0166, -0.0431],\n                      [ 0.0523, -0.0107, -0.0500,  ...,  0.0200, -0.0420, -0.0966],\n                      ...,\n                      [ 0.0927, -0.0554, -0.1098,  ..., -0.0805,  0.0172, -0.0072],\n                      [ 0.0551,  0.0086, -0.0514,  ..., -0.0256, -0.0330,  0.0819],\n                      [ 0.0048,  0.0284,  0.0103,  ...,  0.0194, -0.0078,  0.0759]])),\n             ('roberta.encoder.layer.7.attention.self.query.lora_B',\n              tensor([[ 0.0566, -0.0437,  0.0078,  ..., -0.0053, -0.0347, -0.0376],\n                      [ 0.0025,  0.0299,  0.0319,  ..., -0.0145, -0.0249,  0.0062],\n                      [ 0.0044,  0.0231, -0.0207,  ..., -0.0295,  0.0131,  0.0170],\n                      ...,\n                      [-0.0026, -0.0186, -0.0189,  ...,  0.0476, -0.0059, -0.0037],\n                      [-0.0131, -0.0034, -0.0638,  ..., -0.0357,  0.0249,  0.0167],\n                      [-0.0418,  0.0533, -0.0646,  ..., -0.0720, -0.0057,  0.0969]])),\n             ('roberta.encoder.layer.7.attention.self.value.lora_A',\n              tensor([[ 0.0062, -0.0069,  0.0446,  ..., -0.0536, -0.0554,  0.0395],\n                      [-0.0117,  0.0531,  0.0115,  ..., -0.0419, -0.0649,  0.0302],\n                      [ 0.0051, -0.0571,  0.0613,  ..., -0.0152, -0.0322,  0.0082],\n                      ...,\n                      [ 0.0124, -0.0193,  0.0499,  ...,  0.0164, -0.0011, -0.0114],\n                      [ 0.0235,  0.0080, -0.0117,  ...,  0.0023,  0.1026,  0.0277],\n                      [ 0.0156,  0.0790,  0.0164,  ...,  0.0402,  0.0093, -0.0385]])),\n             ('roberta.encoder.layer.7.attention.self.value.lora_B',\n              tensor([[ 2.2764e-02, -9.3771e-05, -9.7448e-03,  ..., -1.5649e-02,\n                       -3.4243e-03, -4.2520e-02],\n                      [-8.1606e-03, -1.4630e-02,  2.1378e-02,  ..., -2.2610e-02,\n                        1.3477e-02, -2.3278e-02],\n                      [ 2.4701e-02,  1.7462e-02, -1.2710e-02,  ...,  6.3123e-02,\n                        4.7096e-02,  4.3844e-02],\n                      ...,\n                      [ 2.5983e-02,  3.5171e-02,  5.6922e-02,  ...,  2.3292e-02,\n                       -3.0597e-02,  5.4749e-02],\n                      [-1.2989e-02,  2.7183e-02,  8.3437e-02,  ...,  3.8226e-02,\n                       -7.9098e-02,  7.9849e-02],\n                      [ 3.3650e-02,  6.9578e-02,  5.8423e-02,  ..., -1.8506e-02,\n                       -6.0916e-02, -1.5590e-02]])),\n             ('roberta.encoder.layer.8.attention.self.query.lora_A',\n              tensor([[ 0.0812,  0.0237,  0.0604,  ...,  0.0045, -0.1506, -0.0146],\n                      [ 0.0775,  0.0254, -0.1264,  ...,  0.0304, -0.0198, -0.0043],\n                      [ 0.1268, -0.0362, -0.0819,  ..., -0.0225, -0.0516, -0.0574],\n                      ...,\n                      [-0.0496, -0.0503, -0.0164,  ...,  0.0286,  0.0375,  0.0054],\n                      [ 0.0223,  0.0280,  0.0616,  ..., -0.0362, -0.0115,  0.0839],\n                      [ 0.0045, -0.0184,  0.0525,  ...,  0.0311,  0.0296,  0.0144]])),\n             ('roberta.encoder.layer.8.attention.self.query.lora_B',\n              tensor([[-0.0318, -0.0704, -0.0600,  ..., -0.0057,  0.0047, -0.0038],\n                      [-0.0562, -0.0067,  0.0031,  ..., -0.0012,  0.0012,  0.0321],\n                      [-0.0387, -0.0054, -0.0486,  ...,  0.0455, -0.0507, -0.0652],\n                      ...,\n                      [-0.0651,  0.0140,  0.0335,  ...,  0.0331, -0.0477, -0.0510],\n                      [ 0.0084,  0.0221,  0.0103,  ...,  0.0125, -0.0086, -0.0300],\n                      [ 0.0151, -0.0113, -0.0127,  ...,  0.0197, -0.0065, -0.0036]])),\n             ('roberta.encoder.layer.8.attention.self.value.lora_A',\n              tensor([[ 0.0037,  0.0553, -0.0449,  ...,  0.0670, -0.0278,  0.0100],\n                      [-0.0403, -0.0078,  0.0600,  ...,  0.0027, -0.0202, -0.0143],\n                      [ 0.0209, -0.0387,  0.0236,  ..., -0.0735, -0.0159,  0.0410],\n                      ...,\n                      [ 0.0829,  0.0080, -0.0198,  ...,  0.0218, -0.0452,  0.0008],\n                      [-0.0936, -0.0120, -0.0059,  ..., -0.0243,  0.0409,  0.0171],\n                      [ 0.0212, -0.0023, -0.0602,  ..., -0.0292, -0.0604,  0.0328]])),\n             ('roberta.encoder.layer.8.attention.self.value.lora_B',\n              tensor([[ 0.0480, -0.0198, -0.0011,  ...,  0.0131, -0.0225,  0.0258],\n                      [-0.0086,  0.0347,  0.0026,  ..., -0.0229,  0.0708, -0.0280],\n                      [-0.0003, -0.0051, -0.0306,  ...,  0.0084, -0.0109, -0.0043],\n                      ...,\n                      [ 0.0193, -0.0452, -0.0772,  ...,  0.0161, -0.0218, -0.0142],\n                      [-0.0732, -0.0209,  0.0382,  ..., -0.0380,  0.0623, -0.0013],\n                      [ 0.0110, -0.0363,  0.0265,  ...,  0.0120, -0.0499, -0.0179]])),\n             ('roberta.encoder.layer.9.attention.self.query.lora_A',\n              tensor([[ 0.0677,  0.0080, -0.0531,  ..., -0.0631,  0.0086, -0.0320],\n                      [-0.0216, -0.0262,  0.0041,  ...,  0.0122, -0.0106,  0.0322],\n                      [ 0.0192,  0.0818,  0.0322,  ...,  0.0046,  0.0288, -0.0982],\n                      ...,\n                      [-0.0072,  0.0649, -0.0323,  ...,  0.0426, -0.0721, -0.0665],\n                      [-0.0960, -0.0222, -0.0034,  ...,  0.0160,  0.0034,  0.0439],\n                      [-0.0788, -0.0102,  0.0237,  ..., -0.0597,  0.0130, -0.0133]])),\n             ('roberta.encoder.layer.9.attention.self.query.lora_B',\n              tensor([[ 0.0168, -0.0147,  0.0178,  ...,  0.0402, -0.0056, -0.0168],\n                      [-0.0473,  0.0413, -0.0245,  ..., -0.0023,  0.0543,  0.0286],\n                      [ 0.0756, -0.0352,  0.0248,  ...,  0.0212, -0.0230, -0.0568],\n                      ...,\n                      [ 0.0227, -0.0035, -0.0215,  ..., -0.0492,  0.0168,  0.0126],\n                      [-0.0225,  0.0211, -0.0193,  ..., -0.0114,  0.0310,  0.0022],\n                      [ 0.0179,  0.0026, -0.0019,  ..., -0.0235, -0.0415, -0.0058]])),\n             ('roberta.encoder.layer.9.attention.self.value.lora_A',\n              tensor([[ 0.0545, -0.0067, -0.0001,  ..., -0.0759,  0.0273,  0.0039],\n                      [ 0.0389,  0.0175,  0.0355,  ..., -0.0232, -0.0425, -0.0178],\n                      [-0.0348,  0.0043, -0.0230,  ...,  0.0461,  0.0018, -0.0014],\n                      ...,\n                      [ 0.0269,  0.0201, -0.0086,  ...,  0.0237,  0.0230,  0.0299],\n                      [-0.0202, -0.0203,  0.0080,  ...,  0.0662, -0.0055, -0.0059],\n                      [-0.0092,  0.0052, -0.0529,  ...,  0.0109, -0.0210,  0.0115]])),\n             ('roberta.encoder.layer.9.attention.self.value.lora_B',\n              tensor([[ 0.0274,  0.0078, -0.0201,  ...,  0.0154, -0.0290,  0.0208],\n                      [-0.0022,  0.0091,  0.0100,  ..., -0.0093, -0.0266,  0.0197],\n                      [ 0.0302, -0.0266, -0.0024,  ...,  0.0152, -0.0092,  0.0397],\n                      ...,\n                      [ 0.0361,  0.0799,  0.0147,  ..., -0.0014, -0.0640,  0.0736],\n                      [ 0.0583, -0.0195,  0.0271,  ...,  0.0442, -0.0295,  0.0539],\n                      [ 0.0009,  0.0484,  0.0132,  ..., -0.0510,  0.0097, -0.0212]])),\n             ('roberta.encoder.layer.10.attention.self.query.lora_A',\n              tensor([[-0.0131, -0.0963,  0.0053,  ..., -0.0446,  0.0222,  0.0319],\n                      [ 0.0218,  0.0758,  0.0363,  ...,  0.0108, -0.0262,  0.0091],\n                      [ 0.0254,  0.0679,  0.0305,  ...,  0.0395, -0.0416,  0.0136],\n                      ...,\n                      [ 0.0116, -0.0293,  0.0219,  ..., -0.0332,  0.0154,  0.0359],\n                      [ 0.0024,  0.0322,  0.0047,  ...,  0.0202,  0.0040, -0.0346],\n                      [-0.0051, -0.0893, -0.0194,  ..., -0.0172,  0.0735, -0.0593]])),\n             ('roberta.encoder.layer.10.attention.self.query.lora_B',\n              tensor([[ 0.0210, -0.0036, -0.0314,  ...,  0.0379, -0.0409,  0.0253],\n                      [-0.0270,  0.0068,  0.0258,  ..., -0.0279,  0.0296, -0.0418],\n                      [-0.0039, -0.0013, -0.0035,  ..., -0.0043,  0.0048,  0.0167],\n                      ...,\n                      [ 0.0179, -0.0168, -0.0233,  ...,  0.0204, -0.0230,  0.0347],\n                      [-0.0028,  0.0007,  0.0137,  ..., -0.0072,  0.0032, -0.0129],\n                      [ 0.0261, -0.0181, -0.0408,  ...,  0.0419, -0.0354,  0.0531]])),\n             ('roberta.encoder.layer.10.attention.self.value.lora_A',\n              tensor([[ 0.0293, -0.0257, -0.0478,  ..., -0.0068,  0.0140, -0.0056],\n                      [ 0.0301, -0.0029, -0.0668,  ...,  0.0179,  0.0285, -0.0605],\n                      [-0.0088,  0.0343, -0.0185,  ...,  0.0350,  0.0438, -0.0157],\n                      ...,\n                      [-0.0383,  0.0025, -0.0034,  ..., -0.0209, -0.0264,  0.0387],\n                      [-0.0108,  0.0414, -0.0403,  ...,  0.0500,  0.0393, -0.0121],\n                      [ 0.0211,  0.0116,  0.0334,  ..., -0.0189, -0.0402, -0.0231]])),\n             ('roberta.encoder.layer.10.attention.self.value.lora_B',\n              tensor([[-0.0132, -0.0120,  0.0048,  ..., -0.0273,  0.0150, -0.0008],\n                      [ 0.0759,  0.0518,  0.0531,  ..., -0.0202,  0.0406,  0.0021],\n                      [-0.0379, -0.0239, -0.0224,  ...,  0.0111, -0.0123, -0.0185],\n                      ...,\n                      [-0.0381,  0.0088,  0.0004,  ...,  0.0078,  0.0096, -0.0243],\n                      [-0.0036, -0.0215,  0.0153,  ...,  0.0197,  0.0117,  0.0529],\n                      [-0.0184,  0.0147,  0.0439,  ..., -0.0238,  0.0140, -0.0113]])),\n             ('roberta.encoder.layer.11.attention.self.query.lora_A',\n              tensor([[-6.1163e-02,  2.2987e-02, -3.0461e-02,  ..., -2.8454e-02,\n                        3.1928e-02, -3.8497e-02],\n                      [ 5.6456e-02, -6.2001e-02, -5.1524e-02,  ..., -1.2194e-02,\n                       -2.0903e-02, -5.4315e-03],\n                      [ 5.8009e-02, -4.2476e-02, -9.0509e-03,  ...,  2.3104e-02,\n                       -4.1823e-02,  2.2825e-02],\n                      ...,\n                      [-7.3580e-02,  3.5630e-02, -7.7870e-05,  ..., -3.0242e-03,\n                        3.0233e-02, -2.5657e-02],\n                      [ 4.3940e-02, -4.0682e-02, -2.4687e-02,  ...,  4.1767e-03,\n                       -5.4858e-03,  3.8959e-03],\n                      [-5.1257e-02,  1.7466e-02, -1.0626e-02,  ..., -2.8614e-03,\n                        1.9107e-02, -3.8401e-02]])),\n             ('roberta.encoder.layer.11.attention.self.query.lora_B',\n              tensor([[ 8.7776e-03, -1.9222e-02, -1.4145e-02,  ...,  1.1083e-02,\n                       -1.7917e-02,  1.7847e-02],\n                      [ 1.7225e-02, -4.1018e-03, -1.5448e-02,  ...,  7.6522e-03,\n                       -1.6829e-03,  1.4175e-02],\n                      [-5.8497e-02,  5.7934e-02,  5.6302e-02,  ..., -5.5452e-02,\n                        5.5538e-02, -5.6192e-02],\n                      ...,\n                      [ 1.7975e-03,  8.3457e-03, -4.3902e-05,  ..., -4.8657e-03,\n                        1.6735e-02, -4.2159e-03],\n                      [-9.1476e-02,  6.4823e-02,  8.2943e-02,  ..., -6.8899e-02,\n                        5.4182e-02, -7.9584e-02],\n                      [-1.2026e-02, -6.2556e-03,  5.8916e-03,  ..., -5.6947e-03,\n                       -1.0286e-03, -1.3003e-02]])),\n             ('roberta.encoder.layer.11.attention.self.value.lora_A',\n              tensor([[-0.0776,  0.0450,  0.0259,  ...,  0.0508, -0.0443, -0.0129],\n                      [ 0.0327,  0.0439,  0.0772,  ..., -0.0079, -0.0256,  0.0448],\n                      [ 0.0510, -0.0513, -0.0517,  ..., -0.0381,  0.0431, -0.0082],\n                      ...,\n                      [ 0.0275, -0.0293, -0.0611,  ..., -0.0308,  0.0237, -0.0125],\n                      [-0.0723,  0.0448,  0.0147,  ...,  0.0290, -0.0606,  0.0019],\n                      [-0.0227, -0.0193, -0.0488,  ...,  0.0148,  0.0076, -0.0201]])),\n             ('roberta.encoder.layer.11.attention.self.value.lora_B',\n              tensor([[ 0.0269,  0.0291, -0.0255,  ..., -0.0421,  0.0206, -0.0167],\n                      [ 0.0208, -0.0002, -0.0284,  ...,  0.0098,  0.0090,  0.0269],\n                      [-0.0806, -0.0195,  0.0731,  ...,  0.0655, -0.0668, -0.0048],\n                      ...,\n                      [-0.0128,  0.0070,  0.0242,  ...,  0.0016,  0.0207, -0.0185],\n                      [ 0.0054,  0.0490, -0.0121,  ..., -0.0100, -0.0044, -0.0108],\n                      [-0.0237,  0.0663,  0.0108,  ...,  0.0069, -0.0049, -0.0362]])),\n             ('classifier.dense.weight',\n              tensor([[ 0.0117,  0.0120, -0.0083,  ...,  0.0087,  0.0192,  0.0470],\n                      [-0.0124,  0.0162, -0.0270,  ...,  0.0188, -0.0292,  0.0244],\n                      [-0.0014, -0.0169,  0.0146,  ..., -0.0182,  0.0338,  0.0326],\n                      ...,\n                      [ 0.0240, -0.0217,  0.0276,  ..., -0.0056, -0.0210, -0.0028],\n                      [ 0.0296, -0.0146, -0.0154,  ...,  0.0137, -0.0036,  0.0066],\n                      [ 0.0259, -0.0381,  0.0175,  ..., -0.0438, -0.0208, -0.0242]])),\n             ('classifier.dense.bias',\n              tensor([ 1.4323e-04,  1.2846e-03,  1.1815e-03,  1.3741e-03,  6.6699e-04,\n                       9.1406e-04,  2.3541e-04,  1.4081e-03,  4.6728e-04, -3.3836e-04,\n                      -7.4588e-04, -1.5730e-03,  3.6003e-04, -1.3481e-04, -3.3723e-04,\n                      -9.0568e-04, -1.0251e-03, -3.2085e-04, -2.1173e-04, -4.3671e-04,\n                      -9.8845e-04, -3.0979e-04, -2.6630e-03,  1.6805e-04,  7.2896e-04,\n                       1.0199e-03,  7.5981e-04, -3.2573e-04, -1.3606e-03,  5.0354e-04,\n                       1.7423e-03,  1.1015e-03,  1.1882e-03, -2.6515e-03, -3.8210e-04,\n                      -1.3220e-03, -2.8332e-04, -2.7151e-04,  7.7803e-04, -1.2590e-03,\n                       9.3388e-04, -2.5079e-04, -2.0111e-03, -4.1049e-04, -1.0194e-03,\n                      -2.0139e-04,  2.1971e-03,  7.6690e-04, -4.2277e-04,  2.0390e-04,\n                       6.2761e-04,  6.0533e-04, -1.2181e-03,  8.7695e-04,  9.2385e-04,\n                       9.1485e-04,  1.1460e-04,  9.0728e-04, -3.6311e-04,  1.0736e-03,\n                      -5.3810e-04, -4.0905e-04,  8.1588e-04, -7.2902e-04,  6.0276e-04,\n                       9.0728e-04, -2.1299e-04,  1.2603e-04, -5.5188e-04, -2.1692e-03,\n                       8.4975e-04,  7.9182e-04, -1.2371e-06,  1.2144e-03, -9.0643e-04,\n                       1.9946e-04, -5.8568e-04,  6.5279e-04, -5.4931e-04,  8.6442e-04,\n                      -8.1590e-04,  1.9741e-04, -1.2218e-03, -1.7791e-04, -1.8459e-03,\n                       2.1339e-04,  3.8926e-04,  1.2471e-03,  8.8429e-04, -7.6841e-04,\n                      -8.0224e-04, -7.3633e-05,  1.0602e-03,  1.3976e-03,  1.1862e-04,\n                      -1.7278e-03, -1.3226e-04, -5.0057e-04, -1.0574e-03,  5.9206e-04,\n                       1.9260e-04,  1.7060e-03, -1.6976e-03, -1.1938e-03,  4.1993e-04,\n                       8.2552e-04,  1.1747e-03, -5.4692e-04, -8.3509e-04,  7.2850e-04,\n                       1.7597e-03, -9.1889e-05,  1.1539e-04, -1.8008e-03,  1.1647e-03,\n                       1.1508e-03, -8.1015e-04,  2.9747e-05, -2.4767e-03,  2.7466e-03,\n                       3.1424e-04, -4.1500e-04, -5.7110e-04,  1.2013e-03, -3.7010e-04,\n                      -5.3474e-04,  7.9482e-04,  9.0076e-04,  8.0656e-04,  1.2798e-03,\n                      -3.9400e-04,  1.0191e-03,  8.6851e-05, -5.0648e-04, -9.0693e-04,\n                      -1.5269e-03,  7.8766e-04, -1.1897e-03, -1.3165e-03, -3.0853e-06,\n                       9.3052e-04,  1.7445e-03,  8.3421e-04,  1.1761e-03,  1.2223e-03,\n                      -5.8273e-04, -3.4227e-04, -4.0972e-04, -1.3951e-03,  4.0385e-04,\n                      -3.8729e-04,  5.0338e-05, -1.1947e-03, -1.6587e-03,  6.3761e-04,\n                      -1.6640e-03,  1.1153e-03,  1.1410e-03,  7.1212e-04,  1.3506e-03,\n                      -1.2070e-03, -1.0521e-03, -7.2358e-04, -1.4232e-03, -4.2747e-04,\n                      -7.4361e-04,  1.8610e-03, -8.0913e-04, -6.4412e-04,  1.6685e-03,\n                       6.5513e-04,  3.1863e-04,  4.0457e-04,  1.4375e-03, -2.5077e-05,\n                       2.3913e-04, -9.6403e-04, -1.0342e-03,  1.5237e-03,  1.1576e-03,\n                      -5.6068e-04,  1.9149e-03,  1.7460e-03,  1.6788e-04, -1.1630e-03,\n                      -1.0092e-04, -2.1124e-04, -4.9492e-04,  1.0426e-03, -5.6609e-05,\n                       4.4306e-04, -1.6358e-04, -8.1332e-04, -4.7787e-04, -1.2207e-03,\n                       9.9799e-04,  2.0801e-04, -5.7826e-04,  3.3206e-04, -4.0498e-04,\n                       1.3523e-03, -1.4439e-04,  1.2682e-03, -2.8350e-03,  1.0432e-03,\n                       2.1079e-04, -8.2381e-04, -6.6387e-04, -6.3463e-04,  2.9948e-04,\n                       1.7914e-04, -2.2641e-04, -5.7464e-04, -2.0864e-04, -1.5903e-03,\n                       4.6289e-04, -5.4347e-04, -6.6215e-04, -3.1632e-03, -3.0699e-04,\n                       6.2917e-04,  7.5890e-04,  1.4956e-04,  9.9407e-05, -2.2027e-04,\n                      -5.1714e-04, -8.6224e-04,  1.3111e-04,  1.3386e-04,  8.2470e-04,\n                       9.4781e-04, -2.3199e-04, -5.9274e-05,  1.3677e-04,  2.9967e-04,\n                       2.2991e-04, -1.8549e-03,  7.5595e-04, -1.9850e-04,  2.0207e-04,\n                      -7.6739e-04, -8.3831e-04, -3.2776e-04, -8.4723e-04,  1.1102e-03,\n                       8.7097e-04, -6.4522e-04,  1.8442e-03,  1.4723e-03, -8.4347e-05,\n                      -2.0189e-04, -1.1704e-03,  3.5397e-04,  4.8071e-04, -8.5605e-04,\n                       2.5104e-03, -9.8527e-04, -5.6521e-04, -5.4028e-04, -4.0828e-04,\n                      -4.7036e-05,  1.0052e-03, -1.2124e-03,  9.5621e-04,  2.3658e-04,\n                       2.5777e-04,  1.4007e-03,  3.6306e-04, -4.8274e-04,  4.7458e-04,\n                      -2.0306e-03,  8.9404e-04,  1.5348e-03,  8.3183e-05,  2.2250e-04,\n                      -7.4934e-04,  3.8918e-04, -2.6876e-04,  3.1910e-04, -3.8303e-04,\n                      -3.8770e-04,  7.3559e-04,  6.5786e-05,  6.2279e-04, -4.6266e-04,\n                      -2.4858e-04,  1.9443e-03, -1.0660e-04, -1.2248e-03,  6.8297e-04,\n                      -7.2158e-04,  2.9704e-04, -1.0337e-04, -1.2188e-03, -2.7289e-04,\n                       5.8494e-05, -6.7643e-04, -9.9545e-04,  4.8629e-04, -1.6008e-03,\n                       7.9726e-04, -3.4825e-04, -3.9549e-04, -1.3751e-03, -5.2535e-04,\n                      -7.6465e-05,  3.9663e-04, -3.9642e-04, -7.7228e-04,  3.8786e-04,\n                       4.1712e-04,  2.9147e-05, -3.4668e-04, -2.6294e-04, -2.2744e-04,\n                       7.3365e-04, -8.3460e-04,  2.3122e-04, -9.1316e-04,  2.1589e-03,\n                       7.1786e-04,  7.8091e-04, -8.0086e-04,  6.1835e-04, -1.1315e-03,\n                      -6.0925e-04,  5.5897e-04, -1.0043e-03, -6.8763e-04, -1.9490e-05,\n                       8.8597e-04, -7.8854e-04,  1.4882e-03,  1.1153e-04,  1.6186e-03,\n                      -1.2551e-03, -1.7603e-03, -1.1395e-03,  9.6064e-04,  3.3627e-04,\n                       1.2359e-03,  3.5107e-04, -4.8746e-05, -5.0412e-04, -1.0969e-03,\n                       1.5683e-03, -6.6912e-04, -1.8524e-04,  1.3080e-03,  3.9699e-04,\n                       1.0335e-03, -9.6427e-04,  1.0288e-03, -1.0738e-03, -3.1591e-04,\n                      -2.4323e-04,  9.0713e-05,  9.1777e-04,  3.4787e-05,  2.0335e-04,\n                      -7.9674e-04, -6.1139e-04, -1.7735e-04, -1.5337e-04, -6.8349e-04,\n                      -3.6173e-04, -1.3710e-03,  1.2964e-03, -1.5911e-04,  2.9047e-03,\n                      -8.2844e-04,  9.9295e-04, -1.1369e-03, -7.3473e-05,  6.5455e-04,\n                       1.5269e-03, -6.3746e-04,  1.1795e-03,  2.0090e-03,  4.3834e-04,\n                       3.8070e-04,  1.1605e-03, -2.5465e-04,  4.7727e-04, -1.0017e-03,\n                       9.7787e-04, -6.7510e-04,  2.9254e-04,  2.5929e-05,  8.6173e-04,\n                       3.3353e-04,  9.5972e-04,  1.6975e-03,  4.9391e-04, -5.6189e-04,\n                       1.8776e-03, -1.7038e-03, -6.6783e-04, -8.0791e-05,  9.3125e-04,\n                       5.1823e-04, -2.9953e-04, -4.0683e-04, -1.4313e-03,  1.4173e-03,\n                      -1.0051e-04, -1.2423e-04, -3.1590e-04, -5.6619e-04, -1.2159e-03,\n                      -2.3773e-04, -1.7091e-03,  1.0251e-03,  4.5029e-04,  9.6850e-04,\n                       4.2436e-04, -6.3867e-04, -3.2606e-04,  3.4135e-03, -7.1750e-04,\n                      -6.5369e-04, -9.4402e-04,  5.2744e-05, -4.7515e-04, -1.2587e-03,\n                       9.3866e-04, -7.8740e-04, -1.7277e-03, -3.1258e-04,  3.4704e-05,\n                       9.6326e-04, -2.9346e-03,  4.2203e-04, -5.8493e-04,  4.0515e-04,\n                       9.1759e-04, -3.2363e-04,  1.4135e-04,  1.2760e-03,  4.2539e-04,\n                       1.4684e-03, -1.5188e-03,  1.8076e-03,  3.5850e-04,  3.9089e-04,\n                       6.1090e-05, -5.0390e-04, -9.0819e-04, -2.0948e-04, -6.0569e-04,\n                       5.3924e-04,  2.5273e-03, -1.3986e-03,  2.3087e-05, -1.7486e-03,\n                      -2.7466e-04,  9.7019e-04,  1.2963e-03, -5.3363e-04,  4.0390e-04,\n                       2.7740e-03, -9.7201e-04,  1.2798e-03, -7.5384e-04,  5.9516e-04,\n                      -3.7651e-04,  6.7793e-04, -1.1888e-03,  6.3617e-04, -7.7864e-05,\n                       4.6457e-04, -1.1054e-03, -8.8280e-04, -6.2179e-04,  2.6918e-05,\n                      -4.3774e-04,  5.4735e-04, -7.7931e-04, -1.3414e-03,  9.9184e-04,\n                       1.2236e-05, -1.2862e-03,  7.7436e-04, -5.5365e-04, -8.6073e-04,\n                       2.3124e-04, -1.7994e-03,  8.1624e-04,  6.9303e-04, -7.4358e-04,\n                       3.0775e-04, -5.7380e-04, -1.4429e-03,  1.5994e-03, -5.9927e-04,\n                      -6.3657e-04,  9.3230e-04,  2.8109e-04, -3.2446e-04,  1.2638e-03,\n                       4.2485e-04, -1.3157e-03,  9.3974e-04, -8.7932e-04,  3.4710e-04,\n                       1.5597e-03, -2.2636e-03,  6.2443e-04,  2.0448e-03, -1.0620e-03,\n                      -1.6075e-05,  1.8676e-03, -6.8718e-05,  5.2409e-04,  1.1590e-03,\n                      -5.2333e-04,  8.1949e-04, -1.1209e-03,  7.7076e-04,  5.7026e-04,\n                      -3.4147e-04,  8.4021e-05, -1.6025e-03,  8.6735e-04, -1.3240e-03,\n                       1.2433e-03, -7.0315e-04,  1.1959e-03, -2.1370e-04,  4.6354e-04,\n                      -6.7193e-04,  7.8646e-04, -7.8545e-04,  1.1236e-03, -1.1280e-03,\n                       1.4629e-04,  2.4125e-04,  8.5113e-04,  9.4495e-04,  7.9561e-04,\n                      -1.1113e-03,  1.2678e-03,  5.3265e-04, -6.2383e-04,  1.2227e-03,\n                       7.2598e-04, -6.9132e-04, -1.5599e-03, -3.6623e-03, -1.5112e-03,\n                      -1.1515e-03, -2.7825e-04, -3.4875e-04,  3.2637e-04,  1.2991e-03,\n                       6.2565e-04,  1.4337e-03, -1.3864e-04,  9.2931e-04, -8.7797e-04,\n                      -1.4686e-03,  8.3205e-04, -6.0587e-04, -1.9721e-04,  4.9598e-04,\n                       8.9289e-04,  2.5102e-03,  4.7776e-04,  4.0610e-04, -3.8494e-04,\n                      -1.2952e-04,  1.2377e-03,  4.3714e-05,  5.6277e-04,  3.6699e-04,\n                       2.0556e-04, -7.5023e-04, -9.8841e-04, -1.5409e-03, -3.0011e-04,\n                       1.5373e-04,  9.8371e-04, -3.0652e-05, -6.3339e-07, -6.9460e-04,\n                       1.2998e-03, -1.9836e-03, -5.9281e-04, -1.3493e-03, -8.9729e-04,\n                       1.4573e-03, -1.4108e-03,  4.2566e-03,  1.0479e-03, -1.1484e-03,\n                      -2.6325e-05, -1.6868e-03, -4.9152e-04,  1.0355e-03,  5.4707e-04,\n                       7.1946e-05, -9.7133e-04, -1.6303e-03,  1.6959e-04,  2.5688e-04,\n                      -2.5292e-04, -4.2351e-04, -1.3996e-03,  1.0093e-04, -1.0279e-03,\n                      -1.5119e-03, -8.9937e-04, -1.1252e-03,  6.1409e-04, -6.5657e-04,\n                      -1.0421e-03,  1.3473e-03,  8.6904e-04, -7.2719e-04,  1.5072e-03,\n                       2.4596e-04,  5.7351e-04,  5.1860e-04, -2.8874e-04, -4.0873e-04,\n                       2.9425e-04, -6.3612e-04, -7.6895e-04,  4.6390e-04, -1.2668e-03,\n                      -5.7708e-04, -4.7950e-04, -9.0049e-04,  3.0589e-04,  6.7148e-04,\n                      -3.2745e-04, -2.2596e-04, -5.1159e-04, -7.6072e-04, -1.1024e-03,\n                       1.0572e-03,  1.3643e-03, -7.4281e-04, -8.3276e-04,  2.4831e-04,\n                      -6.4620e-05, -7.0444e-04, -3.2346e-05, -1.2795e-03,  6.2657e-05,\n                      -1.1704e-03,  7.5910e-04, -9.3546e-04, -8.3773e-04, -7.9195e-04,\n                       3.9926e-04, -3.3244e-04, -4.1014e-04,  6.6722e-04, -3.3808e-04,\n                      -1.0087e-03,  5.5722e-04, -5.2375e-05, -1.2505e-04,  1.5315e-03,\n                       1.3721e-03, -1.8471e-03,  8.2545e-08,  8.7091e-05,  1.0442e-03,\n                       1.5180e-03, -1.4217e-03,  1.6458e-04,  2.5436e-03,  8.4385e-04,\n                       6.6180e-04,  1.9089e-03,  1.1639e-03,  4.9350e-04, -2.1838e-04,\n                       1.6620e-03, -7.3495e-04, -2.1441e-04, -1.5796e-03,  4.3184e-04,\n                       1.1852e-03,  9.6671e-04, -1.3836e-03, -3.9109e-04,  1.8562e-03,\n                       3.1361e-04, -3.4927e-04, -2.9445e-03, -5.4246e-04,  6.2977e-04,\n                       5.0782e-05, -1.3844e-03, -1.3468e-03,  1.0247e-03,  4.2030e-04,\n                       7.8760e-04, -5.9565e-04, -2.1536e-04, -2.6764e-05, -4.0201e-04,\n                      -1.1784e-03,  2.1190e-03, -1.0962e-03,  1.0530e-03,  4.0725e-04,\n                      -2.9041e-04, -6.2502e-04, -9.2387e-04, -1.7763e-03,  3.4900e-04,\n                       3.1505e-03,  5.7129e-04,  4.8220e-04,  6.6100e-04,  9.8009e-04,\n                       1.2241e-03,  8.8722e-04, -1.6751e-04,  4.8133e-04,  5.5157e-04,\n                      -7.1508e-06,  2.2720e-04, -4.7360e-04,  1.5750e-03, -3.8591e-03,\n                      -4.3960e-04, -8.8459e-04, -1.6772e-03, -3.4093e-04,  5.4348e-05,\n                      -8.6301e-04, -3.6378e-04,  6.4545e-04, -7.4142e-04,  4.1263e-04,\n                      -2.9984e-03, -2.0323e-03,  2.1527e-04,  7.3124e-04,  3.5464e-04,\n                       1.4334e-03, -7.3181e-04, -2.0931e-05,  1.7261e-03, -1.5164e-04,\n                      -1.0194e-03,  1.3569e-03,  4.6392e-04,  3.2685e-05,  1.8171e-03,\n                      -4.6514e-04, -8.7425e-04, -1.5213e-03,  9.1843e-04,  1.4300e-03,\n                       1.2690e-04, -3.9115e-04, -1.1068e-03, -7.3905e-04,  2.5691e-04,\n                      -9.7867e-04,  1.2859e-03,  6.8425e-04])),\n             ('classifier.out_proj.weight',\n              tensor([[ 0.0138, -0.0246,  0.0110,  ...,  0.0201,  0.0150, -0.0138],\n                      [-0.0058,  0.0107,  0.0205,  ..., -0.0288,  0.0267,  0.0158]])),\n             ('classifier.out_proj.bias', tensor([-0.0005,  0.0005]))])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" LoRA 결과 해석 재현 \"\"\"\n",
    "pt_config = AutoConfig.from_pretrained('FacebookAI/roberta-base')\n",
    "pt_model = AutoModel.from_pretrained(\n",
    "    'FacebookAI/roberta-base',\n",
    "    config=pt_config\n",
    ")\n",
    "\n",
    "lora_checkpoint = torch.load('model/roberta_base_lora_mrpc.bin', map_location='cpu')\n",
    "lora_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T08:59:58.551169Z",
     "start_time": "2024-04-01T08:59:56.852465Z"
    }
   },
   "id": "5aa9ad7c8de26322",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([768, 768]),\n torch.Size([8, 768]),\n torch.Size([768, 8]),\n torch.Size([768, 768]))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Select Wq in 6-th encoder layer \"\"\"\n",
    "\n",
    "pt_wq, lora_a, lora_b = pt_model.encoder.layer[6].attention.self.query.weight, lora_checkpoint['roberta.encoder.layer.6.attention.self.query.lora_A'], lora_checkpoint['roberta.encoder.layer.6.attention.self.query.lora_B']\n",
    "delta_wq = lora_b @ lora_a\n",
    "pt_wq.shape, lora_a.shape, lora_b.shape, delta_wq.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T08:59:59.549887Z",
     "start_time": "2024-04-01T08:59:59.545644Z"
    }
   },
   "id": "b6f3539181199627",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta W U: torch.Size([768, 768])\n",
      "Delta W S: torch.Size([768])\n",
      "Delta W V: torch.Size([768, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[-0.0441,  0.0447,  0.0323,  0.0963],\n         [-0.0038, -0.0412, -0.0903, -0.0949],\n         [-0.0314,  0.1003, -0.0599,  0.0023],\n         [-0.0222, -0.1090,  0.0315,  0.0575]], grad_fn=<MmBackward0>),\n tensor(0.2539, grad_fn=<LinalgVectorNormBackward0>))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Let's SVD, select top-r singular vector \"\"\"\n",
    "\n",
    "U, S, V = torch.svd(delta_wq)\n",
    "print(f\"Delta W U: {U.shape}\")\n",
    "print(f\"Delta W S: {S.shape}\")\n",
    "print(f\"Delta W V: {V.shape}\")\n",
    "\n",
    "r = 4\n",
    "r_U, r_V = U[:, :r], V[:r, :]\n",
    "result1 = torch.matmul(r_U.T @ pt_wq, r_V.T)\n",
    "fwq_norm = torch.norm(result1)\n",
    "result1, fwq_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:00:00.673824Z",
     "start_time": "2024-04-01T09:00:00.631307Z"
    }
   },
   "id": "3d8d278fb3e8fd58",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5.0820)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ∥∆W ∥F\"\"\"\n",
    "fdwq_norm = torch.norm(delta_wq)\n",
    "fdwq_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:00:03.599651Z",
     "start_time": "2024-04-01T09:00:03.595919Z"
    }
   },
   "id": "d41a63a830c8335a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(20.0170, grad_fn=<DivBackward0>)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Final \"\"\"\n",
    "\n",
    "fdwq_norm / fwq_norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:00:04.649701Z",
     "start_time": "2024-04-01T09:00:04.646262Z"
    }
   },
   "id": "3b4309bb6780300a",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), Embedding(10, 4))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Test code for making rotary embedding more computational efficient \"\"\"\n",
    "\n",
    "position = torch.arange(0, 10, dtype=torch.long)\n",
    "pos_embedding = nn.Embedding(10, 4)\n",
    "position, pos_embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T21:55:36.613473Z",
     "start_time": "2024-03-15T21:55:36.597953Z"
    }
   },
   "id": "c535fa9ae48b2e11",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.3922,  0.8835],\n         [ 0.3392,  0.0947],\n         [ 0.3570, -0.6238],\n         [-0.1659, -0.4547],\n         [-0.8697,  1.9447],\n         [-0.0843, -0.2012],\n         [ 0.7752, -0.4308],\n         [ 2.1914,  0.8687],\n         [-0.5303,  0.8186],\n         [-1.2912,  1.4390]], grad_fn=<SplitBackward0>),\n tensor([[-0.9374,  0.7161],\n         [-0.5622, -0.5999],\n         [-0.8200,  0.9056],\n         [ 1.4742, -0.0596],\n         [-0.2230,  2.0772],\n         [ 1.3687,  0.7459],\n         [-1.0737, -0.4662],\n         [-0.2012, -1.2607],\n         [-0.3093, -0.4485],\n         [ 0.9633,  1.0118]], grad_fn=<SplitBackward0>))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = pos_embedding(position)\n",
    "sin, cos = pos_emb.chunk(2, dim=-1) \n",
    "sin, cos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T21:56:21.993027Z",
     "start_time": "2024-03-15T21:56:21.989136Z"
    }
   },
   "id": "b03f19b1ac4400e4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.3922, -0.3922,  0.8835,  0.8835],\n         [ 0.3392,  0.3392,  0.0947,  0.0947],\n         [ 0.3570,  0.3570, -0.6238, -0.6238],\n         [-0.1659, -0.1659, -0.4547, -0.4547],\n         [-0.8697, -0.8697,  1.9447,  1.9447],\n         [-0.0843, -0.0843, -0.2012, -0.2012],\n         [ 0.7752,  0.7752, -0.4308, -0.4308],\n         [ 2.1914,  2.1914,  0.8687,  0.8687],\n         [-0.5303, -0.5303,  0.8186,  0.8186],\n         [-1.2912, -1.2912,  1.4390,  1.4390]], grad_fn=<ReshapeAliasBackward0>),\n torch.Size([10, 4]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Sine \"\"\"\n",
    "sin_pos = torch.stack([sin, sin], dim=-1).reshape_as(pos_emb)\n",
    "sin_pos, sin_pos.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T22:15:30.879691Z",
     "start_time": "2024-03-15T22:15:30.875592Z"
    }
   },
   "id": "c511b2e1e8e60f98",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.9374, -0.9374,  0.7161,  0.7161],\n         [-0.5622, -0.5622, -0.5999, -0.5999],\n         [-0.8200, -0.8200,  0.9056,  0.9056],\n         [ 1.4742,  1.4742, -0.0596, -0.0596],\n         [-0.2230, -0.2230,  2.0772,  2.0772],\n         [ 1.3687,  1.3687,  0.7459,  0.7459],\n         [-1.0737, -1.0737, -0.4662, -0.4662],\n         [-0.2012, -0.2012, -1.2607, -1.2607],\n         [-0.3093, -0.3093, -0.4485, -0.4485],\n         [ 0.9633,  0.9633,  1.0118,  1.0118]], grad_fn=<ReshapeAliasBackward0>),\n torch.Size([10, 4]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Cosine \"\"\"\n",
    "cos_pos = torch.stack([cos, cos], dim=-1).reshape_as(pos_emb)\n",
    "cos_pos, cos_pos.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T22:17:12.154057Z",
     "start_time": "2024-03-15T22:17:12.149641Z"
    }
   },
   "id": "6ffeb6cf75242320",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 5, 4, 8]), torch.Size([3, 5, 4, 4]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Tensor indexing\n",
    "... => :,:,:\n",
    "\"\"\"\n",
    "\n",
    "query = torch.rand(3, 5, 4, 8, device=device)\n",
    "query.shape, query[:,:,:, 1::2].shape  # ... => 모든 차원 select, 시작 위치::스탭 크기"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T22:23:28.302582Z",
     "start_time": "2024-03-15T22:23:28.299023Z"
    }
   },
   "id": "98a29c4184d9ee14",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([16, 12, 512, 32]), torch.Size([16, 12, 512, 32]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.rand(16, 12, 512, 64, device=device)\n",
    "test[:,:,:, ::2].shape, test[..., ::2].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T22:26:28.547870Z",
     "start_time": "2024-03-15T22:26:28.543955Z"
    }
   },
   "id": "b9b14044390f8889",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-1.5524,  0.6596,  2.4447,  0.2761],\n         [ 0.2821,  0.1620,  0.9388, -0.7997],\n         [ 0.7599, -0.9758,  0.1258, -2.2957],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[-0.5441,  0.2044, -1.0543, -0.6610],\n         [ 0.2436,  0.3609,  1.6111,  0.0072],\n         [-0.4589, -0.5709, -0.9771, -0.9881],\n         [-0.3361, -0.6272, -0.0786,  1.5555],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[-0.5229,  0.7038, -0.5714,  2.3070],\n         [-0.6425,  0.7309, -1.4076,  0.0123],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = torch.tensor([\n",
    "    [0,0,0,1,1],\n",
    "    [0,0,0,0,1],\n",
    "    [0,0,1,1,1]\n",
    "]).to(device)\n",
    "key = torch.randn(3, 5, 4, device=device)\n",
    "key[padding_mask == 1] = 0\n",
    "key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:18:03.234633Z",
     "start_time": "2024-03-14T23:18:03.229670Z"
    }
   },
   "id": "93d5426bb9f73f79",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1207959552"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.rand(512, 768, 768, requires_grad=False, device=device)\n",
    "element_size, num_elements = test.element_size(), test.numel()\n",
    "memory_size = element_size * num_elements\n",
    "memory_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T14:18:03.354736Z",
     "start_time": "2024-03-09T14:18:03.340634Z"
    }
   },
   "id": "944facfd62c7ff39",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler tensor: (tensor([[[1., 1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3., 3.],\n",
      "         [4., 4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3., 3.],\n",
      "         [4., 4., 4., 4., 4., 4.]]], device='cuda:0'), torch.Size([2, 4, 6]))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[[0.8779, 0.3744, 0.3236, 0.7615, 0.3494, 0.2805],\n          [0.5583, 0.4323, 0.7704, 0.2998, 0.6243, 0.1674],\n          [0.4235, 0.8064, 0.3026, 0.2402, 0.6097, 0.7895],\n          [0.3535, 0.9134, 0.1527, 0.5949, 0.6882, 0.5629]],\n \n         [[0.5002, 0.6934, 0.1638, 0.4659, 0.5179, 0.3682],\n          [0.0644, 0.6148, 0.5767, 0.6943, 0.1547, 0.4829],\n          [0.5885, 0.2067, 0.9069, 0.6666, 0.0275, 0.5214],\n          [0.7359, 0.3934, 0.3014, 0.2766, 0.2825, 0.0026]]], device='cuda:0'),\n tensor([[[0.8779, 0.3744, 0.3236, 0.7615, 0.3494, 0.2805],\n          [1.1165, 0.8646, 1.5407, 0.5996, 1.2486, 0.3347],\n          [1.2704, 2.4192, 0.9077, 0.7206, 1.8291, 2.3685],\n          [1.4140, 3.6534, 0.6109, 2.3797, 2.7529, 2.2514]],\n \n         [[0.5002, 0.6934, 0.1638, 0.4659, 0.5179, 0.3682],\n          [0.1288, 1.2296, 1.1534, 1.3886, 0.3094, 0.9658],\n          [1.7656, 0.6201, 2.7208, 1.9999, 0.0825, 1.5643],\n          [2.9438, 1.5736, 1.2058, 1.1066, 1.1300, 0.0104]]], device='cuda:0'),\n torch.Size([2, 4, 6]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Rotary Position Encoding Test\n",
    "1) integrate with multi-head attention\n",
    "2) multiply it before separate the heads\n",
    "최대한 행렬로 처리할 방법을 찾자\n",
    "dim 0, 1이 같은 공간으로 들어가고, \n",
    "dim 2, 3이 같은 공간으로 들어가게\n",
    "\n",
    "cos m*theta1, -sin m*theta1 0 0 0 0 0 0 0 0 0 0   여기가 그럼 디\n",
    "sin m*theta1, cos m*theta1  0 0 0 0 0 0 0 0 0 0\n",
    "0               0\n",
    "\n",
    "\n",
    "[Rotary Postion Encoding Algorithm]\n",
    "1) create a scaler tensor\n",
    "2) make theta tensor\n",
    "3) multiple theta tensor and scaler => m*theta1\n",
    "4) linear projection to transformation matrix\n",
    "5) multiply it with word embedding\n",
    "5) linear projectino to query, key\n",
    "    - value matrix does not multiply with transformation matrix\n",
    "\"\"\"\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQ = 4\n",
    "DIM_MODEL = 6\n",
    "scaler = torch.arange(1, MAX_SEQ+1, device=device, dtype=torch.float).unsqueeze(1).repeat(1, DIM_MODEL).reshape(MAX_SEQ, DIM_MODEL).unsqueeze(0).repeat(BATCH_SIZE, 1, 1)\n",
    "print(f\"scaler tensor: {scaler, scaler.shape}\")\n",
    "\n",
    "query = torch.rand(BATCH_SIZE, MAX_SEQ, DIM_MODEL, device=device)\n",
    "test = torch.mul(query, scaler)\n",
    "query, test, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T12:10:55.465182Z",
     "start_time": "2024-03-09T12:10:54.113928Z"
    }
   },
   "id": "46e860c62006f395",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1.0000, 1.0000, 0.0464, 0.0464, 0.0022, 0.0022], device='mps:0'),\n torch.Size([6]))"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" make theta tensor \"\"\"\n",
    "i_arr = torch.arange(1, int(DIM_MODEL/2)+1).to(device)\n",
    "i_arr = i_arr.repeat_interleave(2)\n",
    "theta = 10000**(-2*(i_arr - 1)/DIM_MODEL)\n",
    "theta, theta.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T07:04:34.871474Z",
     "start_time": "2024-03-09T07:04:34.807241Z"
    }
   },
   "id": "b604eec35efe80dd",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1.0000e+00, 1.0000e+00, 4.6416e-02, 4.6416e-02, 2.1544e-03,\n           2.1544e-03],\n          [2.0000e+00, 2.0000e+00, 9.2832e-02, 9.2832e-02, 4.3089e-03,\n           4.3089e-03],\n          [3.0000e+00, 3.0000e+00, 1.3925e-01, 1.3925e-01, 6.4633e-03,\n           6.4633e-03],\n          [4.0000e+00, 4.0000e+00, 1.8566e-01, 1.8566e-01, 8.6177e-03,\n           8.6177e-03]],\n \n         [[1.0000e+00, 1.0000e+00, 4.6416e-02, 4.6416e-02, 2.1544e-03,\n           2.1544e-03],\n          [2.0000e+00, 2.0000e+00, 9.2832e-02, 9.2832e-02, 4.3089e-03,\n           4.3089e-03],\n          [3.0000e+00, 3.0000e+00, 1.3925e-01, 1.3925e-01, 6.4633e-03,\n           6.4633e-03],\n          [4.0000e+00, 4.0000e+00, 1.8566e-01, 1.8566e-01, 8.6177e-03,\n           8.6177e-03]]], device='mps:0'),\n torch.Size([2, 4, 6]))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" multiple scaler and theta tensor \"\"\"\n",
    "var_tensor = torch.mul(scaler, theta)\n",
    "var_tensor, var_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T07:04:34.896145Z",
     "start_time": "2024-03-09T07:04:34.872744Z"
    }
   },
   "id": "88d09ee586f8996f",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 2, 2, 3, 3], device='cuda:0')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_arr = torch.arange(1, int(DIM_MODEL/2)+1).repeat_interleave(2).to(device)\n",
    "i_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T12:10:57.093701Z",
     "start_time": "2024-03-09T12:10:57.089846Z"
    }
   },
   "id": "974cad551a489038",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4., 4., 4.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[[-0.1132,  0.1565,  0.3930,  0.6889,  0.9187,  0.7205],\n          [-1.1905,  0.5498,  0.9004,  0.4854,  0.9392,  0.0111],\n          [-0.9666, -0.5393,  0.3010,  0.6850,  0.7560,  0.5727],\n          [-0.0436, -0.9012,  0.4945,  0.9079,  0.6551,  0.3986]],\n \n         [[-0.3056,  1.0390,  0.0308,  0.6546,  0.0471,  0.8311],\n          [-0.7194,  0.3709,  0.8517,  0.2788,  0.5287,  0.8799],\n          [-0.4567, -0.1643,  0.7193,  0.8177,  0.7088,  0.1128],\n          [-0.3710, -0.7775,  0.7493,  0.7202,  0.5490,  0.0412]]],\n        device='cuda:0'),\n torch.Size([2, 4, 6]))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "MAX_SEQ = 4\n",
    "DIM_MODEL = 6\n",
    "scaler = torch.arange(1, MAX_SEQ+1, device=device, dtype=torch.float).unsqueeze(1).repeat(1, DIM_MODEL).reshape(MAX_SEQ, DIM_MODEL)\n",
    "print(scaler)\n",
    "\n",
    "\"\"\" make theta tensor \"\"\"\n",
    "i_arr = torch.arange(1, int(DIM_MODEL/2)+1).to(device)\n",
    "i_arr = i_arr.repeat_interleave(2)\n",
    "theta = 10000**(-2*(i_arr - 1)/DIM_MODEL)\n",
    "var_tensor = torch.mul(scaler, theta)\n",
    "\n",
    "\n",
    "def create_rotation_matrix_v2(d, thetas):\n",
    "    \"\"\"\n",
    "    Create a batch of rotation matrices from the given thetas.\n",
    "    \n",
    "    Args:\n",
    "        d (int): The dimensionality of the rotation matrix (must be even).\n",
    "        thetas (Tensor): A tensor of shape (batch_size, seq_len, d/2) containing the rotation angles.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: A tensor of shape (batch_size, seq_len, d, d) containing the rotation matrices.\n",
    "    \n",
    "    \"\"\"\n",
    "    seq_len, _ = thetas.size()\n",
    "    R = torch.eye(d, device=thetas.device).repeat(seq_len, 1, 1)\n",
    "    \n",
    "    for i in range(0, d, 2):\n",
    "        cos_t = torch.cos(thetas[:, i]).unsqueeze(-1)\n",
    "        sin_t = torch.sin(thetas[:, i]).unsqueeze(-1)\n",
    "    \n",
    "        R[:, i, i] = cos_t.squeeze(-1)\n",
    "        R[:, i+1, i+1] = cos_t.squeeze(-1)\n",
    "        R[:, i, i+1] = -sin_t.squeeze(-1)\n",
    "        R[:, i+1, i] = sin_t.squeeze(-1)\n",
    "        \n",
    "    return R\n",
    "R = create_rotation_matrix_v2(DIM_MODEL, var_tensor)\n",
    "query = torch.rand(BATCH_SIZE, MAX_SEQ, DIM_MODEL, device=device)\n",
    "# test = query.clone().detach()\n",
    "# for s in range(MAX_SEQ):\n",
    "#     sub_rotary, sub_word = R[s, :, :], test[s, :]\n",
    "#     test[s, :] = torch.matmul(sub_rotary, sub_word)\n",
    "\n",
    "query = query.view(BATCH_SIZE, MAX_SEQ, DIM_MODEL)  # 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\n",
    "R = R.view(MAX_SEQ, DIM_MODEL, DIM_MODEL)  # 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\n",
    "\n",
    "result = torch.vstack([torch.bmm(R, query[i].unsqueeze(-1)).squeeze(-1).view(MAX_SEQ, DIM_MODEL) for i in range(BATCH_SIZE)]).view(BATCH_SIZE, MAX_SEQ, DIM_MODEL)\n",
    "result, result.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T14:23:28.624655Z",
     "start_time": "2024-03-09T14:23:28.608969Z"
    }
   },
   "id": "935d09b406074267",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 4, 6]), torch.Size([2, 4, 6]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, result.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T13:05:02.190654Z",
     "start_time": "2024-03-09T13:05:02.188102Z"
    }
   },
   "id": "de2e1be07b778819",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 4, 6]' is invalid for input of size 288",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10403/2344666709.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mR\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m \u001B[0mcreate_rotation_matrix_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDIM_MODEL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0mquery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBATCH_SIZE\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mMAX_SEQ\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDIM_MODEL\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0mR\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mR\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBATCH_SIZE\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mMAX_SEQ\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDIM_MODEL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDIM_MODEL\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_10403/2344666709.py\u001B[0m in \u001B[0;36mcreate_rotation_matrix_v2\u001B[0;34m(d, thetas)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;31m# 각각의 회전 행렬 요소 계산\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mcos_stack\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcos_t\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseq_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0msin_stack\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msin_t\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseq_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[2, 4, 6]' is invalid for input of size 288"
     ]
    }
   ],
   "source": [
    "# 회전 행렬 생성 최적화\n",
    "def create_rotation_matrix_v2(d, thetas):\n",
    "    \"\"\"\n",
    "    Create a batch of rotation matrices from the given thetas.\n",
    "    \n",
    "    Args:\n",
    "        d (int): The dimensionality of the rotation matrix (must be even).\n",
    "        thetas (Tensor): A tensor of shape (batch_size, seq_len, d/2) containing the rotation angles.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: A tensor of shape (batch_size, seq_len, d, d) containing the rotation matrices.\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_size, seq_len, _ = thetas.size()\n",
    "\n",
    "    cos_t = torch.cos(thetas).unsqueeze(-1)\n",
    "    sin_t = torch.sin(thetas).unsqueeze(-1)\n",
    "    \n",
    "    # 각각의 회전 행렬 요소 계산\n",
    "    cos_stack = cos_t.repeat(1, 1, d//2, 2).reshape(batch_size, seq_len, d)\n",
    "    sin_stack = sin_t.repeat(1, 1, d//2, 2).reshape(batch_size, seq_len, d)\n",
    "    \n",
    "    # 회전 행렬 생성\n",
    "    R = torch.eye(d, device=thetas.device).unsqueeze(0).unsqueeze(0).repeat(batch_size, seq_len, 1, 1)\n",
    "    R[:, :, ::2, ::2] = cos_stack\n",
    "    R[:, :, 1::2, 1::2] = cos_stack\n",
    "    R[:, :, ::2, 1::2] = -sin_stack\n",
    "    R[:, :, 1::2, ::2] = sin_stack\n",
    "    \n",
    "    return R\n",
    "\n",
    "create_rotation_matrix_v2(DIM_MODEL, var_tensor)\n",
    "query = query.view(BATCH_SIZE * MAX_SEQ, DIM_MODEL)  # 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\n",
    "R = R.view(BATCH_SIZE * MAX_SEQ, DIM_MODEL, DIM_MODEL)  # 배치 및 시퀀스 차원을 결합하여 행렬 곱셈을 위한 준비\n",
    "\n",
    "result = torch.bmm(R, query.unsqueeze(-1)).squeeze(-1).view(BATCH_SIZE, MAX_SEQ, DIM_MODEL)  \n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T13:30:07.691131Z",
     "start_time": "2024-03-09T13:30:07.676584Z"
    }
   },
   "id": "be191fe2275a039c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.5181, 0.0157, 0.2816, 0.8102, 0.7531, 0.3929],\n         [0.2677, 0.4532, 0.2546, 0.8741, 0.9514, 0.7601],\n         [0.8453, 0.2444, 0.2729, 0.9591, 0.9617, 0.2893],\n         [0.7103, 0.3587, 0.7432, 0.9069, 0.2104, 0.2306]],\n\n        [[0.7296, 0.3562, 0.6634, 0.2245, 0.1866, 0.4317],\n         [0.5114, 0.0046, 0.2526, 0.8282, 0.1672, 0.7417],\n         [0.1639, 0.5335, 0.7061, 0.8498, 0.0443, 0.5817],\n         [0.5541, 0.2003, 0.7650, 0.3248, 0.2091, 0.3983]]], device='mps:0')"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.rand(BATCH_SIZE, MAX_SEQ, DIM_MODEL, device=device)\n",
    "query"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T07:41:55.937406Z",
     "start_time": "2024-03-09T07:41:55.916491Z"
    }
   },
   "id": "9ea4daed37e1a79",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" expand to hole word embedding shape \"\"\"\n",
    "\n",
    "for b in range(BATCH_SIZE):\n",
    "    for s in range(MAX_SEQ):\n",
    "        sub_rotary, sub_word = R[b, s, :, :], query[b, s, :]\n",
    "        query[b, s, :] = torch.matmul(sub_rotary, sub_word)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T07:42:48.361595Z",
     "start_time": "2024-03-09T07:42:48.356999Z"
    }
   },
   "id": "9effe40c2e264e2d",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.2667,  0.4445,  0.2437,  0.8224,  0.7523,  0.3945],\n         [-0.5235,  0.0548,  0.1725,  0.8940,  0.9481,  0.7642],\n         [-0.8714, -0.1227,  0.1372,  0.9877,  0.9599,  0.2956],\n         [-0.1929, -0.7720,  0.5630,  1.0285,  0.2084,  0.2324]],\n\n        [[ 0.0945,  0.8064,  0.6523,  0.2550,  0.1857,  0.4321],\n         [-0.2170,  0.4631,  0.1747,  0.8481,  0.1640,  0.7424],\n         [-0.2375, -0.5051,  0.5813,  0.9395,  0.0405,  0.5820],\n         [-0.2106, -0.5502,  0.6919,  0.4605,  0.2057,  0.4001]]],\n       device='mps:0')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, dim_model: int= 768):\n",
    "        super().__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.i_arr = torch.arange(1, int(dim_model/2)+1) \n",
    "        self.theta = 10000**(-2*(self.i_arr - 1)/self.dim_model)\n",
    "    \n",
    "    def forward(self):\n",
    "        print(self.theta.shape)\n",
    "        print(self.theta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T07:42:53.588027Z",
     "start_time": "2024-03-09T07:42:53.566088Z"
    }
   },
   "id": "81d36a939fbf4962",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n",
      "tensor([1.0000e+00, 9.7630e-01, 9.5316e-01, 9.3057e-01, 9.0852e-01, 8.8699e-01,\n",
      "        8.6596e-01, 8.4544e-01, 8.2540e-01, 8.0584e-01, 7.8674e-01, 7.6810e-01,\n",
      "        7.4989e-01, 7.3212e-01, 7.1477e-01, 6.9783e-01, 6.8129e-01, 6.6515e-01,\n",
      "        6.4938e-01, 6.3399e-01, 6.1897e-01, 6.0430e-01, 5.8997e-01, 5.7599e-01,\n",
      "        5.6234e-01, 5.4901e-01, 5.3600e-01, 5.2330e-01, 5.1090e-01, 4.9879e-01,\n",
      "        4.8697e-01, 4.7543e-01, 4.6416e-01, 4.5316e-01, 4.4242e-01, 4.3193e-01,\n",
      "        4.2170e-01, 4.1170e-01, 4.0195e-01, 3.9242e-01, 3.8312e-01, 3.7404e-01,\n",
      "        3.6517e-01, 3.5652e-01, 3.4807e-01, 3.3982e-01, 3.3177e-01, 3.2390e-01,\n",
      "        3.1623e-01, 3.0873e-01, 3.0142e-01, 2.9427e-01, 2.8730e-01, 2.8049e-01,\n",
      "        2.7384e-01, 2.6735e-01, 2.6102e-01, 2.5483e-01, 2.4879e-01, 2.4289e-01,\n",
      "        2.3714e-01, 2.3152e-01, 2.2603e-01, 2.2067e-01, 2.1544e-01, 2.1034e-01,\n",
      "        2.0535e-01, 2.0049e-01, 1.9573e-01, 1.9110e-01, 1.8657e-01, 1.8214e-01,\n",
      "        1.7783e-01, 1.7361e-01, 1.6950e-01, 1.6548e-01, 1.6156e-01, 1.5773e-01,\n",
      "        1.5399e-01, 1.5034e-01, 1.4678e-01, 1.4330e-01, 1.3991e-01, 1.3659e-01,\n",
      "        1.3335e-01, 1.3019e-01, 1.2711e-01, 1.2409e-01, 1.2115e-01, 1.1828e-01,\n",
      "        1.1548e-01, 1.1274e-01, 1.1007e-01, 1.0746e-01, 1.0491e-01, 1.0243e-01,\n",
      "        1.0000e-01, 9.7630e-02, 9.5316e-02, 9.3057e-02, 9.0852e-02, 8.8699e-02,\n",
      "        8.6596e-02, 8.4544e-02, 8.2540e-02, 8.0584e-02, 7.8674e-02, 7.6810e-02,\n",
      "        7.4989e-02, 7.3212e-02, 7.1477e-02, 6.9783e-02, 6.8129e-02, 6.6515e-02,\n",
      "        6.4938e-02, 6.3399e-02, 6.1897e-02, 6.0430e-02, 5.8997e-02, 5.7599e-02,\n",
      "        5.6234e-02, 5.4901e-02, 5.3600e-02, 5.2330e-02, 5.1090e-02, 4.9879e-02,\n",
      "        4.8697e-02, 4.7543e-02, 4.6416e-02, 4.5316e-02, 4.4242e-02, 4.3193e-02,\n",
      "        4.2170e-02, 4.1170e-02, 4.0195e-02, 3.9242e-02, 3.8312e-02, 3.7404e-02,\n",
      "        3.6517e-02, 3.5652e-02, 3.4807e-02, 3.3982e-02, 3.3177e-02, 3.2390e-02,\n",
      "        3.1623e-02, 3.0873e-02, 3.0142e-02, 2.9427e-02, 2.8730e-02, 2.8049e-02,\n",
      "        2.7384e-02, 2.6735e-02, 2.6102e-02, 2.5483e-02, 2.4879e-02, 2.4289e-02,\n",
      "        2.3714e-02, 2.3152e-02, 2.2603e-02, 2.2067e-02, 2.1544e-02, 2.1034e-02,\n",
      "        2.0535e-02, 2.0049e-02, 1.9573e-02, 1.9110e-02, 1.8657e-02, 1.8214e-02,\n",
      "        1.7783e-02, 1.7361e-02, 1.6950e-02, 1.6548e-02, 1.6156e-02, 1.5773e-02,\n",
      "        1.5399e-02, 1.5034e-02, 1.4678e-02, 1.4330e-02, 1.3991e-02, 1.3659e-02,\n",
      "        1.3335e-02, 1.3019e-02, 1.2711e-02, 1.2409e-02, 1.2115e-02, 1.1828e-02,\n",
      "        1.1548e-02, 1.1274e-02, 1.1007e-02, 1.0746e-02, 1.0491e-02, 1.0243e-02,\n",
      "        1.0000e-02, 9.7630e-03, 9.5316e-03, 9.3057e-03, 9.0852e-03, 8.8699e-03,\n",
      "        8.6596e-03, 8.4544e-03, 8.2540e-03, 8.0584e-03, 7.8674e-03, 7.6810e-03,\n",
      "        7.4989e-03, 7.3212e-03, 7.1477e-03, 6.9783e-03, 6.8129e-03, 6.6515e-03,\n",
      "        6.4938e-03, 6.3399e-03, 6.1897e-03, 6.0430e-03, 5.8997e-03, 5.7599e-03,\n",
      "        5.6234e-03, 5.4901e-03, 5.3600e-03, 5.2330e-03, 5.1090e-03, 4.9879e-03,\n",
      "        4.8697e-03, 4.7543e-03, 4.6416e-03, 4.5316e-03, 4.4242e-03, 4.3193e-03,\n",
      "        4.2170e-03, 4.1170e-03, 4.0195e-03, 3.9242e-03, 3.8312e-03, 3.7404e-03,\n",
      "        3.6517e-03, 3.5652e-03, 3.4807e-03, 3.3982e-03, 3.3177e-03, 3.2390e-03,\n",
      "        3.1623e-03, 3.0873e-03, 3.0142e-03, 2.9427e-03, 2.8730e-03, 2.8049e-03,\n",
      "        2.7384e-03, 2.6735e-03, 2.6102e-03, 2.5483e-03, 2.4879e-03, 2.4289e-03,\n",
      "        2.3714e-03, 2.3152e-03, 2.2603e-03, 2.2067e-03, 2.1544e-03, 2.1034e-03,\n",
      "        2.0535e-03, 2.0049e-03, 1.9573e-03, 1.9110e-03, 1.8657e-03, 1.8214e-03,\n",
      "        1.7783e-03, 1.7361e-03, 1.6950e-03, 1.6548e-03, 1.6156e-03, 1.5773e-03,\n",
      "        1.5399e-03, 1.5034e-03, 1.4678e-03, 1.4330e-03, 1.3991e-03, 1.3659e-03,\n",
      "        1.3335e-03, 1.3019e-03, 1.2711e-03, 1.2409e-03, 1.2115e-03, 1.1828e-03,\n",
      "        1.1548e-03, 1.1274e-03, 1.1007e-03, 1.0746e-03, 1.0491e-03, 1.0243e-03,\n",
      "        1.0000e-03, 9.7630e-04, 9.5316e-04, 9.3057e-04, 9.0852e-04, 8.8699e-04,\n",
      "        8.6596e-04, 8.4544e-04, 8.2540e-04, 8.0584e-04, 7.8674e-04, 7.6810e-04,\n",
      "        7.4989e-04, 7.3212e-04, 7.1477e-04, 6.9783e-04, 6.8129e-04, 6.6515e-04,\n",
      "        6.4938e-04, 6.3399e-04, 6.1897e-04, 6.0430e-04, 5.8997e-04, 5.7599e-04,\n",
      "        5.6234e-04, 5.4901e-04, 5.3600e-04, 5.2330e-04, 5.1090e-04, 4.9879e-04,\n",
      "        4.8697e-04, 4.7543e-04, 4.6416e-04, 4.5316e-04, 4.4242e-04, 4.3193e-04,\n",
      "        4.2170e-04, 4.1170e-04, 4.0195e-04, 3.9242e-04, 3.8312e-04, 3.7404e-04,\n",
      "        3.6517e-04, 3.5652e-04, 3.4807e-04, 3.3982e-04, 3.3177e-04, 3.2390e-04,\n",
      "        3.1623e-04, 3.0873e-04, 3.0142e-04, 2.9427e-04, 2.8730e-04, 2.8049e-04,\n",
      "        2.7384e-04, 2.6735e-04, 2.6102e-04, 2.5483e-04, 2.4879e-04, 2.4289e-04,\n",
      "        2.3714e-04, 2.3152e-04, 2.2603e-04, 2.2067e-04, 2.1544e-04, 2.1034e-04,\n",
      "        2.0535e-04, 2.0049e-04, 1.9573e-04, 1.9110e-04, 1.8657e-04, 1.8214e-04,\n",
      "        1.7783e-04, 1.7361e-04, 1.6950e-04, 1.6548e-04, 1.6156e-04, 1.5773e-04,\n",
      "        1.5399e-04, 1.5034e-04, 1.4678e-04, 1.4330e-04, 1.3991e-04, 1.3659e-04,\n",
      "        1.3335e-04, 1.3019e-04, 1.2711e-04, 1.2409e-04, 1.2115e-04, 1.1828e-04,\n",
      "        1.1548e-04, 1.1274e-04, 1.1007e-04, 1.0746e-04, 1.0491e-04, 1.0243e-04])\n"
     ]
    }
   ],
   "source": [
    "rotary_pos_enc = RoPE(DIM_MODEL)\n",
    "rotary_pos_enc()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T05:23:16.979704Z",
     "start_time": "2024-03-09T05:23:16.974710Z"
    }
   },
   "id": "f9b18f3fcc726988",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original query: (torch.Size([1, 8, 4, 2]), tensor([[[[0.9168, 0.0523],\n",
      "          [0.5834, 0.3648],\n",
      "          [0.1445, 0.6178],\n",
      "          [0.5795, 0.7004]],\n",
      "\n",
      "         [[0.9812, 0.6302],\n",
      "          [0.1581, 0.9039],\n",
      "          [0.3351, 0.6687],\n",
      "          [0.9043, 0.7900]],\n",
      "\n",
      "         [[0.4702, 0.4620],\n",
      "          [0.0865, 0.3290],\n",
      "          [0.5967, 0.5650],\n",
      "          [0.1954, 0.9916]],\n",
      "\n",
      "         [[0.4202, 0.9388],\n",
      "          [0.4909, 0.4016],\n",
      "          [0.4052, 0.9085],\n",
      "          [0.5089, 0.3139]],\n",
      "\n",
      "         [[0.8943, 0.1367],\n",
      "          [0.1901, 0.1161],\n",
      "          [0.3471, 0.0353],\n",
      "          [0.1799, 0.8890]],\n",
      "\n",
      "         [[0.8990, 0.4810],\n",
      "          [0.8155, 0.6152],\n",
      "          [0.7975, 0.7668],\n",
      "          [0.6558, 0.6093]],\n",
      "\n",
      "         [[0.6960, 0.4698],\n",
      "          [0.1492, 0.0688],\n",
      "          [0.0338, 0.2450],\n",
      "          [0.6533, 0.4803]],\n",
      "\n",
      "         [[0.2576, 0.7272],\n",
      "          [0.7371, 0.8030],\n",
      "          [0.2122, 0.0413],\n",
      "          [0.5253, 0.0612]]]], device='cuda:0'))\n",
      "test1: (torch.Size([1, 8, 8]), tensor([[[0.9168, 0.0523, 0.9812, 0.6302, 0.4702, 0.4620, 0.4202, 0.9388],\n",
      "         [0.8943, 0.1367, 0.8990, 0.4810, 0.6960, 0.4698, 0.2576, 0.7272],\n",
      "         [0.5834, 0.3648, 0.1581, 0.9039, 0.0865, 0.3290, 0.4909, 0.4016],\n",
      "         [0.1901, 0.1161, 0.8155, 0.6152, 0.1492, 0.0688, 0.7371, 0.8030],\n",
      "         [0.1445, 0.6178, 0.3351, 0.6687, 0.5967, 0.5650, 0.4052, 0.9085],\n",
      "         [0.3471, 0.0353, 0.7975, 0.7668, 0.0338, 0.2450, 0.2122, 0.0413],\n",
      "         [0.5795, 0.7004, 0.9043, 0.7900, 0.1954, 0.9916, 0.5089, 0.3139],\n",
      "         [0.1799, 0.8890, 0.6558, 0.6093, 0.6533, 0.4803, 0.5253, 0.0612]]],\n",
      "       device='cuda:0'))\n",
      "test2: (torch.Size([1, 8, 8]), tensor([[[0.9168, 0.0523, 0.5834, 0.3648, 0.1445, 0.6178, 0.5795, 0.7004],\n",
      "         [0.9812, 0.6302, 0.1581, 0.9039, 0.3351, 0.6687, 0.9043, 0.7900],\n",
      "         [0.4702, 0.4620, 0.0865, 0.3290, 0.5967, 0.5650, 0.1954, 0.9916],\n",
      "         [0.4202, 0.9388, 0.4909, 0.4016, 0.4052, 0.9085, 0.5089, 0.3139],\n",
      "         [0.8943, 0.1367, 0.1901, 0.1161, 0.3471, 0.0353, 0.1799, 0.8890],\n",
      "         [0.8990, 0.4810, 0.8155, 0.6152, 0.7975, 0.7668, 0.6558, 0.6093],\n",
      "         [0.6960, 0.4698, 0.1492, 0.0688, 0.0338, 0.2450, 0.6533, 0.4803],\n",
      "         [0.2576, 0.7272, 0.7371, 0.8030, 0.2122, 0.0413, 0.5253, 0.0612]]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" test for parallel multi-head attention\n",
    "1) permute. contiguous, reshape\n",
    "2) directly call reshape from torch.matmul(attention_matrix, v)\n",
    "\"\"\"\n",
    "\n",
    "query = torch.rand(1, 8, 4, 2, device=device)\n",
    "BS, SEQ_LEN, NUM_HEADS, DIM_HEADS = query.shape\n",
    "print(f\"original query: {query.shape, query}\")\n",
    "\n",
    "test1 = query.permute(0, 2, 1, 3).contiguous().reshape(-1, SEQ_LEN, NUM_HEADS*DIM_HEADS)\n",
    "print(f\"test1: {test1.shape, test1}\")\n",
    "\n",
    "test2 = query.reshape(-1, SEQ_LEN, NUM_HEADS*DIM_HEADS)\n",
    "print(f\"test2: {test2.shape, test2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:21:51.030758Z",
     "start_time": "2024-03-07T15:21:51.009673Z"
    }
   },
   "id": "a56dfef369aa96c8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: (torch.Size([3, 4, 2, 2]), tensor([[[[1.8712, 1.7441],\n",
      "          [2.0152, 1.8818]],\n",
      "\n",
      "         [[1.2480, 1.6586],\n",
      "          [0.9948, 1.8648]],\n",
      "\n",
      "         [[1.8897, 1.1054],\n",
      "          [1.4765, 1.0960]],\n",
      "\n",
      "         [[1.1829, 2.3455],\n",
      "          [1.1215, 1.7871]]],\n",
      "\n",
      "\n",
      "        [[[1.2551, 1.4782],\n",
      "          [0.6835, 0.8580]],\n",
      "\n",
      "         [[2.0954, 2.2804],\n",
      "          [1.2951, 1.9219]],\n",
      "\n",
      "         [[1.5423, 1.0609],\n",
      "          [2.4590, 1.7339]],\n",
      "\n",
      "         [[2.1012, 1.5119],\n",
      "          [1.1772, 0.9965]]],\n",
      "\n",
      "\n",
      "        [[[1.3803, 2.0247],\n",
      "          [1.0918, 1.3187]],\n",
      "\n",
      "         [[1.6456, 1.3337],\n",
      "          [0.9049, 1.3710]],\n",
      "\n",
      "         [[1.0539, 1.3264],\n",
      "          [1.2296, 1.8057]],\n",
      "\n",
      "         [[1.3767, 1.8384],\n",
      "          [0.7315, 0.7558]]]], device='mps:0'))\n",
      "z: (torch.Size([3, 5, 4]), tensor([[[0.4404, 0.2922, 0.5909, 0.2315],\n",
      "         [0.2317, 0.4030, 0.4618, 0.2901],\n",
      "         [0.6622, 0.5419, 0.2251, 0.2437],\n",
      "         [0.6661, 0.3618, 0.3576, 0.9171],\n",
      "         [0.2153, 0.3808, 0.4363, 0.4122]],\n",
      "\n",
      "        [[1.4899, 0.4322, 0.3827, 0.5344],\n",
      "         [0.3850, 0.3527, 0.3429, 0.4290],\n",
      "         [0.3780, 0.5035, 0.6515, 0.7208],\n",
      "         [0.4250, 0.3972, 0.3370, 1.3863],\n",
      "         [0.3472, 0.3455, 0.2217, 1.5013]],\n",
      "\n",
      "        [[0.3272, 0.7635, 0.5159, 0.2584],\n",
      "         [0.9012, 0.3209, 0.9350, 0.3100],\n",
      "         [0.4084, 0.2545, 0.4274, 1.0087],\n",
      "         [0.5627, 0.4500, 0.4330, 0.4545],\n",
      "         [1.5795, 0.3925, 0.2638, 0.2200]]], device='mps:0'))\n",
      "qkv: (torch.Size([3, 5, 4, 2]), tensor([[[[1.2408, 1.3386],\n",
      "          [1.9509, 1.9588],\n",
      "          [0.9196, 0.8562],\n",
      "          [3.3162, 2.7151]],\n",
      "\n",
      "         [[2.4284, 2.6169],\n",
      "          [1.4205, 1.3660],\n",
      "          [1.1989, 0.9490],\n",
      "          [2.7088, 2.1410]],\n",
      "\n",
      "         [[0.8548, 0.9209],\n",
      "          [1.0627, 0.9601],\n",
      "          [2.4392, 2.0793],\n",
      "          [3.1278, 2.5885]],\n",
      "\n",
      "         [[0.8536, 0.9195],\n",
      "          [1.5770, 1.5684],\n",
      "          [1.5383, 1.2891],\n",
      "          [0.8249, 0.6902]],\n",
      "\n",
      "         [[2.6101, 2.8128],\n",
      "          [1.4883, 1.5801],\n",
      "          [1.2475, 1.1469],\n",
      "          [1.8955, 1.5112]]],\n",
      "\n",
      "\n",
      "        [[[0.4177, 0.2318],\n",
      "          [1.5713, 0.9904],\n",
      "          [1.2565, 2.0138],\n",
      "          [1.4761, 0.9572]],\n",
      "\n",
      "         [[1.6114, 0.8961],\n",
      "          [2.0765, 1.6904],\n",
      "          [1.3481, 2.1707],\n",
      "          [1.8239, 1.0630]],\n",
      "\n",
      "         [[1.5629, 0.8965],\n",
      "          [1.3791, 0.9452],\n",
      "          [0.7315, 1.1736],\n",
      "          [1.0948, 0.7137]],\n",
      "\n",
      "         [[1.4697, 0.8137],\n",
      "          [1.7890, 1.3274],\n",
      "          [1.4375, 2.3020],\n",
      "          [0.5640, 0.3250]],\n",
      "\n",
      "         [[1.7515, 0.9863],\n",
      "          [2.1310, 1.7614],\n",
      "          [2.0671, 3.3321],\n",
      "          [0.5222, 0.3126]]],\n",
      "\n",
      "\n",
      "        [[[2.2275, 1.6126],\n",
      "          [0.8339, 0.5236],\n",
      "          [1.1866, 1.4508],\n",
      "          [2.3908, 1.0708]],\n",
      "\n",
      "         [[0.8616, 0.5745],\n",
      "          [1.8054, 1.5124],\n",
      "          [0.5985, 0.8084],\n",
      "          [1.9112, 0.9052]],\n",
      "\n",
      "         [[1.8351, 1.2817],\n",
      "          [2.3440, 1.8055],\n",
      "          [1.4109, 1.7541],\n",
      "          [0.6324, 0.2711]],\n",
      "\n",
      "         [[1.3795, 0.9202],\n",
      "          [1.2058, 1.1998],\n",
      "          [1.3451, 1.7382],\n",
      "          [1.1998, 0.6342]],\n",
      "\n",
      "         [[0.4345, 0.3398],\n",
      "          [1.5145, 1.1788],\n",
      "          [2.2275, 2.8506],\n",
      "          [2.7646, 1.2644]]]], device='mps:0'))\n",
      "V: (torch.Size([3, 5, 4, 2]), tensor([[[[0.5465, 0.5896],\n",
      "          [0.5701, 0.5724],\n",
      "          [0.5434, 0.5059],\n",
      "          [0.7676, 0.6285]],\n",
      "\n",
      "         [[0.5626, 0.6063],\n",
      "          [0.5725, 0.5505],\n",
      "          [0.5536, 0.4382],\n",
      "          [0.7858, 0.6211]],\n",
      "\n",
      "         [[0.5660, 0.6098],\n",
      "          [0.5759, 0.5203],\n",
      "          [0.5491, 0.4681],\n",
      "          [0.7621, 0.6307]],\n",
      "\n",
      "         [[0.5686, 0.6125],\n",
      "          [0.5706, 0.5675],\n",
      "          [0.5502, 0.4610],\n",
      "          [0.7565, 0.6330]],\n",
      "\n",
      "         [[0.5618, 0.6055],\n",
      "          [0.5668, 0.6018],\n",
      "          [0.5442, 0.5004],\n",
      "          [0.7813, 0.6229]]],\n",
      "\n",
      "\n",
      "        [[[0.6224, 0.3454],\n",
      "          [0.6792, 0.4281],\n",
      "          [0.4809, 0.7707],\n",
      "          [0.7887, 0.5115]],\n",
      "\n",
      "         [[0.6203, 0.3450],\n",
      "          [0.7324, 0.5963],\n",
      "          [0.4623, 0.7444],\n",
      "          [0.7825, 0.4561]],\n",
      "\n",
      "         [[0.5908, 0.3389],\n",
      "          [0.6943, 0.4759],\n",
      "          [0.4765, 0.7645],\n",
      "          [0.7891, 0.5144]],\n",
      "\n",
      "         [[0.6247, 0.3459],\n",
      "          [0.7106, 0.5272],\n",
      "          [0.4844, 0.7757],\n",
      "          [0.7819, 0.4505]],\n",
      "\n",
      "         [[0.6082, 0.3425],\n",
      "          [0.7364, 0.6086],\n",
      "          [0.4583, 0.7388],\n",
      "          [0.7840, 0.4692]]],\n",
      "\n",
      "\n",
      "        [[[0.7290, 0.5277],\n",
      "          [0.6367, 0.3998],\n",
      "          [0.6122, 0.7485],\n",
      "          [0.6177, 0.2766]],\n",
      "\n",
      "         [[0.7765, 0.5178],\n",
      "          [0.5793, 0.4853],\n",
      "          [0.5596, 0.7558],\n",
      "          [0.5926, 0.2807]],\n",
      "\n",
      "         [[0.7494, 0.5234],\n",
      "          [0.5966, 0.4595],\n",
      "          [0.6031, 0.7497],\n",
      "          [0.6378, 0.2734]],\n",
      "\n",
      "         [[0.7763, 0.5178],\n",
      "          [0.5426, 0.5399],\n",
      "          [0.5824, 0.7526],\n",
      "          [0.5453, 0.2882]],\n",
      "\n",
      "         [[0.6864, 0.5367],\n",
      "          [0.5945, 0.4627],\n",
      "          [0.5876, 0.7519],\n",
      "          [0.6082, 0.2782]]]], device='mps:0'))\n",
      "test_v: (torch.Size([3, 5, 4, 2]), tensor([[[[0.5465, 0.5896],\n",
      "          [0.5701, 0.5724],\n",
      "          [0.5434, 0.5059],\n",
      "          [0.7676, 0.6285]],\n",
      "\n",
      "         [[0.5626, 0.6063],\n",
      "          [0.5725, 0.5505],\n",
      "          [0.5536, 0.4382],\n",
      "          [0.7858, 0.6211]],\n",
      "\n",
      "         [[0.5660, 0.6098],\n",
      "          [0.5759, 0.5203],\n",
      "          [0.5491, 0.4681],\n",
      "          [0.7621, 0.6307]],\n",
      "\n",
      "         [[0.5686, 0.6125],\n",
      "          [0.5706, 0.5675],\n",
      "          [0.5502, 0.4610],\n",
      "          [0.7565, 0.6330]],\n",
      "\n",
      "         [[0.5618, 0.6055],\n",
      "          [0.5668, 0.6018],\n",
      "          [0.5442, 0.5004],\n",
      "          [0.7813, 0.6229]]],\n",
      "\n",
      "\n",
      "        [[[0.6224, 0.3454],\n",
      "          [0.6792, 0.4281],\n",
      "          [0.4809, 0.7707],\n",
      "          [0.7887, 0.5115]],\n",
      "\n",
      "         [[0.6203, 0.3450],\n",
      "          [0.7324, 0.5963],\n",
      "          [0.4623, 0.7444],\n",
      "          [0.7825, 0.4561]],\n",
      "\n",
      "         [[0.5908, 0.3389],\n",
      "          [0.6943, 0.4759],\n",
      "          [0.4765, 0.7645],\n",
      "          [0.7891, 0.5144]],\n",
      "\n",
      "         [[0.6247, 0.3459],\n",
      "          [0.7106, 0.5272],\n",
      "          [0.4844, 0.7757],\n",
      "          [0.7819, 0.4505]],\n",
      "\n",
      "         [[0.6082, 0.3425],\n",
      "          [0.7364, 0.6086],\n",
      "          [0.4583, 0.7388],\n",
      "          [0.7840, 0.4692]]],\n",
      "\n",
      "\n",
      "        [[[0.7290, 0.5277],\n",
      "          [0.6367, 0.3998],\n",
      "          [0.6122, 0.7485],\n",
      "          [0.6177, 0.2766]],\n",
      "\n",
      "         [[0.7765, 0.5178],\n",
      "          [0.5793, 0.4853],\n",
      "          [0.5596, 0.7558],\n",
      "          [0.5926, 0.2807]],\n",
      "\n",
      "         [[0.7494, 0.5234],\n",
      "          [0.5966, 0.4595],\n",
      "          [0.6031, 0.7497],\n",
      "          [0.6378, 0.2734]],\n",
      "\n",
      "         [[0.7763, 0.5178],\n",
      "          [0.5426, 0.5399],\n",
      "          [0.5824, 0.7526],\n",
      "          [0.5453, 0.2882]],\n",
      "\n",
      "         [[0.6864, 0.5367],\n",
      "          [0.5945, 0.4627],\n",
      "          [0.5876, 0.7519],\n",
      "          [0.6082, 0.2782]]]], device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" source code from original linear transformers paper github\n",
    "\"\"\"\n",
    "\n",
    "max_seq = 5\n",
    "dim_model = 8\n",
    "num_heads = 4\n",
    "dim_head = dim_model // num_heads\n",
    "batch_size = 3\n",
    "\n",
    "# 3, 5, 4, 2\n",
    "query = torch.rand(batch_size, max_seq, num_heads, dim_head, device=device)\n",
    "key = torch.rand(batch_size, max_seq, num_heads, dim_head, device=device)\n",
    "value = torch.rand(batch_size, max_seq, num_heads, dim_head, device=device)\n",
    "\n",
    "kv = torch.einsum(\"nshd,nshm->nhmd\", key, value)\n",
    "print(f\"kv: {kv.shape, kv}\")\n",
    "\n",
    "z = 1/(torch.einsum(\"nlhd,nhd->nlh\", query, key.sum(dim=1))+1e-6)\n",
    "print(f\"z: {z.shape, z}\")\n",
    "\n",
    "qkv = torch.einsum(\"nlhd,nhmd->nlhm\", query, kv)\n",
    "print(f\"qkv: {qkv.shape, qkv}\")\n",
    "\n",
    "V = torch.einsum(\"nlhd,nhmd,nlh->nlhm\", query, kv, z)\n",
    "print(f\"V: {V.shape, V}\")\n",
    "\n",
    "test_v = torch.einsum(\"nlhm,nlh->nlhm\", qkv, z)\n",
    "print(f\"test_v: {test_v.shape, test_v}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T07:44:32.680278Z",
     "start_time": "2024-03-05T07:44:31.593837Z"
    }
   },
   "id": "79e47d3676ad6a6d",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV: (torch.Size([3, 2, 2]), tensor([[[1.6945, 2.5599],\n",
      "         [1.6986, 2.4920]],\n",
      "\n",
      "        [[3.7326, 3.1925],\n",
      "         [3.5027, 3.1093]],\n",
      "\n",
      "        [[1.4581, 2.1359],\n",
      "         [2.1605, 2.8166]]], device='cuda:0'))\n",
      "Z: (torch.Size([3, 5]), tensor([[5.9278e-02, 8.4242e-02, 8.2484e-02, 1.0000e+06, 1.0000e+06],\n",
      "        [4.6290e-02, 4.3917e-02, 6.5639e-02, 6.5267e-02, 1.0000e+06],\n",
      "        [1.0978e-01, 1.0496e-01, 1.0000e+06, 1.0000e+06, 1.0000e+06]],\n",
      "       device='cuda:0'))\n",
      "V: (torch.Size([3, 5, 2]), tensor([[[0.9854, 0.9707],\n",
      "         [1.0248, 1.0095],\n",
      "         [1.0131, 0.9979],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[1.1236, 1.0728],\n",
      "         [1.1181, 1.0675],\n",
      "         [1.1167, 1.0662],\n",
      "         [1.1213, 1.0706],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0962, 1.5180],\n",
      "         [1.1320, 1.5677],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" alias of each tensor dimension for torch einsum\n",
    "b: batch_size\n",
    "s: sequence length\n",
    "q: dim_head of query\n",
    "k: dim_head of key\n",
    "v: dim_head of value\n",
    "\"\"\"\n",
    "def kernel_fn(x: Tensor):\n",
    "    return F.elu(x) + 1\n",
    "\n",
    "query = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "key = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "value = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "padding_mask = torch.tensor([\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1]],\n",
    "    device=device\n",
    ")\n",
    "query, key = kernel_fn(query), kernel_fn(key)\n",
    "query[padding_mask == 1], key[padding_mask == 1], value[padding_mask == 1] = 0, 0, 0\n",
    "\n",
    "KV = torch.matmul(value.permute(0, 2, 1), key.permute(0, 1, 2))\n",
    "print(f\"KV: {KV.shape, KV}\")\n",
    "\n",
    "Z = 1 / torch.clamp(torch.mul(query,key.sum(dim=1).unsqueeze(1)).sum(dim=-1), min=1e-6)\n",
    "print(f\"Z: {Z.shape, Z}\")\n",
    "\n",
    "V = torch.einsum(\"bsq,bvk,bs->bsv\", query, KV, Z)\n",
    "print(f\"V: {V.shape, V}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T02:09:58.073747Z",
     "start_time": "2024-03-05T02:09:58.058927Z"
    }
   },
   "id": "87b8384ff530d8c3",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV: (torch.Size([3, 4, 2, 2]), tensor([[[[1.8712, 1.7441],\n",
      "          [2.0152, 1.8818]],\n",
      "\n",
      "         [[1.2480, 1.6586],\n",
      "          [0.9948, 1.8648]],\n",
      "\n",
      "         [[1.8897, 1.1054],\n",
      "          [1.4765, 1.0960]],\n",
      "\n",
      "         [[1.1829, 2.3455],\n",
      "          [1.1215, 1.7871]]],\n",
      "\n",
      "\n",
      "        [[[1.2551, 1.4782],\n",
      "          [0.6835, 0.8580]],\n",
      "\n",
      "         [[2.0954, 2.2804],\n",
      "          [1.2951, 1.9219]],\n",
      "\n",
      "         [[1.5423, 1.0609],\n",
      "          [2.4590, 1.7339]],\n",
      "\n",
      "         [[2.1012, 1.5119],\n",
      "          [1.1772, 0.9965]]],\n",
      "\n",
      "\n",
      "        [[[1.3803, 2.0247],\n",
      "          [1.0918, 1.3187]],\n",
      "\n",
      "         [[1.6456, 1.3337],\n",
      "          [0.9049, 1.3710]],\n",
      "\n",
      "         [[1.0539, 1.3264],\n",
      "          [1.2296, 1.8057]],\n",
      "\n",
      "         [[1.3767, 1.8384],\n",
      "          [0.7315, 0.7558]]]], device='mps:0'))\n",
      "query: torch.Size([3, 5, 4, 2])\n",
      "key sum: torch.Size([3, 4, 2])\n",
      "Z: (tensor([[[0.4404, 0.2922, 0.5909, 0.2315],\n",
      "         [0.2317, 0.4030, 0.4618, 0.2901],\n",
      "         [0.6622, 0.5419, 0.2251, 0.2437],\n",
      "         [0.6661, 0.3618, 0.3576, 0.9171],\n",
      "         [0.2153, 0.3808, 0.4363, 0.4122]],\n",
      "\n",
      "        [[1.4899, 0.4323, 0.3827, 0.5344],\n",
      "         [0.3850, 0.3527, 0.3429, 0.4290],\n",
      "         [0.3780, 0.5035, 0.6515, 0.7208],\n",
      "         [0.4250, 0.3972, 0.3370, 1.3863],\n",
      "         [0.3472, 0.3455, 0.2217, 1.5013]],\n",
      "\n",
      "        [[0.3272, 0.7635, 0.5159, 0.2584],\n",
      "         [0.9012, 0.3209, 0.9350, 0.3100],\n",
      "         [0.4084, 0.2545, 0.4274, 1.0087],\n",
      "         [0.5627, 0.4500, 0.4330, 0.4545],\n",
      "         [1.5795, 0.3925, 0.2638, 0.2200]]], device='mps:0'), torch.Size([3, 5, 4]))\n"
     ]
    }
   ],
   "source": [
    "# [bs, num_heads, dim_head, max_seq]*[bs, num_heads, max_seq, dim_head] = [bs, num_heads, dim_head, dim_head]\n",
    "KV = torch.matmul(value.permute(0, 2, 3, 1), key.permute(0, 2, 1, 3))  \n",
    "print(f\"KV: {KV.shape, KV}\")\n",
    "\n",
    "print(f\"query: {query.shape}\")\n",
    "print(f\"key sum: {key.sum(dim=1).shape}\")\n",
    " \n",
    "Z = 1 / torch.clamp(torch.mul(query,key.sum(dim=1).unsqueeze(1)).sum(dim=-1), min=1e-6)\n",
    "print(f\"Z: {Z, Z.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T07:45:38.051623Z",
     "start_time": "2024-03-05T07:45:37.998378Z"
    }
   },
   "id": "aa54418f2826a466",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 5, 2]' is invalid for input of size 120",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_5978/321065780.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_query\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_seq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim_head\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtest_key\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_seq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim_head\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtest_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_seq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim_head\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mKV\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_key\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_value\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[3, 5, 2]' is invalid for input of size 120"
     ]
    }
   ],
   "source": [
    "# test_query = query.reshape(batch_size, max_seq, dim_head)\n",
    "# test_key = key.reshape(batch_size, max_seq, dim_head)\n",
    "# test_value = value.reshape(batch_size, max_seq, dim_head)\n",
    "# \n",
    "# KV = torch.matmul(test_key.permute(0, 2, 1), test_value)\n",
    "# print(f\"KV: {KV.shape, KV}\")\n",
    "# QKV = torch.matmul(test_query, KV)\n",
    "# print(f\"QKV: {QKV.shape, QKV}\")\n",
    "\n",
    "# summation_key = test_key.sum(dim=1).unsqueeze(1)\n",
    "# print(f\"key, summation_key: {test_key.shape, summation_key.shape}\")\n",
    "# \n",
    "# Z = 1/torch.clamp(torch.mul(test_query, summation_key), min=1e-6)\n",
    "# print(f\"Normalizer Z: {Z, Z.shape}\")\n",
    "# \n",
    "# linear_attn_matrix = torch.matmul(QKV, Z)\n",
    "# print(f\"linear_attn_matrix: {linear_attn_matrix.shape, linear_attn_matrix}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T00:13:28.653319Z",
     "start_time": "2024-03-05T00:13:28.647237Z"
    }
   },
   "id": "47061c931e144f11",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(9663676416, 1207959552, 8)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic = 512*64*64*512 + 512*512*512*64\n",
    "linear = 64*512*512*64 + 512*64*64*64\n",
    "\n",
    "quadratic, linear, quadratic // linear"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:30:48.714062Z",
     "start_time": "2024-03-02T13:30:48.709081Z"
    }
   },
   "id": "5c0366bb014d387d",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 5, 2]),\n torch.Size([3, 5, 2]),\n torch.Size([3, 5, 2]),\n torch.Size([3, 5]))"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Inputs for Linear Attentions\n",
    "\"\"\"\n",
    "\n",
    "max_seq = 5\n",
    "dim_model = 2\n",
    "num_heads = 12\n",
    "batch_size = 3\n",
    "# dim_head = dim_model // num_heads\n",
    "dim_head = dim_model\n",
    "\n",
    "def kernel_fn(x: Tensor):\n",
    "    return F.elu(x) + 1\n",
    "\n",
    "query = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "key = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "value = torch.rand(batch_size, max_seq, dim_head, device=device)\n",
    "\n",
    "padding_mask = torch.tensor([\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1]],\n",
    "    device=device\n",
    ")\n",
    "query.shape, key.shape, value.shape, padding_mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:05.824614Z",
     "start_time": "2024-03-04T16:47:05.816133Z"
    }
   },
   "id": "2db69b58bd5032a",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1.6423, 2.3725],\n          [1.9186, 2.7227]],\n \n         [[2.5099, 4.3219],\n          [2.0842, 3.6178]],\n \n         [[1.7249, 2.7095],\n          [1.6283, 2.5576]]], device='cuda:0'),\n torch.Size([3, 2, 2]))"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Testing for Linear Attentions: KV Matrix\n",
    "\"\"\"\n",
    "k_query, k_key = kernel_fn(query), kernel_fn(key)\n",
    "k_query[padding_mask == 1], k_key[padding_mask == 1], value[padding_mask == 1] = 0, 0, 0 \n",
    "\n",
    "KV = torch.matmul(k_key.permute(0, 2, 1), value)\n",
    "KV, KV.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:05.999245Z",
     "start_time": "2024-03-04T16:47:05.993702Z"
    }
   },
   "id": "1d4d4a249fb2cf68",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 6.9833,  9.9921],\n          [ 4.8467,  6.9438],\n          [ 5.7299,  8.2035],\n          [ 0.2364,  0.8221],\n          [ 0.5723,  0.9037]],\n \n         [[ 6.3969, 11.0627],\n          [ 6.1451, 10.6128],\n          [ 6.6618, 11.5190],\n          [ 7.9548, 13.7416],\n          [ 0.5258,  0.1820]],\n \n         [[ 4.7064,  7.3925],\n          [ 4.8010,  7.5412],\n          [ 0.4323,  0.3144],\n          [ 0.6062,  0.6203],\n          [ 0.8389,  0.5675]]], device='cuda:0'),\n torch.Size([3, 5, 2]))"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Testing for Linear Attentions: QKV\n",
    "\"\"\"\n",
    "\n",
    "QKV = torch.matmul(k_query, KV)\n",
    "QKV, QKV.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:06.172677Z",
     "start_time": "2024-03-04T16:47:06.166589Z"
    }
   },
   "id": "56d258a4ac1b2e78",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key, summation_key: (torch.Size([3, 5, 2]), torch.Size([3, 2, 2]))\n",
      "Normalizer Z: (tensor([[[5.6876e-02, 5.6876e-02],\n",
      "         [8.1770e-02, 8.1770e-02],\n",
      "         [6.9246e-02, 6.9246e-02],\n",
      "         [1.0000e+06, 1.0000e+06],\n",
      "         [1.0000e+06, 1.0000e+06]],\n",
      "\n",
      "        [[6.3809e-02, 6.3809e-02],\n",
      "         [6.7458e-02, 6.7458e-02],\n",
      "         [6.1383e-02, 6.1383e-02],\n",
      "         [5.1966e-02, 5.1966e-02],\n",
      "         [1.0000e+06, 1.0000e+06]],\n",
      "\n",
      "        [[9.9465e-02, 9.9465e-02],\n",
      "         [9.7511e-02, 9.7511e-02],\n",
      "         [1.0000e+06, 1.0000e+06],\n",
      "         [1.0000e+06, 1.0000e+06],\n",
      "         [1.0000e+06, 1.0000e+06]]], device='cuda:0'), torch.Size([3, 5, 2]))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing for Linear Attentions: QKV / normalizer Z\n",
    "softmax는 row-wise하게 정규화 하는데, 우리도 똑같이 정규화가 필요하지 않냐고 그래서 Z가 필요\n",
    "여기서, QKV가 결국 row-wise 하게 정규화 되어야 한다는게 포인트임\n",
    "그렇다면 Z의 크기는 16, 512, 64가 되어야 한다\n",
    "\"\"\"\n",
    "\n",
    "summation_key = k_key.sum(dim=1).unsqueeze(1).expand(-1, dim_head, -1).permute(0,2,1)\n",
    "\n",
    "print(f\"key, summation_key: {key.shape, summation_key.shape}\")\n",
    "\n",
    "Z = 1/torch.clamp(torch.matmul(k_query, summation_key), min=1e-6)\n",
    "print(f\"Normalizer Z: {Z, Z.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:09.815960Z",
     "start_time": "2024-03-04T16:47:09.810687Z"
    }
   },
   "id": "4b94b3decb9e4270",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_attn_matrix: (torch.Size([3, 5, 2]), tensor([[[3.9718e-01, 5.6831e-01],\n",
      "         [3.9631e-01, 5.6779e-01],\n",
      "         [3.9677e-01, 5.6806e-01],\n",
      "         [2.3637e+05, 8.2210e+05],\n",
      "         [5.7225e+05, 9.0375e+05]],\n",
      "\n",
      "        [[4.0818e-01, 7.0590e-01],\n",
      "         [4.1454e-01, 7.1592e-01],\n",
      "         [4.0892e-01, 7.0707e-01],\n",
      "         [4.1338e-01, 7.1410e-01],\n",
      "         [5.2581e+05, 1.8200e+05]],\n",
      "\n",
      "        [[4.6812e-01, 7.3529e-01],\n",
      "         [4.6815e-01, 7.3535e-01],\n",
      "         [4.3231e+05, 3.1439e+05],\n",
      "         [6.0615e+05, 6.2035e+05],\n",
      "         [8.3891e+05, 5.6749e+05]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing for Linear Attentions: QKV / normalizer Z \n",
    "\"\"\"\n",
    "\n",
    "linear_attn_matrix = torch.mul(QKV, Z)\n",
    "print(f\"linear_attn_matrix: {linear_attn_matrix.shape, linear_attn_matrix}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:12.928666Z",
     "start_time": "2024-03-04T16:47:12.922616Z"
    }
   },
   "id": "65459cc6481c7d45",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_matrix: (torch.Size([3, 5, 5]), tensor([[[0.3713, 0.6363, 1.0094, 0.5870, 0.7410],\n",
      "         [0.1055, 0.2372, 0.3701, 0.2420, 0.2239],\n",
      "         [0.2164, 0.4022, 0.6346, 0.3840, 0.4393],\n",
      "         [0.3069, 0.4024, 0.6519, 0.3202, 0.5834],\n",
      "         [0.1555, 0.2623, 0.4167, 0.2403, 0.3093]],\n",
      "\n",
      "        [[0.2487, 0.1702, 0.1442, 0.2789, 0.3663],\n",
      "         [0.0394, 0.2411, 0.1327, 0.3839, 0.3884],\n",
      "         [0.2519, 0.2133, 0.1670, 0.3475, 0.4341],\n",
      "         [0.2112, 0.4541, 0.2813, 0.7280, 0.7887],\n",
      "         [0.0527, 0.1607, 0.0945, 0.2568, 0.2699]],\n",
      "\n",
      "        [[0.3726, 0.5146, 0.2369, 0.3336, 0.5193],\n",
      "         [0.4214, 0.5751, 0.1496, 0.1591, 0.4101],\n",
      "         [0.7383, 1.0163, 0.4114, 0.5539, 0.9420],\n",
      "         [0.6791, 0.9325, 0.3396, 0.4380, 0.8084],\n",
      "         [0.5018, 0.6880, 0.2337, 0.2919, 0.5716]]], device='cuda:0'))\n",
      "attention_dist: (torch.Size([3, 5, 5]), tensor([[[0.2383, 0.3106, 0.4511, 0.0000, 0.0000],\n",
      "         [0.2904, 0.3313, 0.3783, 0.0000, 0.0000],\n",
      "         [0.2686, 0.3234, 0.4080, 0.0000, 0.0000],\n",
      "         [0.2847, 0.3132, 0.4020, 0.0000, 0.0000],\n",
      "         [0.2931, 0.3262, 0.3806, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2593, 0.2398, 0.2336, 0.2673, 0.0000],\n",
      "         [0.2113, 0.2585, 0.2320, 0.2982, 0.0000],\n",
      "         [0.2512, 0.2417, 0.2308, 0.2764, 0.0000],\n",
      "         [0.1990, 0.2538, 0.2135, 0.3337, 0.0000],\n",
      "         [0.2281, 0.2542, 0.2379, 0.2798, 0.0000]],\n",
      "\n",
      "        [[0.4646, 0.5354, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4617, 0.5383, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4310, 0.5690, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4370, 0.5630, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4536, 0.5464, 0.0000, 0.0000, 0.0000]]], device='cuda:0'))\n",
      "attention_matrix: (torch.Size([3, 5, 2]), tensor([[[0.3691, 0.5519],\n",
      "         [0.4015, 0.5708],\n",
      "         [0.3881, 0.5630],\n",
      "         [0.3950, 0.5671],\n",
      "         [0.4020, 0.5712]],\n",
      "\n",
      "        [[0.4038, 0.6930],\n",
      "         [0.4199, 0.7168],\n",
      "         [0.4049, 0.6984],\n",
      "         [0.4116, 0.7319],\n",
      "         [0.4174, 0.7058]],\n",
      "\n",
      "        [[0.4683, 0.7356],\n",
      "         [0.4691, 0.7369],\n",
      "         [0.4780, 0.7515],\n",
      "         [0.4763, 0.7486],\n",
      "         [0.4715, 0.7408]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Comparing with pure self-attention\n",
    "\"\"\"\n",
    "\n",
    "attn_matrix = torch.matmul(query, key.transpose(-1, -2)) / torch.sqrt(torch.tensor(dim_head))\n",
    "print(f\"attn_matrix: {attn_matrix.shape, attn_matrix}\")\n",
    "\n",
    "padding_mask = padding_mask.unsqueeze(1)\n",
    "attn_matrix = attn_matrix.masked_fill(padding_mask == 1, float('-inf'))\n",
    "attention_dist = F.softmax(attn_matrix, dim=-1)\n",
    "print(f\"attention_dist: {attention_dist.shape, attention_dist}\")\n",
    "\n",
    "attention_matrix = torch.matmul(attention_dist, value)\n",
    "print(f\"attention_matrix: {attention_matrix.shape, attention_matrix}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T16:47:17.615429Z",
     "start_time": "2024-03-04T16:47:17.591879Z"
    }
   },
   "id": "5b0242ad3d65be20",
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(inf, device='cuda:0')"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Comparing with pure self-attention by KL-divergence\n",
    "배치 별, 평균 총합 0.5 ~ 2 정도 차이남, 이게 보니까 처음에 랜덤 초기화 빨로 갈리네\n",
    "\"\"\"\n",
    "\n",
    "kl_div = F.kl_div(linear_attn_matrix.log(), attention_matrix, reduction='batchmean')\n",
    "kl_div"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T13:13:39.924499Z",
     "start_time": "2024-03-04T13:13:39.919385Z"
    }
   },
   "id": "2cdaaf0b6c2d4400",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0264, -0.0698, -1.3971, -1.5667],\n         [ 0.5706, -1.4718,  0.3398, -0.5280],\n         [ 1.5465,  0.2453,  1.0911,  0.6062],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.4773,  1.9033,  0.6571,  0.4388],\n         [ 0.1047, -0.3162, -3.4738, -0.4424],\n         [ 0.4799,  0.7670, -1.0056, -0.4248],\n         [ 1.2279, -0.7639,  1.4043, -0.2604],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[-0.1115,  0.3349, -1.0625,  0.5592],\n         [ 0.3361,  1.7460,  1.9226,  0.5757],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Test code for applying padding masking to linear attention \"\"\"\n",
    "test_q = torch.randn(3, 5, 4, device=device)\n",
    "test_k = torch.randn(3, 5, 4, device=device)\n",
    "test_v = torch.randn(3, 5, 4, device=device)\n",
    "\n",
    "padding_mask = torch.tensor([\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1]],\n",
    "    device=device\n",
    ")\n",
    "test_k[padding_mask == 1] = 0\n",
    "test_k"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T04:00:33.032590Z",
     "start_time": "2024-03-04T04:00:33.027595Z"
    }
   },
   "id": "26644eb6ded2d1c8",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, dim_model: int= 768):\n",
    "        super().__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.i_arr = torch.arange(1, int(dim_model/2)+1)  # 세타값을 살리려면 \n",
    "        self.theta = 10000**(-2*(self.i_arr - 1)/self.dim_model)\n",
    "    \n",
    "    def forward(self):\n",
    "        print(self.i_arr.shape)\n",
    "        print(self.i_arr)\n",
    "        print(self.theta.shape)\n",
    "        print(self.theta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:30:49.209569Z",
     "start_time": "2024-03-02T13:30:49.203796Z"
    }
   },
   "id": "97c1f10595f4412f",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n",
      "tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
      "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384])\n",
      "torch.Size([384])\n",
      "tensor([1.0000e+00, 9.7630e-01, 9.5316e-01, 9.3057e-01, 9.0852e-01, 8.8699e-01,\n",
      "        8.6596e-01, 8.4544e-01, 8.2540e-01, 8.0584e-01, 7.8674e-01, 7.6810e-01,\n",
      "        7.4989e-01, 7.3212e-01, 7.1477e-01, 6.9783e-01, 6.8129e-01, 6.6515e-01,\n",
      "        6.4938e-01, 6.3399e-01, 6.1897e-01, 6.0430e-01, 5.8997e-01, 5.7599e-01,\n",
      "        5.6234e-01, 5.4901e-01, 5.3600e-01, 5.2330e-01, 5.1090e-01, 4.9879e-01,\n",
      "        4.8697e-01, 4.7543e-01, 4.6416e-01, 4.5316e-01, 4.4242e-01, 4.3193e-01,\n",
      "        4.2170e-01, 4.1170e-01, 4.0195e-01, 3.9242e-01, 3.8312e-01, 3.7404e-01,\n",
      "        3.6517e-01, 3.5652e-01, 3.4807e-01, 3.3982e-01, 3.3177e-01, 3.2390e-01,\n",
      "        3.1623e-01, 3.0873e-01, 3.0142e-01, 2.9427e-01, 2.8730e-01, 2.8049e-01,\n",
      "        2.7384e-01, 2.6735e-01, 2.6102e-01, 2.5483e-01, 2.4879e-01, 2.4289e-01,\n",
      "        2.3714e-01, 2.3152e-01, 2.2603e-01, 2.2067e-01, 2.1544e-01, 2.1034e-01,\n",
      "        2.0535e-01, 2.0049e-01, 1.9573e-01, 1.9110e-01, 1.8657e-01, 1.8214e-01,\n",
      "        1.7783e-01, 1.7361e-01, 1.6950e-01, 1.6548e-01, 1.6156e-01, 1.5773e-01,\n",
      "        1.5399e-01, 1.5034e-01, 1.4678e-01, 1.4330e-01, 1.3991e-01, 1.3659e-01,\n",
      "        1.3335e-01, 1.3019e-01, 1.2711e-01, 1.2409e-01, 1.2115e-01, 1.1828e-01,\n",
      "        1.1548e-01, 1.1274e-01, 1.1007e-01, 1.0746e-01, 1.0491e-01, 1.0243e-01,\n",
      "        1.0000e-01, 9.7630e-02, 9.5316e-02, 9.3057e-02, 9.0852e-02, 8.8699e-02,\n",
      "        8.6596e-02, 8.4544e-02, 8.2540e-02, 8.0584e-02, 7.8674e-02, 7.6810e-02,\n",
      "        7.4989e-02, 7.3212e-02, 7.1477e-02, 6.9783e-02, 6.8129e-02, 6.6515e-02,\n",
      "        6.4938e-02, 6.3399e-02, 6.1897e-02, 6.0430e-02, 5.8997e-02, 5.7599e-02,\n",
      "        5.6234e-02, 5.4901e-02, 5.3600e-02, 5.2330e-02, 5.1090e-02, 4.9879e-02,\n",
      "        4.8697e-02, 4.7543e-02, 4.6416e-02, 4.5316e-02, 4.4242e-02, 4.3193e-02,\n",
      "        4.2170e-02, 4.1170e-02, 4.0195e-02, 3.9242e-02, 3.8312e-02, 3.7404e-02,\n",
      "        3.6517e-02, 3.5652e-02, 3.4807e-02, 3.3982e-02, 3.3177e-02, 3.2390e-02,\n",
      "        3.1623e-02, 3.0873e-02, 3.0142e-02, 2.9427e-02, 2.8730e-02, 2.8049e-02,\n",
      "        2.7384e-02, 2.6735e-02, 2.6102e-02, 2.5483e-02, 2.4879e-02, 2.4289e-02,\n",
      "        2.3714e-02, 2.3152e-02, 2.2603e-02, 2.2067e-02, 2.1544e-02, 2.1034e-02,\n",
      "        2.0535e-02, 2.0049e-02, 1.9573e-02, 1.9110e-02, 1.8657e-02, 1.8214e-02,\n",
      "        1.7783e-02, 1.7361e-02, 1.6950e-02, 1.6548e-02, 1.6156e-02, 1.5773e-02,\n",
      "        1.5399e-02, 1.5034e-02, 1.4678e-02, 1.4330e-02, 1.3991e-02, 1.3659e-02,\n",
      "        1.3335e-02, 1.3019e-02, 1.2711e-02, 1.2409e-02, 1.2115e-02, 1.1828e-02,\n",
      "        1.1548e-02, 1.1274e-02, 1.1007e-02, 1.0746e-02, 1.0491e-02, 1.0243e-02,\n",
      "        1.0000e-02, 9.7630e-03, 9.5316e-03, 9.3057e-03, 9.0852e-03, 8.8699e-03,\n",
      "        8.6596e-03, 8.4544e-03, 8.2540e-03, 8.0584e-03, 7.8674e-03, 7.6810e-03,\n",
      "        7.4989e-03, 7.3212e-03, 7.1477e-03, 6.9783e-03, 6.8129e-03, 6.6515e-03,\n",
      "        6.4938e-03, 6.3399e-03, 6.1897e-03, 6.0430e-03, 5.8997e-03, 5.7599e-03,\n",
      "        5.6234e-03, 5.4901e-03, 5.3600e-03, 5.2330e-03, 5.1090e-03, 4.9879e-03,\n",
      "        4.8697e-03, 4.7543e-03, 4.6416e-03, 4.5316e-03, 4.4242e-03, 4.3193e-03,\n",
      "        4.2170e-03, 4.1170e-03, 4.0195e-03, 3.9242e-03, 3.8312e-03, 3.7404e-03,\n",
      "        3.6517e-03, 3.5652e-03, 3.4807e-03, 3.3982e-03, 3.3177e-03, 3.2390e-03,\n",
      "        3.1623e-03, 3.0873e-03, 3.0142e-03, 2.9427e-03, 2.8730e-03, 2.8049e-03,\n",
      "        2.7384e-03, 2.6735e-03, 2.6102e-03, 2.5483e-03, 2.4879e-03, 2.4289e-03,\n",
      "        2.3714e-03, 2.3152e-03, 2.2603e-03, 2.2067e-03, 2.1544e-03, 2.1034e-03,\n",
      "        2.0535e-03, 2.0049e-03, 1.9573e-03, 1.9110e-03, 1.8657e-03, 1.8214e-03,\n",
      "        1.7783e-03, 1.7361e-03, 1.6950e-03, 1.6548e-03, 1.6156e-03, 1.5773e-03,\n",
      "        1.5399e-03, 1.5034e-03, 1.4678e-03, 1.4330e-03, 1.3991e-03, 1.3659e-03,\n",
      "        1.3335e-03, 1.3019e-03, 1.2711e-03, 1.2409e-03, 1.2115e-03, 1.1828e-03,\n",
      "        1.1548e-03, 1.1274e-03, 1.1007e-03, 1.0746e-03, 1.0491e-03, 1.0243e-03,\n",
      "        1.0000e-03, 9.7630e-04, 9.5316e-04, 9.3057e-04, 9.0852e-04, 8.8699e-04,\n",
      "        8.6596e-04, 8.4544e-04, 8.2540e-04, 8.0584e-04, 7.8674e-04, 7.6810e-04,\n",
      "        7.4989e-04, 7.3212e-04, 7.1477e-04, 6.9783e-04, 6.8129e-04, 6.6515e-04,\n",
      "        6.4938e-04, 6.3399e-04, 6.1897e-04, 6.0430e-04, 5.8997e-04, 5.7599e-04,\n",
      "        5.6234e-04, 5.4901e-04, 5.3600e-04, 5.2330e-04, 5.1090e-04, 4.9879e-04,\n",
      "        4.8697e-04, 4.7543e-04, 4.6416e-04, 4.5316e-04, 4.4242e-04, 4.3193e-04,\n",
      "        4.2170e-04, 4.1170e-04, 4.0195e-04, 3.9242e-04, 3.8312e-04, 3.7404e-04,\n",
      "        3.6517e-04, 3.5652e-04, 3.4807e-04, 3.3982e-04, 3.3177e-04, 3.2390e-04,\n",
      "        3.1623e-04, 3.0873e-04, 3.0142e-04, 2.9427e-04, 2.8730e-04, 2.8049e-04,\n",
      "        2.7384e-04, 2.6735e-04, 2.6102e-04, 2.5483e-04, 2.4879e-04, 2.4289e-04,\n",
      "        2.3714e-04, 2.3152e-04, 2.2603e-04, 2.2067e-04, 2.1544e-04, 2.1034e-04,\n",
      "        2.0535e-04, 2.0049e-04, 1.9573e-04, 1.9110e-04, 1.8657e-04, 1.8214e-04,\n",
      "        1.7783e-04, 1.7361e-04, 1.6950e-04, 1.6548e-04, 1.6156e-04, 1.5773e-04,\n",
      "        1.5399e-04, 1.5034e-04, 1.4678e-04, 1.4330e-04, 1.3991e-04, 1.3659e-04,\n",
      "        1.3335e-04, 1.3019e-04, 1.2711e-04, 1.2409e-04, 1.2115e-04, 1.1828e-04,\n",
      "        1.1548e-04, 1.1274e-04, 1.1007e-04, 1.0746e-04, 1.0491e-04, 1.0243e-04])\n"
     ]
    }
   ],
   "source": [
    "test = RoPE()\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:30:49.213790Z",
     "start_time": "2024-03-02T13:30:49.206814Z"
    }
   },
   "id": "938bd92df37c8366",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:30:49.227687Z",
     "start_time": "2024-03-02T13:30:49.213511Z"
    }
   },
   "id": "e598d761ff00999a",
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
